from modelling_utils.model_management import save_model_and_comparison
from modelling_utils.sampling import undersample_zeros,smoteR
from modelling_utils.preprocessing import split_com_sem_vizinha,particao_por_estacao
from comparison_utils import compute_comparison_df
from tqdm.notebook import tqdm
import pandas as pd
import warnings
warnings.filterwarnings('ignore')
import numpy as np
import os

def generate_X_y_train_test(abt_estacoes_vizinhas, usar_n_estacoes_vizinhas=0, 
                           zero_undersampling_ratio=None, smote_oversampling=False, 
                           smote_threshold=0.5, smote_pct_oversampling=0.01, 
                           smote_pct_undersampling=1.0, smote_k_neighbors=5,
                           smote_constraint_columns=None, smote_relevance_function=None,
                           smote_explanatory_variables=None,
                           percent_datetime_partitioning_split=0.7,
                           random_state=None):
    """
    Gera conjuntos de treino e teste a partir de dados de esta√ß√µes meteorol√≥gicas.
    
    Esta fun√ß√£o processa um DataFrame com dados de esta√ß√µes meteorol√≥gicas e suas
    esta√ß√µes vizinhas, criando conjuntos de treino e teste para modelagem preditiva
    de precipita√ß√£o. Oferece op√ß√µes para incluir dados de esta√ß√µes vizinhas,
    balanceamento de dados e particionamento temporal.
    
    Parameters
    ----------
    abt_estacoes_vizinhas : pd.DataFrame
        DataFrame contendo os dados das esta√ß√µes meteorol√≥gicas e suas vizinhas.
        Deve conter a coluna 'vl_precipitacao' como vari√°vel target.
        
    usar_n_estacoes_vizinhas : int, optional, default=0
        N√∫mero de esta√ß√µes vizinhas a incluir no dataset. Se 0, n√£o inclui
        dados de esta√ß√µes vizinhas. Deve ser >= 0.
        
    zero_undersampling_ratio : float, optional, default=None
        Propor√ß√£o de registros com precipita√ß√£o zero em rela√ß√£o aos registros
        com precipita√ß√£o > 0 no conjunto de treino. Se None, n√£o aplica undersampling.
        Exemplos:
        - 1.0: mant√©m mesmo n√∫mero de zeros e n√£o-zeros (balanceamento 50/50)
        - 0.5: mant√©m metade de zeros em rela√ß√£o aos n√£o-zeros
        - 2.0: mant√©m o dobro de zeros em rela√ß√£o aos n√£o-zeros
        Deve ser > 0.
        
    smote_oversampling : bool, optional, default=False
        Se True, aplica t√©cnica SMOTE-R para oversampling de casos raros.
        
    smote_threshold : float, optional, default=0.5
        Limiar para determinar observa√ß√µes raras vs comuns no SMOTE-R.
        
    smote_pct_oversampling : float, optional, default=0.01
        Porcentagem decimal de aumento nos casos raros (0.01 = 1%, 0.50 = 50%)
        Exemplo: 100 casos raros com smote_pct_oversampling=0.01 ‚Üí 1 caso sint√©tico
        
    smote_pct_undersampling : float, optional, default=1.0
        Multiplicador para casos comuns em rela√ß√£o ao total de casos raros + sint√©ticos
        (1.0 = mesmo n√∫mero, 0.5 = metade, 2.0 = dobro)
        
    smote_k_neighbors : int, optional, default=5
        N√∫mero de vizinhos mais pr√≥ximos para gera√ß√£o sint√©tica no SMOTE-R.
        
    smote_constraint_columns : list or str, optional, default=None
        Lista de colunas que devem ter valores iguais entre a amostra e seus vizinhos
        no SMOTE-R. Exemplo: ['dt_medicao'] ou ['dt_medicao', 'regiao'].
        
    smote_relevance_function : callable, optional, default=None
        Fun√ß√£o customizada que determina a relev√¢ncia de uma observa√ß√£o no SMOTE-R.
        Se None, usa fun√ß√£o padr√£o baseada na dist√¢ncia da mediana.
        
    percent_datetime_partitioning_split : float, optional, default=0.7
        Percentual dos dados para treino na parti√ß√£o temporal.
        Deve estar entre 0 e 1.
        
    random_state : int, optional, default=None
        Semente para reprodutibilidade em opera√ß√µes aleat√≥rias.
    
    Returns
    -------
    tuple
        Tupla contendo (X_train, X_test, y_train, y_test):
        - X_train : pd.DataFrame - Features de treino
        - X_test : pd.DataFrame - Features de teste  
        - y_train : pd.Series - Target de treino
        - y_test : pd.Series - Target de teste
    
    Raises
    ------
    ValueError
        Se os par√¢metros estiverem fora dos limites v√°lidos ou se colunas
        obrigat√≥rias estiverem ausentes.
        
    KeyError
        Se colunas esperadas n√£o existirem no DataFrame de entrada.
        
    TypeError
        Se os tipos dos par√¢metros n√£o forem os esperados.
    
    Examples
    --------
    >>> # Uso b√°sico sem esta√ß√µes vizinhas
    >>> X_train, X_test, y_train, y_test = generate_X_y_train_test(df_estacoes)
    
    >>> # Balanceamento 50/50 (mesmo n√∫mero de zeros e n√£o-zeros)
    >>> X_train, X_test, y_train, y_test = generate_X_y_train_test(
    ...     df_estacoes, 
    ...     zero_undersampling_ratio=1.0,
    ...     random_state=42
    ... )
    
    >>> # Incluindo 3 esta√ß√µes vizinhas com SMOTE-R (1% de aumento)
    >>> X_train, X_test, y_train, y_test = generate_X_y_train_test(
    ...     df_estacoes, 
    ...     usar_n_estacoes_vizinhas=3,
    ...     zero_undersampling_ratio=0.5,  # metade de zeros em rela√ß√£o aos n√£o-zeros
    ...     smote_oversampling=True,
    ...     smote_threshold=0.6,
    ...     smote_pct_oversampling=0.01,  # 1% de aumento nos casos raros
    ...     smote_constraint_columns=['dt_medicao'],
    ...     random_state=42
    ... )
    
    >>> # SMOTE-R com 50% de aumento nos casos raros
    >>> X_train, X_test, y_train, y_test = generate_X_y_train_test(
    ...     df_estacoes, 
    ...     zero_undersampling_ratio=2.0,  # dobro de zeros em rela√ß√£o aos n√£o-zeros
    ...     smote_oversampling=True,
    ...     smote_pct_oversampling=0.50,  # 50% de aumento
    ...     smote_pct_undersampling=0.8,   # 80% de casos comuns em rela√ß√£o aos raros+sint√©ticos
    ...     random_state=42
    ... )
    
    Notes
    -----
    - A fun√ß√£o assume que existe uma fun√ß√£o `particao_por_estacao` dispon√≠vel
    - A fun√ß√£o assume que existe uma fun√ß√£o `undersample_zeros` dispon√≠vel
    - A fun√ß√£o assume que existe uma fun√ß√£o `smoteR` dispon√≠vel quando smote_oversampling=True
    - O undersampling √© aplicado apenas no conjunto de treino, n√£o afetando o conjunto de teste
    - smote_pct_oversampling agora √© uma porcentagem decimal (0.01 = 1% de aumento)
    """
    
    
    try:
        if not isinstance(usar_n_estacoes_vizinhas, int) or usar_n_estacoes_vizinhas < 0:
            raise ValueError("usar_n_estacoes_vizinhas deve ser um inteiro >= 0")
        
        if zero_undersampling_ratio is not None:
            if not isinstance(zero_undersampling_ratio, (int, float)) or zero_undersampling_ratio <= 0:
                raise ValueError("zero_undersampling_ratio deve ser None ou um n√∫mero > 0")
        
        if not isinstance(percent_datetime_partitioning_split, (int, float)) or not (0 < percent_datetime_partitioning_split < 1):
            raise ValueError("percent_datetime_partitioning_split deve ser um n√∫mero entre 0 e 1")
        
        if not isinstance(smote_threshold, (int, float)) or not (0 <= smote_threshold <= 1):
            raise ValueError("smote_threshold deve ser um n√∫mero entre 0 e 1")
        
        # MUDAN√áA: Valida√ß√£o para smote_pct_oversampling como decimal
        if not isinstance(smote_pct_oversampling, (int, float)) or smote_pct_oversampling < 0:
            raise ValueError("smote_pct_oversampling deve ser um n√∫mero >= 0 (ex: 0.01 para 1%)")
        
        if smote_pct_oversampling > 10.0:
            print(f"‚ö†Ô∏è  Aviso: smote_pct_oversampling muito alto ({smote_pct_oversampling*100:.1f}%). Considere usar valores menores.")
        
        # MUDAN√áA: Valida√ß√£o para smote_pct_undersampling como multiplicador
        if not isinstance(smote_pct_undersampling, (int, float)) or smote_pct_undersampling < 0:
            raise ValueError("smote_pct_undersampling deve ser um n√∫mero >= 0")
        
        if not isinstance(smote_k_neighbors, int) or smote_k_neighbors < 1:
            raise ValueError("smote_k_neighbors deve ser um inteiro >= 1")
        
        if abt_estacoes_vizinhas.empty:
            raise ValueError("DataFrame de entrada n√£o pode estar vazio")
        
        if 'vl_precipitacao' not in abt_estacoes_vizinhas.columns:
            raise KeyError("Coluna 'vl_precipitacao' n√£o encontrada no DataFrame")
        
        print(f"üìä Iniciando processamento com {len(abt_estacoes_vizinhas)} registros...")
        
        abt = abt_estacoes_vizinhas[[c for c in abt_estacoes_vizinhas.columns if 'vizinha' not in c]].copy()
        print(f"üè≠ Dataset base criado com {abt.shape[1]} colunas")
        
        if usar_n_estacoes_vizinhas > 0:
            print(f"üåê Incluindo dados de {usar_n_estacoes_vizinhas} esta√ß√£o(√µes) vizinha(s)...")
            
            vizinhas_columns_prefix = [
                'vl_correlacao_estacao_vizinha_{i_vizinha}',
                'pct_intersecao_precipitacao_vizinha_{i_vizinha}',
                'vl_distancia_km_vizinha_{i_vizinha}',
                'vl_prioridade_vizinha_{i_vizinha}',
                'vl_precipitacao_vizinha_{i_vizinha}'
            ]
            
            for i in tqdm(range(1, usar_n_estacoes_vizinhas + 1), desc="Adicionando esta√ß√µes vizinhas"):
                vizinha_columns = [col.format(i_vizinha=i) for col in vizinhas_columns_prefix]
                
                missing_cols = [col for col in vizinha_columns if col not in abt_estacoes_vizinhas.columns]
                if missing_cols:
                    print(f"‚ö†Ô∏è  Aviso: Colunas n√£o encontradas para esta√ß√£o vizinha {i}: {missing_cols}")
                    continue
                
                for col in vizinha_columns:
                    try:
                        abt.loc[:, col] = abt_estacoes_vizinhas[col]
                    except KeyError as e:
                        print(f"‚ö†Ô∏è  Erro ao adicionar coluna {col}: {e}")
            
            print(f"‚úÖ Dataset expandido para {abt.shape[1]} colunas")

        print(f"üîÑ Realizando parti√ß√£o temporal ({percent_datetime_partitioning_split:.1%} treino)...")
        try:
            training_abt, validation_abt = particao_por_estacao(abt, percent_datetime_partitioning_split)
            print(f"üìà Treino: {len(training_abt)} registros | Teste: {len(validation_abt)} registros")
        except Exception as e:
            raise RuntimeError(f"Erro na parti√ß√£o dos dados: {e}")
        
        try:
            X_train, y_train = training_abt.drop('vl_precipitacao', axis=1), training_abt['vl_precipitacao']
            X_test, y_test = validation_abt.drop('vl_precipitacao', axis=1), validation_abt['vl_precipitacao']
        except KeyError as e:
            raise KeyError(f"Erro ao separar features e target: {e}")

        if zero_undersampling_ratio is not None:
            print(f"‚öñÔ∏è  Aplicando undersampling com ratio {zero_undersampling_ratio}...")
            print(f"    üí° Isso significa: {zero_undersampling_ratio} zeros para cada 1 n√£o-zero")
            try:
                original_size = len(X_train)
                zeros_before = (y_train == 0).sum()
                non_zeros_before = (y_train > 0).sum()
                
                X_train, y_train = undersample_zeros(X_train, y_train, zero_ratio=zero_undersampling_ratio, random_state=random_state)
                
                zeros_after = (y_train == 0).sum()
                non_zeros_after = (y_train > 0).sum()
                actual_ratio = zeros_after / non_zeros_after if non_zeros_after > 0 else 0
                
                print(f"üìâ Antes: {zeros_before:,} zeros, {non_zeros_before:,} n√£o-zeros")
                print(f"üìä Depois: {zeros_after:,} zeros, {non_zeros_after:,} n√£o-zeros")
                print(f"üìà Ratio real: {actual_ratio:.2f} | Tamanho: {original_size} ‚Üí {len(X_train)}")
                
            except Exception as e:
                raise RuntimeError(f"Erro no undersampling: {e}")

        if smote_oversampling:
            print(f"üß¨ Aplicando SMOTE-R com threshold={smote_threshold}...")
            print(f"    üìà Oversampling: {smote_pct_oversampling*100:.2f}% de aumento nos casos raros")
            print(f"    ‚öñÔ∏è  Undersampling: multiplicador {smote_pct_undersampling} para casos comuns")
            try:
                training_combined = pd.concat([X_train, y_train], axis=1)
                
                balanced_training = smoteR(
                    dataframe=training_combined,
                    target_column='vl_precipitacao',
                    explanatory_variables=smote_explanatory_variables,
                    relevance_function=smote_relevance_function,
                    threshold=smote_threshold,
                    pct_oversampling=smote_pct_oversampling,
                    pct_undersampling=smote_pct_undersampling,
                    number_of_nearest_neighbors=smote_k_neighbors,
                    constraint_columns=smote_constraint_columns,
                    random_state=random_state)
                
                X_train = balanced_training.drop('vl_precipitacao', axis=1)
                y_train = balanced_training['vl_precipitacao']
                
                print(f"‚úÖ SMOTE-R aplicado com sucesso!")
                
            except Exception as e:
                print(f"‚ùå Erro na aplica√ß√£o do SMOTE-R: {e}")
                print("   Continuando com dataset n√£o balanceado...")
        
        print(f"\nüìã Resumo final:")
        print(f"   ‚Ä¢ Features de treino: {X_train.shape}")
        print(f"   ‚Ä¢ Features de teste: {X_test.shape}")
        print(f"   ‚Ä¢ Target treino - valores √∫nicos: {y_train.nunique()}")
        print(f"   ‚Ä¢ Target teste - valores √∫nicos: {y_test.nunique()}")
        
        if smote_oversampling or zero_undersampling_ratio is not None:
            print(f"\nüìä Estat√≠sticas do target ap√≥s processamento:")
            print(f"   ‚Ä¢ Treino - M√©dia: {y_train.mean():.3f}, Mediana: {y_train.median():.3f}")
            print(f"   ‚Ä¢ Teste  - M√©dia: {y_test.mean():.3f}, Mediana: {y_test.median():.3f}")
            print(f"   ‚Ä¢ Zeros no treino: {(y_train == 0).sum():,} ({(y_train == 0).mean()*100:.1f}%)")
            print(f"   ‚Ä¢ Zeros no teste: {(y_test == 0).sum():,} ({(y_test == 0).mean()*100:.1f}%)")
        
        return X_train, X_test, y_train, y_test
        
    except (ValueError, KeyError, TypeError) as e:
        print(f"‚ùå Erro de valida√ß√£o: {e}")
        raise
    except Exception as e:
        print(f"‚ùå Erro inesperado: {e}")
        raise RuntimeError(f"Erro inesperado durante o processamento: {e}")
    

def train_model(abt_estacoes_vizinhas, Model, model_number, usar_n_estacoes_vizinhas,
                zero_undersampling_ratio=None, smote_oversampling=False, 
                smote_threshold=0.5, smote_pct_oversampling=0.01,
                smote_pct_undersampling=1.0, smote_k_neighbors=5,smote_explanatory_variables=None,
                smote_constraint_columns=None, smote_random_state=None,
                use_bi_model=False, threshold_prioridade=0.5, 
                percent_datetime_partitioning_split=0.7,
                truncate_to_non_negative_target=True,
                classifier_model=None, classifier_thresholds=None):
    """
    Treina modelo(s) de machine learning para previs√£o de precipita√ß√£o.
    
    Esta fun√ß√£o treina modelos preditivos usando dados de esta√ß√µes meteorol√≥gicas,
    oferecendo tr√™s abordagens: modelo √∫nico, modelo duplo (bi-model) e/ou 
    modelo h√≠brido (classificador + regressores por bins). As abordagens podem
    ser combinadas para m√°xima flexibilidade.
    
    Parameters
    ----------
    abt_estacoes_vizinhas : pd.DataFrame
        DataFrame contendo os dados das esta√ß√µes meteorol√≥gicas e suas vizinhas.
        Deve conter as colunas 'id_estacao', 'dt_medicao' e 'vl_precipitacao'.
        
    Model : class
        Classe do modelo de machine learning a ser utilizado para regress√£o 
        (ex: RandomForestRegressor). Deve implementar os m√©todos fit() e predict().
        
    model_number : int or str
        Identificador √∫nico do modelo para salvamento dos arquivos.
        
    usar_n_estacoes_vizinhas : int
        N√∫mero de esta√ß√µes vizinhas a incluir no dataset. Deve ser >= 0.
        
    zero_undersampling_ratio : float, optional, default=None
        Propor√ß√£o de registros com precipita√ß√£o zero em rela√ß√£o aos registros
        com precipita√ß√£o > 0 no conjunto de treino. Se None, n√£o aplica undersampling.
        Exemplos:
        - 1.0: mant√©m mesmo n√∫mero de zeros e n√£o-zeros (balanceamento 50/50)
        - 0.5: mant√©m metade de zeros em rela√ß√£o aos n√£o-zeros
        - 2.0: mant√©m o dobro de zeros em rela√ß√£o aos n√£o-zeros
        Deve ser > 0.
        
    smote_oversampling : bool, optional, default=False
        Se True, aplica t√©cnica SMOTE-R para balanceamento de target cont√≠nuo.
        
    smote_threshold : float, optional, default=0.5
        Limiar para determinar observa√ß√µes raras vs comuns no SMOTE-R.
        
    smote_pct_oversampling : float, optional, default=0.01
        Porcentagem decimal de aumento nos casos raros (0.01 = 1%, 0.50 = 50%)
        Exemplo: 100 casos raros com smote_pct_oversampling=0.01 ‚Üí 1 caso sint√©tico
        
    smote_pct_undersampling : float, optional, default=1.0
        Multiplicador para casos comuns em rela√ß√£o ao total de casos raros + sint√©ticos
        (1.0 = mesmo n√∫mero, 0.5 = metade, 2.0 = dobro)
        
    smote_k_neighbors : int, optional, default=5
        N√∫mero de vizinhos mais pr√≥ximos para gera√ß√£o sint√©tica no SMOTE-R.
        
    smote_constraint_columns : list or str, optional
        Colunas que devem ter valores iguais entre amostras e vizinhos no SMOTE-R.
        Exemplo: ['dt_medicao'] para manter consist√™ncia temporal.
        
    smote_random_state : int, optional
        Semente para reprodutibilidade do SMOTE-R.
        
    use_bi_model : bool, optional, default=False
        Se True, treina dois modelos separados baseado no threshold_prioridade.
        Se False, treina um modelo √∫nico.
        
    threshold_prioridade : float, optional, default=0.5
        Threshold para separar dados em 'com_vizinha' e 'sem_vizinha' quando
        use_bi_model=True. Deve estar entre 0 e 1.
        
    percent_datetime_partitioning_split : float, optional, default=0.7
        Percentual dos dados para treino na parti√ß√£o temporal.
        Deve estar entre 0 e 1.
        
    truncate_to_non_negative_target : bool, optional, default=True
        Se True, trunca predi√ß√µes negativas para 0 (precipita√ß√£o n√£o pode ser negativa).
        
    classifier_model : class, optional, default=None
        Classe do modelo de classifica√ß√£o para abordagem h√≠brida (ex: XGBClassifier).
        Se fornecido, classifier_thresholds tamb√©m deve ser fornecido.
        
    classifier_thresholds : array-like, optional, default=None
        Array com thresholds para cria√ß√£o dos bins de classifica√ß√£o.
        Exemplo: [1, 5, 20] cria bins: [0,1), [1,5), [5,20), [20,‚àû).
        Deve estar em ordem crescente e todos os valores > 0.
    
    Returns
    -------
    tuple
        Tupla contendo (model, comparison):
        
        Para modelo √∫nico sem classificador:
        - model : objeto do modelo treinado
        - comparison : pd.DataFrame com compara√ß√£o entre valores reais e preditos
        
        Para modelo √∫nico com classificador:
        - model : dict com chaves 'classifier' e 'regressors' (bins)
        - comparison : pd.DataFrame com compara√ß√£o incluindo predi√ß√µes h√≠bridas
        
        Para bi-model sem classificador:
        - model : dict com chaves 'com_vizinha' e 'sem_vizinha' contendo os modelos
        - comparison : dict com chaves 'com_vizinha' e 'sem_vizinha' contendo as compara√ß√µes
        
        Para bi-model com classificador:
        - model : dict aninhado onde cada tipo cont√©m 'classifier' e 'regressors' (bins)
        - comparison : dict aninhado combinando ambas as estruturas
    
    Raises
    ------
    ValueError
        Se os par√¢metros estiverem fora dos limites v√°lidos, se colunas
        obrigat√≥rias estiverem ausentes, ou se classifier_model e 
        classifier_thresholds n√£o forem consistentes.
        
    TypeError
        Se o Model ou classifier_model n√£o implementarem os m√©todos necess√°rios
        ou se os tipos dos par√¢metros n√£o forem os esperados.
        
    RuntimeError
        Se ocorrer erro durante o treinamento ou salvamento dos modelos.
        
    FileNotFoundError
        Se os diret√≥rios 'models' ou 'comparisons' n√£o existirem.
    
    Examples
    --------
    >>> from sklearn.ensemble import RandomForestRegressor
    >>> from xgboost import XGBClassifier
    >>> 
    >>> # Modelo √∫nico tradicional
    >>> model, comparison = train_model(
    ...     df_estacoes, 
    ...     RandomForestRegressor, 
    ...     model_number=1,
    ...     usar_n_estacoes_vizinhas=2
    ... )
    
    >>> # Modelo h√≠brido (classificador + regressores por bins)
    >>> model, comparison = train_model(
    ...     df_estacoes,
    ...     RandomForestRegressor,
    ...     model_number=2,
    ...     usar_n_estacoes_vizinhas=2,
    ...     classifier_model=XGBClassifier,
    ...     classifier_thresholds=[1, 5, 20]  # Bins: [0,1), [1,5), [5,20), [20,‚àû)
    ... )
    
    >>> # Bi-model + h√≠brido
    >>> model, comparison = train_model(
    ...     df_estacoes,
    ...     RandomForestRegressor,
    ...     model_number=3,
    ...     usar_n_estacoes_vizinhas=3,
    ...     use_bi_model=True,
    ...     classifier_model=XGBClassifier,
    ...     classifier_thresholds=[2, 8, 15],  # Bins: [0,2), [2,8), [8,15), [15,‚àû)
    ...     threshold_prioridade=0.6
    ... )
    
    Notes
    -----
    - A fun√ß√£o salva automaticamente o modelo e compara√ß√£o nos diret√≥rios 'models' e 'comparisons'
    - Requer as fun√ß√µes auxiliares: generate_X_y_train_test, split_com_sem_vizinha, 
      compute_comparison_df, save_model_and_comparison
    - Para bi-model, os dados s√£o separados baseado na prioridade das esta√ß√µes vizinhas
    - Predi√ß√µes negativas s√£o truncadas para 0 por padr√£o (precipita√ß√£o f√≠sica)
    - O undersampling √© aplicado apenas no conjunto de treino, n√£o afetando o conjunto de teste
    - smote_pct_oversampling agora √© uma porcentagem decimal (0.01 = 1% de aumento)
    - smote_pct_undersampling agora √© um multiplicador direto (1.0 = mesmo n√∫mero)
    - Bins s√£o criados como intervalos: [0, t1), [t1, t2), ..., [tn, ‚àû)
    - A predi√ß√£o h√≠brida usa o classificador para determinar o bin e depois o regressor correspondente
    - Cada regressor √© especializado em seu range espec√≠fico de precipita√ß√£o
    """
    
    # Valida√ß√µes b√°sicas
    if not hasattr(Model, '__call__'):
        raise TypeError("Model deve ser uma classe instanci√°vel")
    
    if not isinstance(usar_n_estacoes_vizinhas, int) or usar_n_estacoes_vizinhas < 0:
        raise ValueError("usar_n_estacoes_vizinhas deve ser um inteiro >= 0")
    
    if zero_undersampling_ratio is not None and zero_undersampling_ratio <= 0:
        raise ValueError("zero_undersampling_ratio deve ser None ou um n√∫mero > 0")
    
    if not isinstance(smote_pct_oversampling, (int, float)) or smote_pct_oversampling < 0:
        raise ValueError("smote_pct_oversampling deve ser um n√∫mero >= 0 (ex: 0.01 para 1%)")
    
    if not isinstance(threshold_prioridade, (int, float)) or not (0 <= threshold_prioridade <= 1):
        raise ValueError("threshold_prioridade deve ser um n√∫mero entre 0 e 1")
    
    # Valida√ß√µes do classificador - CORRIGIDAS
    if (classifier_model is None) != (classifier_thresholds is None):
        raise ValueError("classifier_model e classifier_thresholds devem ser fornecidos juntos ou ambos None")
    
    if classifier_model is not None:
        if not hasattr(classifier_model, '__call__'):
            raise TypeError("classifier_model deve ser uma classe instanci√°vel")
        
        if not isinstance(classifier_thresholds, (list, tuple, np.ndarray)):
            raise TypeError("classifier_thresholds deve ser array-like")
        
        classifier_thresholds = np.array(classifier_thresholds)
        
        if len(classifier_thresholds) < 1:
            raise ValueError("classifier_thresholds deve ter pelo menos 1 elemento")
        
        if np.any(classifier_thresholds <= 0):
            raise ValueError("Todos os thresholds devem ser > 0")
        
        if not np.all(classifier_thresholds[:-1] < classifier_thresholds[1:]):
            raise ValueError("classifier_thresholds deve estar em ordem crescente")
    
    if abt_estacoes_vizinhas.empty:
        raise ValueError("DataFrame de entrada n√£o pode estar vazio")
    
    required_columns = ['id_estacao', 'dt_medicao', 'vl_precipitacao']
    missing_cols = [col for col in required_columns if col not in abt_estacoes_vizinhas.columns]
    if missing_cols:
        raise KeyError(f"Colunas obrigat√≥rias n√£o encontradas: {missing_cols}")
    
    os.makedirs('models', exist_ok=True)
    os.makedirs('comparisons', exist_ok=True)
    
    use_classifier = classifier_model is not None
    model_type = f"{'Bi-model' if use_bi_model else '√önico'}{' + H√≠brido' if use_classifier else ''}"
    
    print(f"Modelo {model_number} | {Model.__name__} | {usar_n_estacoes_vizinhas} esta√ß√µes | {model_type}")
    if use_classifier:
        print(f"  Classificador: {classifier_model.__name__} | Thresholds: {list(classifier_thresholds)}")
    
    def _create_target_classes(y_values, thresholds):
        """Cria classes baseadas nos bins definidos pelos thresholds."""
        classes = np.zeros(len(y_values), dtype=int)
        
        # Bin 0: [0, primeiro_threshold)
        # Bin 1: [primeiro_threshold, segundo_threshold)
        # ...
        # Bin n: [ultimo_threshold, ‚àû)
        
        for i, threshold in enumerate(thresholds, 1):
            classes[y_values >= threshold] = i
        
        return classes
    
    def _train_hybrid_model(X_train, X_test, y_train, y_test, model_prefix=""):
        """Treina modelo h√≠brido (classificador + regressores) para um dataset."""
        
        # Preparar dados para classifica√ß√£o
        y_train_classes = _create_target_classes(y_train, classifier_thresholds)
        y_test_classes = _create_target_classes(y_test, classifier_thresholds)
        
        # Remover colunas n√£o-features
        train_cols_to_drop = [col for col in ['id_estacao', 'dt_medicao'] if col in X_train.columns]
        test_cols_to_drop = [col for col in ['id_estacao', 'dt_medicao'] if col in X_test.columns]
        
        X_train_features = X_train.drop(train_cols_to_drop, axis=1)
        X_test_features = X_test.drop(test_cols_to_drop, axis=1)
        
        # Treinar classificador
        classifier = classifier_model()
        classifier.fit(X_train_features, y_train_classes)
        
        # Predi√ß√µes do classificador
        y_pred_classes = classifier.predict(X_test_features)
        
        # Treinar regressores para cada bin
        regressors = {}
        n_bins = len(classifier_thresholds) + 1
        
        for bin_idx in range(n_bins):
            # Definir limites do bin
            if bin_idx == 0:
                # Bin 0: [0, primeiro_threshold)
                lower_bound = 0
                upper_bound = classifier_thresholds[0]
                mask_train = (y_train >= lower_bound) & (y_train < upper_bound)
                bin_name = f"bin_{bin_idx}"
                bin_desc = f"[{lower_bound}, {upper_bound})"
            elif bin_idx == n_bins - 1:
                # √öltimo bin: [ultimo_threshold, ‚àû)
                lower_bound = classifier_thresholds[-1]
                mask_train = y_train >= lower_bound
                bin_name = f"bin_{bin_idx}"
                bin_desc = f"[{lower_bound}, ‚àû)"
            else:
                # Bins intermedi√°rios: [threshold_i, threshold_i+1)
                lower_bound = classifier_thresholds[bin_idx - 1]
                upper_bound = classifier_thresholds[bin_idx]
                mask_train = (y_train >= lower_bound) & (y_train < upper_bound)
                bin_name = f"bin_{bin_idx}"
                bin_desc = f"[{lower_bound}, {upper_bound})"
            
            if np.sum(mask_train) == 0:
                print(f"  ‚ö†Ô∏è  {model_prefix}Bin {bin_idx} {bin_desc}: Nenhum dado de treino dispon√≠vel")
                continue
            
            X_train_bin = X_train_features[mask_train]
            y_train_bin = y_train[mask_train]
            
            # Treinar regressor para este bin
            regressor = Model()
            regressor.fit(X_train_bin, y_train_bin)
            regressors[bin_name] = regressor
            
            print(f"  ‚úì {model_prefix}Bin {bin_idx} {bin_desc}: {np.sum(mask_train)} amostras de treino")
        
        # Fazer predi√ß√µes h√≠bridas
        y_pred_hybrid = np.zeros(len(y_test))
        
        for i, predicted_class in enumerate(y_pred_classes):
            bin_name = f"bin_{predicted_class}"
            
            if bin_name in regressors:
                # Fazer predi√ß√£o com o regressor do bin correspondente
                sample_features = X_test_features.iloc[i:i+1]
                prediction = regressors[bin_name].predict(sample_features)[0]
            else:
                # Fallback para o regressor do bin 0 se dispon√≠vel
                if "bin_0" in regressors:
                    sample_features = X_test_features.iloc[i:i+1]
                    prediction = regressors["bin_0"].predict(sample_features)[0]
                else:
                    # Usar qualquer regressor dispon√≠vel como √∫ltimo recurso
                    if regressors:
                        available_bin = list(regressors.keys())[0]
                        sample_features = X_test_features.iloc[i:i+1]
                        prediction = regressors[available_bin].predict(sample_features)[0]
                    else:
                        prediction = 0.0
            
            y_pred_hybrid[i] = prediction
        
        if truncate_to_non_negative_target:
            y_pred_hybrid = np.clip(y_pred_hybrid, a_min=0, a_max=None)
        
        # Criar estrutura do modelo h√≠brido
        hybrid_model = {
            'classifier': classifier,
            'regressors': regressors
        }
        
        # Calcular compara√ß√£o incluindo informa√ß√µes do classificador
        comparison = compute_comparison_df(X_test, y_test, y_pred_hybrid)
        comparison['predicted_class'] = y_pred_classes
        comparison['actual_class'] = y_test_classes
        
        return hybrid_model, comparison
    
    def _train_single_model(X_train, X_test, y_train, y_test):
        """Treina modelo √∫nico (regress√£o tradicional)."""
        train_cols_to_drop = [col for col in ['id_estacao', 'dt_medicao'] if col in X_train.columns]
        test_cols_to_drop = [col for col in ['id_estacao', 'dt_medicao'] if col in X_test.columns]
        
        model = Model()
        X_train_features = X_train.drop(train_cols_to_drop, axis=1)
        model.fit(X_train_features, y_train)
        
        X_test_features = X_test.drop(test_cols_to_drop, axis=1)
        y_pred = model.predict(X_test_features)
        
        if truncate_to_non_negative_target:
            y_pred = np.clip(y_pred, a_min=0, a_max=None)
        
        comparison = compute_comparison_df(X_test, y_test, y_pred)
        return model, comparison
    
    if not use_bi_model:
        # Modelo √∫nico (com ou sem classificador)
        X_train, X_test, y_train, y_test = generate_X_y_train_test(
            abt_estacoes_vizinhas,
            usar_n_estacoes_vizinhas=usar_n_estacoes_vizinhas,
            zero_undersampling_ratio=zero_undersampling_ratio,
            smote_oversampling=smote_oversampling,
            smote_threshold=smote_threshold,
            smote_pct_oversampling=smote_pct_oversampling,
            smote_pct_undersampling=smote_pct_undersampling,
            smote_k_neighbors=smote_k_neighbors,
            smote_explanatory_variables=smote_explanatory_variables,
            smote_constraint_columns=smote_constraint_columns,
            smote_relevance_function=None,
            percent_datetime_partitioning_split=percent_datetime_partitioning_split,
            random_state=smote_random_state
        )
        
        if use_classifier:
            model, comparison = _train_hybrid_model(X_train, X_test, y_train, y_test)
        else:
            model, comparison = _train_single_model(X_train, X_test, y_train, y_test)
    
    else:
        # Bi-model (com ou sem classificador)
        abt_com_vizinha, abt_sem_vizinha = split_com_sem_vizinha(
            abt_estacoes_vizinhas, threshold_prioridade
        )
        
        X_train, X_test, y_train, y_test, model, comparison = {}, {}, {}, {}, {}, {}
        
        for tipo in tqdm(['com_vizinha', 'sem_vizinha'], desc="Preparando dados"):
            abt_data = abt_com_vizinha if tipo == 'com_vizinha' else abt_sem_vizinha
            
            if len(abt_data) == 0:
                print(f"  ‚ö†Ô∏è  Tipo '{tipo}': Nenhum dado dispon√≠vel")
                continue
                
            X_train[tipo], X_test[tipo], y_train[tipo], y_test[tipo] = generate_X_y_train_test(
                abt_data,
                usar_n_estacoes_vizinhas=usar_n_estacoes_vizinhas,
                zero_undersampling_ratio=zero_undersampling_ratio,
                smote_oversampling=smote_oversampling,
                smote_threshold=smote_threshold,
                smote_pct_oversampling=smote_pct_oversampling,
                smote_pct_undersampling=smote_pct_undersampling,
                smote_k_neighbors=smote_k_neighbors,
                smote_constraint_columns=smote_constraint_columns,
                smote_relevance_function=None,
                smote_explanatory_variables=smote_explanatory_variables,
                percent_datetime_partitioning_split=percent_datetime_partitioning_split,
                random_state=smote_random_state
            )
        
        for tipo in tqdm(['com_vizinha', 'sem_vizinha'], desc="Treinando modelos"):
            if tipo not in X_train or len(X_train[tipo]) == 0:
                continue
            
            model_prefix = f"[{tipo}] "
            
            if use_classifier:
                model[tipo], comparison[tipo] = _train_hybrid_model(
                    X_train[tipo], X_test[tipo], y_train[tipo], y_test[tipo], model_prefix
                )
            else:
                model[tipo], comparison[tipo] = _train_single_model(
                    X_train[tipo], X_test[tipo], y_train[tipo], y_test[tipo]
                )
    
    model_path = f'models/model_{model_number}.pkl'
    comparison_path = f'comparisons/comparison_{model_number}.pkl'
    
    save_model_and_comparison(model, comparison, model_path, comparison_path)
    
    print(f"‚úÖ Modelo {model_number} salvo")
    
    return model, comparison