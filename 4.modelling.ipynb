{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4dabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulação de dados\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Tratamento de dados\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# Visualização\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "# Algoritmos\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor, ExtraTreesClassifier\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "\n",
    "# Métricas de validação\n",
    "from metrics import MAE,RMSE,R2_determinacao,PSC_A,PCC_A,PMC_A\n",
    "\n",
    "# Salvar e importar modelos e métricas\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Configurações de bibliotecas\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "# Importando o database de dados de modelagem\n",
    "final_db = duckdb.connect(database='final_db')\n",
    "\n",
    "# Defininindo os tipos de variáveis presentes no dataset\n",
    "n_vizinhas_disponiveis = 10\n",
    "\n",
    "list_key = ['id_estacao','dt_medicao']\n",
    "\n",
    "list_features_geoespaciais = ['latitude','longitude','vl_declividade','vl_altitude','vl_distancia_oceano','vl_aspecto_relevo']\n",
    "\n",
    "list_features_estacoes_temperatura = ['vl_temperatura_maxima','vl_temperatura_media','vl_temperatura_minima']\n",
    "list_features_estacoes_umidade = ['vl_umidade_relativa_maxima','vl_umidade_relativa_media','vl_umidade_relativa_minima']\n",
    "list_features_estacoes_vento = ['vl_velocidade_vento_2m_maxima','vl_velocidade_vento_2m_media','vl_velocidade_vento_10m_media']\n",
    "list_features_estacoes = list_features_estacoes_temperatura + list_features_estacoes_umidade + list_features_estacoes_vento\n",
    "\n",
    "list_features_chirps = ['vl_precipitacao_chirps']\n",
    "list_features_cpc = ['vl_precipitacao_cpc','vl_temperatura_maxima_cpc','vl_temperatura_minima_cpc']\n",
    "list_features_gpm_final_run = ['vl_precipitacao_gpm_final_run']\n",
    "list_features_gpm_late_run = ['vl_precipitacao_gpm_late_run']\n",
    "list_features_power = ['vl_precipitacao_power','vl_temperatura_maxima_2m_K_power','vl_temperatura_media_2m_K_power','vl_temperatura_minima_2m_K_power','vl_umidade_relativa_2m_power','vl_pressao_nivel_superficie_power','vl_irradiancia_allsky_power','vl_direcao_vento_10m_power','vl_direcao_vento_2m_power','vl_temperatura_orvalho_2m_K_power','vl_vento_10m_power','vl_vento_medio_2m_power','vl_vento_maximo_2m_power','vl_vento_maximo_10m_power']\n",
    "list_features_produtos = list_features_chirps + list_features_cpc + list_features_gpm_final_run + list_features_gpm_late_run + list_features_power\n",
    "\n",
    "list_vizinhas_aux = sum([[f'vl_correlacao_estacao_vizinha_{i}',f'pct_intersecao_precipitacao_vizinha_{i}',f'vl_distancia_km_vizinha_{i}',f'vl_prioridade_vizinha_{i}',f'vl_precipitacao_vizinha_{i}']for i in range(1, n_vizinhas_disponiveis+1)], [])\n",
    "list_features_vizinhas = [f'vl_precipitacao_vizinha_{i}' for i in range(1,n_vizinhas_disponiveis+1)]\n",
    "\n",
    "list_features_target = ['vl_precipitacao','vl_precipitacao_log']\n",
    "\n",
    "list_split_column = ['percentil_temporal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde37957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oi(a,b):\n",
    "    print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5263d8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a' in oi.__code__.co_varnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e8e658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__builtins__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__closure__',\n",
       " '__code__',\n",
       " '__defaults__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__globals__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__kwdefaults__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(oi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea406eda",
   "metadata": {},
   "source": [
    "# MODELOS 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8bed8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os modelos 1 são os mais simples. Esses modelos são compostos por um único algoritmo de regressão, sempre usando XGBoost. A partição já é a padrão, de 70-30 por estação, e não há tentativas \n",
      "de modificação da target\n",
      "\n",
      "> Sem pré modelo de classificação\n",
      "> Sem modelo especializado\n",
      "> Apenas algoritmo de XGBoost\n",
      "> Partição padrão\n",
      "> Sem modificações da target\n",
      "> Testando diferentes combinações de variáveis explicativas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Os modelos 1 são os mais simples. Esses modelos são compostos por um único algoritmo de regressão, sempre usando XGBoost. A partição já é a padrão, de 70-30 por estação, e não há tentativas \n",
    "de modificação da target\\n\n",
    "> Sem pré modelo de classificação\n",
    "> Sem modelo especializado\n",
    "> Apenas algoritmo de XGBoost\n",
    "> Partição padrão\n",
    "> Sem modificações da target\n",
    "> Testando diferentes combinações de variáveis explicativas\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd3416cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImportBase_Modelo1(final_db=final_db,table_name='abt_base'):\n",
    "    df = final_db.execute(f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM {table_name}\n",
    "    \"\"\").fetch_df()\n",
    "\n",
    "    return df\n",
    "\n",
    "def SplitTreinoTeste_Modelo1(df_base,pct_split,coluna_percentil_temporal='percentil_temporal'):\n",
    "  df_treino = df_base.loc[df_base[coluna_percentil_temporal]<=pct_split]\n",
    "  df_teste = df_base.loc[df_base[coluna_percentil_temporal]>pct_split]\n",
    "  return df_treino,df_teste\n",
    "\n",
    "def PrepararBaseTreino(df_treino,list_features,target):\n",
    "   df_X_treino = df_treino.loc[:,list_features]\n",
    "   df_y_treino = df_treino.loc[:,[target]]\n",
    "   return df_X_treino,df_y_treino\n",
    "\n",
    "def TreinarAlgoritmo_Modelo1(df_X_treino,df_y_treino,Algoritmo):\n",
    "   alg = Algoritmo()\n",
    "   alg.fit(df_X_treino,df_y_treino)\n",
    "   return alg\n",
    "\n",
    "def RealizarPredicaoTeste(df_test,list_features,target,modelo,modelo_number='1_1'):\n",
    "   df_X_test = df_test[list_features]\n",
    "   df_y_pred = modelo.predict(df_X_test)\n",
    "   df_validacao = df_test.copy()\n",
    "   df_validacao[f'{target}_modelo_{modelo_number}'] = df_y_pred\n",
    "   return df_validacao\n",
    "\n",
    "def CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva):\n",
    "   metricas_modelo = {\n",
    "      'MAE':MAE(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "      'RMSE':RMSE(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "      'R2':R2_determinacao(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "      'PSC_A':PSC_A(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}'],psc_a_max_chuva),\n",
    "      'PCC_A':PCC_A(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}'],pcc_a_erro),\n",
    "      'PMC_A':PMC_A(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}'],pmc_a_erro,pmc_a_min_chuva)\n",
    "   }\n",
    "\n",
    "   return metricas_modelo\n",
    "\n",
    "def SalvarValidacaoModeloMetricas_Modelo1(df_validacao,modelo_1_1,metricas_modelo_1_1,target,modelo_number,final_db=final_db):\n",
    "\n",
    "    df_validacao_key_target_pred = df_validacao[list_key+[target,f'{target}_modelo_{modelo_number}']]\n",
    "\n",
    "    final_db.execute(\n",
    "    f\"\"\"\n",
    "    CREATE OR REPLACE TABLE tb_validacao_modelo_{modelo_number} AS (\n",
    "    SELECT * FROM df_validacao_key_target_pred)\n",
    "    \"\"\")\n",
    "\n",
    "    with open(f'modelos_finais/modelo_{modelo_number}.pkl','wb') as f:\n",
    "        pickle.dump(modelo_1_1,f)\n",
    "\n",
    "    with open(f'modelos_finais/metricas_{modelo_number}.json', 'w') as f:\n",
    "        json.dump(metricas_modelo_1_1, f, indent=4)\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb00a527",
   "metadata": {},
   "source": [
    "## Modelo 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77f443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6020890d130d488baccf1ccc6e0b4699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '1_1'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao'\n",
    "list_features_modelo_1_1 = list_features_geoespaciais + list_features_estacoes\n",
    "Algoritmo = XGBRegressor\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo1()\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo1(df_base,pct_train_test_split)\n",
    "df_X_treino,df_y_treino = PrepararBaseTreino(df_treino,list_features_modelo_1_1,target)\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo_1_1 = TreinarAlgoritmo_Modelo1(df_X_treino,df_y_treino,Algoritmo)\n",
    "\n",
    "# Validando\n",
    "df_validacao = RealizarPredicaoTeste(df_teste,list_features_modelo_1_1,target,modelo_1_1,modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_1_1 = CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo1(df_validacao,modelo_1_1,metricas_modelo_1_1,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f3e12a",
   "metadata": {},
   "source": [
    "## Modelo 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9946e057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb4fc0854594aaeb77344bd2cc1e146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '1_2'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao'\n",
    "list_features_modelo_1_2 = list_features_geoespaciais + list_features_estacoes + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo1()\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo1(df_base,pct_train_test_split)\n",
    "df_X_treino,df_y_treino = PrepararBaseTreino(df_treino,list_features_modelo_1_2,target)\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo_1_2 = TreinarAlgoritmo_Modelo1(df_X_treino,df_y_treino,Algoritmo)\n",
    "\n",
    "# Validando\n",
    "df_validacao = RealizarPredicaoTeste(df_teste,list_features_modelo_1_2,target,modelo_1_2,modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_1_2 = CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo1(df_validacao,modelo_1_2,metricas_modelo_1_2,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4686c278",
   "metadata": {},
   "source": [
    "## Modelo 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47556faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9651a107982e417aad53b4ebb0070069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '1_3'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao'\n",
    "list_features_modelo_1_3 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas\n",
    "Algoritmo = XGBRegressor\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo1()\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo1(df_base,pct_train_test_split)\n",
    "df_X_treino,df_y_treino = PrepararBaseTreino(df_treino,list_features_modelo_1_3,target)\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo_1_3 = TreinarAlgoritmo_Modelo1(df_X_treino,df_y_treino,Algoritmo)\n",
    "\n",
    "# Validando\n",
    "df_validacao = RealizarPredicaoTeste(df_teste,list_features_modelo_1_3,target,modelo_1_3,modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_1_3 = CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo1(df_validacao,modelo_1_3,metricas_modelo_1_3,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71de9de3",
   "metadata": {},
   "source": [
    "## Modelo 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "963e03b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9810b0aaffce4e42b43deaada2caf902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '1_4'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao'\n",
    "list_features_modelo_1_4 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo1()\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo1(df_base,pct_train_test_split)\n",
    "df_X_treino,df_y_treino = PrepararBaseTreino(df_treino,list_features_modelo_1_4,target)\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo_1_4 = TreinarAlgoritmo_Modelo1(df_X_treino,df_y_treino,Algoritmo)\n",
    "\n",
    "# Validando\n",
    "df_validacao = RealizarPredicaoTeste(df_teste,list_features_modelo_1_4,target,modelo_1_4,modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_1_4 = CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo1(df_validacao,modelo_1_4,metricas_modelo_1_4,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da43718",
   "metadata": {},
   "source": [
    "# MODELOS 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "190b97af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os modelos 2 são iguais aos modelos 1, porém com a variável target logarítmica. Esses modelos são compostos por um único algoritmo de regressão, sempre usando XGBoost. A partição já é a padrão, de 70-30 por estação.\n",
      "\n",
      "> Sem pré modelo de classificação\n",
      "> Sem modelo especializado\n",
      "> Apenas algoritmo de XGBoost\n",
      "> Partição padrão\n",
      "> Target Logarítmica\n",
      "> Testando diferentes combinações de variáveis explicativas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Os modelos 2 são iguais aos modelos 1, porém com a variável target logarítmica. Esses modelos são compostos por um único algoritmo de regressão, sempre usando XGBoost. A partição já é a padrão, de 70-30 por estação.\\n\n",
    "> Sem pré modelo de classificação\n",
    "> Sem modelo especializado\n",
    "> Apenas algoritmo de XGBoost\n",
    "> Partição padrão\n",
    "> Target Logarítmica\n",
    "> Testando diferentes combinações de variáveis explicativas\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2ae7f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImportBase_Modelo2(final_db=final_db,table_name='abt_base'):\n",
    "    df = final_db.execute(f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM {table_name}\n",
    "    \"\"\").fetch_df()\n",
    "\n",
    "    return df\n",
    "\n",
    "def SplitTreinoTeste_Modelo2(df_base,pct_split,coluna_percentil_temporal='percentil_temporal'):\n",
    "  df_treino = df_base.loc[df_base[coluna_percentil_temporal]<=pct_split]\n",
    "  df_teste = df_base.loc[df_base[coluna_percentil_temporal]>pct_split]\n",
    "  return df_treino,df_teste\n",
    "\n",
    "def PrepararBaseTreino(df_treino,list_features,target):\n",
    "   df_X_treino = df_treino.loc[:,list_features]\n",
    "   df_y_treino = df_treino.loc[:,[target]]\n",
    "   return df_X_treino,df_y_treino\n",
    "\n",
    "def TreinarAlgoritmo_Modelo2(df_X_treino,df_y_treino,Algoritmo):\n",
    "   alg = Algoritmo()\n",
    "   alg.fit(df_X_treino,df_y_treino)\n",
    "   return alg\n",
    "\n",
    "def RealizarPredicaoTeste_Modelo2(df_test,list_features,target,target_original,modelo,modelo_number):\n",
    "   df_X_test = df_test[list_features]\n",
    "   df_y_pred = modelo.predict(df_X_test)\n",
    "   df_validacao = df_test.copy()\n",
    "   df_validacao[f'{target}_modelo_{modelo_number}'] = df_y_pred\n",
    "   df_validacao[f'{target_original}_modelo_{modelo_number}'] = np.exp(df_validacao[f'{target}_modelo_{modelo_number}'])\n",
    "   return df_validacao\n",
    "\n",
    "def CalcularMetricasTeste_Modelo2(df_validacao,target_original,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva):\n",
    "   metricas_modelo = {\n",
    "      'MAE':MAE(df_validacao[target_original],df_validacao[f'{target_original}_modelo_{modelo_number}']),\n",
    "      'RMSE':RMSE(df_validacao[target_original],df_validacao[f'{target_original}_modelo_{modelo_number}']),\n",
    "      'R2':R2_determinacao(df_validacao[target_original],df_validacao[f'{target_original}_modelo_{modelo_number}']),\n",
    "      'PSC_A':PSC_A(df_validacao[target_original],df_validacao[f'{target_original}_modelo_{modelo_number}'],psc_a_max_chuva),\n",
    "      'PCC_A':PCC_A(df_validacao[target_original],df_validacao[f'{target_original}_modelo_{modelo_number}'],pcc_a_erro),\n",
    "      'PMC_A':PMC_A(df_validacao[target_original],df_validacao[f'{target_original}_modelo_{modelo_number}'],pmc_a_erro,pmc_a_min_chuva)\n",
    "   }\n",
    "\n",
    "   return metricas_modelo\n",
    "\n",
    "def SalvarValidacaoModeloMetricas_Modelo2(df_validacao,modelo,metricas_modelo,target,target_original,modelo_number,final_db=final_db):\n",
    "\n",
    "    df_validacao_key_target_pred = df_validacao[list_key+[target_original,f'{target_original}_modelo_{modelo_number}']+[target,f'{target}_modelo_{modelo_number}']]\n",
    "\n",
    "    final_db.execute(\n",
    "    f\"\"\"\n",
    "    CREATE OR REPLACE TABLE tb_validacao_modelo_{modelo_number} AS (\n",
    "    SELECT * FROM df_validacao_key_target_pred)\n",
    "    \"\"\")\n",
    "\n",
    "    with open(f'modelos_finais/modelo_{modelo_number}.pkl','wb') as f:\n",
    "        pickle.dump(modelo,f)\n",
    "\n",
    "    with open(f'modelos_finais/metricas_{modelo_number}.json', 'w') as f:\n",
    "        json.dump(metricas_modelo, f, indent=4)\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab37d41",
   "metadata": {},
   "source": [
    "## Modelo 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "367aad9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480bb3916df049edad793ca667ec02cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '2_1'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao_log'\n",
    "target_original = 'vl_precipitacao'\n",
    "list_features_modelo_2_1 = list_features_geoespaciais + list_features_estacoes\n",
    "Algoritmo = XGBRegressor\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo2()\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo2(df_base,pct_train_test_split)\n",
    "df_X_treino,df_y_treino = PrepararBaseTreino(df_treino,list_features_modelo_2_1,target)\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo_2_1 = TreinarAlgoritmo_Modelo2(df_X_treino,df_y_treino,Algoritmo)\n",
    "\n",
    "# Validando\n",
    "df_validacao = RealizarPredicaoTeste_Modelo2(df_teste,list_features_modelo_2_1,target,target_original,modelo_2_1,modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_2_1 = CalcularMetricasTeste_Modelo2(df_validacao,target_original,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo2(df_validacao,modelo_2_1,metricas_modelo_2_1,target,target_original,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18550c3",
   "metadata": {},
   "source": [
    "## Modelo 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb8ed78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_number = '2_2'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao_log'\n",
    "target_original = 'vl_precipitacao'\n",
    "list_features_modelo_2_2 = list_features_geoespaciais + list_features_estacoes + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo2()\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo2(df_base,pct_train_test_split)\n",
    "df_X_treino,df_y_treino = PrepararBaseTreino(df_treino,list_features_modelo_2_2,target)\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo_2_2 = TreinarAlgoritmo_Modelo2(df_X_treino,df_y_treino,Algoritmo)\n",
    "\n",
    "# Validando\n",
    "df_validacao = RealizarPredicaoTeste_Modelo2(df_teste,list_features_modelo_2_2,target,target_original,modelo_2_2,modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_2_2 = CalcularMetricasTeste_Modelo2(df_validacao,target_original,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo2(df_validacao,modelo_2_2,metricas_modelo_2_2,target,target_original,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3425a4b9",
   "metadata": {},
   "source": [
    "## Modelo 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c765d638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b19267228946fd9bd8e9174e3c42da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '2_3'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao_log'\n",
    "target_original = 'vl_precipitacao'\n",
    "list_features_modelo_2_3 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas\n",
    "Algoritmo = XGBRegressor\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo2()\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo2(df_base,pct_train_test_split)\n",
    "df_X_treino,df_y_treino = PrepararBaseTreino(df_treino,list_features_modelo_2_3,target)\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo_2_3 = TreinarAlgoritmo_Modelo2(df_X_treino,df_y_treino,Algoritmo)\n",
    "\n",
    "# Validando\n",
    "df_validacao = RealizarPredicaoTeste_Modelo2(df_teste,list_features_modelo_2_3,target,target_original,modelo_2_3,modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_2_3 = CalcularMetricasTeste_Modelo2(df_validacao,target_original,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo2(df_validacao,modelo_2_3,metricas_modelo_2_3,target,target_original,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b45a33",
   "metadata": {},
   "source": [
    "## Modelo 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e65ac95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a1086c20364001b93bea935dba9d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '2_4'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao_log'\n",
    "target_original = 'vl_precipitacao'\n",
    "list_features_modelo_2_4 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo2()\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo2(df_base,pct_train_test_split)\n",
    "df_X_treino,df_y_treino = PrepararBaseTreino(df_treino,list_features_modelo_2_4,target)\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo_2_4 = TreinarAlgoritmo_Modelo2(df_X_treino,df_y_treino,Algoritmo)\n",
    "\n",
    "# Validando\n",
    "df_validacao = RealizarPredicaoTeste_Modelo2(df_teste,list_features_modelo_2_4,target,target_original,modelo_2_4,modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_2_4 = CalcularMetricasTeste_Modelo2(df_validacao,target_original,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo2(df_validacao,modelo_2_4,metricas_modelo_2_4,target,target_original,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c0a616",
   "metadata": {},
   "source": [
    "# MODELOS 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94991be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os modelos 3 são iguais aos modelos 1_4, porém com separação entre modelo especializado e modelo geral. Esses modelos são compostos por dois algoritmo de regressão, sempre usando XGBoost. A partição já é a padrão, de 70-30 por estação.\n",
      "\n",
      "> Sem pré modelo de classificação\n",
      "> Modelo especializado, testando diferentes thresholds\n",
      "> Apenas algoritmo de XGBoost\n",
      "> Partição padrão\n",
      "> Target padrão\n",
      "> Usando todas as variáveis explicativas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Os modelos 3 são iguais aos modelos 1_4, porém com separação entre modelo especializado e modelo geral. Esses modelos são compostos por dois algoritmo de regressão, sempre usando XGBoost. A partição já é a padrão, de 70-30 por estação.\\n\n",
    "> Sem pré modelo de classificação\n",
    "> Modelo especializado, testando diferentes thresholds\n",
    "> Apenas algoritmo de XGBoost\n",
    "> Partição padrão\n",
    "> Target padrão\n",
    "> Usando todas as variáveis explicativas\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5caa23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImportBase_Modelo3(final_db=final_db,table_name='abt_base'):\n",
    "    df = final_db.execute(f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM {table_name}\n",
    "    \"\"\").fetch_df()\n",
    "\n",
    "    return df\n",
    "\n",
    "def SepararBaseEspecializadoGeral_Modelo3(df_base,coluna_vl_prioridade_vizinha,threshold_modelo_especializado):\n",
    "    df_base_especializado = df_base.loc[df_base[coluna_vl_prioridade_vizinha]>=threshold_modelo_especializado]\n",
    "    df_base_geral = df_base.copy()\n",
    "    return df_base_geral,df_base_especializado\n",
    "\n",
    "def SplitTreinoTeste_Modelo3(df_base_geral,df_base_especializado,pct_split,coluna_percentil_temporal='percentil_temporal'):\n",
    "  df_treino_especializado = df_base_especializado.loc[df_base_especializado[coluna_percentil_temporal]<=pct_split]\n",
    "  df_teste_especializado = df_base_especializado.loc[df_base_especializado[coluna_percentil_temporal]>pct_split]\n",
    "\n",
    "  df_treino_geral = df_base_geral.loc[df_base_geral[coluna_percentil_temporal]<=pct_split]\n",
    "  df_teste_geral = df_base_geral.loc[df_base_geral[coluna_percentil_temporal]>pct_split]\n",
    "  return df_treino_especializado,df_teste_especializado,df_treino_geral,df_teste_geral\n",
    "\n",
    "def PrepararBaseTreino(df_treino,list_features,target):\n",
    "   df_X_treino = df_treino.loc[:,list_features]\n",
    "   df_y_treino = df_treino.loc[:,[target]]\n",
    "   return df_X_treino,df_y_treino\n",
    "\n",
    "def TreinarAlgoritmo_Modelo3(df_X_treino,df_y_treino,Algoritmo):\n",
    "   alg = Algoritmo()\n",
    "   alg.fit(df_X_treino,df_y_treino)\n",
    "   return alg\n",
    "\n",
    "def RealizarPredicaoTeste_Modelo3(df_test,list_features,target,modelo,modelo_number,tipo_modelo):\n",
    "   df_X_test = df_test[list_features]\n",
    "   df_y_pred = modelo.predict(df_X_test)\n",
    "   df_validacao = df_test.copy()\n",
    "   df_validacao[f'{target}_modelo_{modelo_number}_{tipo_modelo}'] = df_y_pred\n",
    "   return df_validacao\n",
    "\n",
    "def CalcularMetricasTeste_Modelo3(df_validacao_geral,df_validacao_especializado,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva):\n",
    "    df_validacao_all = df_validacao_geral[['id_estacao','dt_medicao',f'vl_precipitacao_modelo_{modelo_number}_geral','vl_precipitacao']] \\\n",
    "        .merge(df_validacao_especializado[['id_estacao','dt_medicao',f'vl_precipitacao_modelo_{modelo_number}_especializado']],on=['id_estacao','dt_medicao'],how='left')\n",
    "\n",
    "    df_validacao_all[f'vl_precipitacao_modelo_{modelo_number}'] = df_validacao_all[f'vl_precipitacao_modelo_{modelo_number}_especializado'].fillna(df_validacao_all[f'vl_precipitacao_modelo_{modelo_number}_geral'])\n",
    "    df_validacao = df_validacao_all\n",
    "    metricas_modelo = {\n",
    "        'MAE':MAE(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "        'RMSE':RMSE(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "        'R2':R2_determinacao(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "        'PSC_A':PSC_A(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}'],psc_a_max_chuva),\n",
    "        'PCC_A':PCC_A(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}'],pcc_a_erro),\n",
    "        'PMC_A':PMC_A(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}'],pmc_a_erro,pmc_a_min_chuva)\n",
    "    }\n",
    "    return metricas_modelo,df_validacao\n",
    "\n",
    "def SalvarValidacaoModeloMetricas_Modelo3(df_validacao,modelo_geral,modelo_especializado,metricas_modelo,target,modelo_number,final_db=final_db):\n",
    "\n",
    "    df_validacao_key_target_pred = df_validacao[list_key+[target,f'{target}_modelo_{modelo_number}']]\n",
    "\n",
    "    final_db.execute(\n",
    "    f\"\"\"\n",
    "    CREATE OR REPLACE TABLE tb_validacao_modelo_{modelo_number} AS (\n",
    "    SELECT * FROM df_validacao_key_target_pred)\n",
    "    \"\"\")\n",
    "\n",
    "    with open(f'modelos_finais/modelo_{modelo_number}_geral.pkl','wb') as f:\n",
    "        pickle.dump(modelo_geral,f)\n",
    "\n",
    "    with open(f'modelos_finais/modelo_{modelo_number}_especializado.pkl','wb') as f:\n",
    "        pickle.dump(modelo_especializado,f)\n",
    "\n",
    "    with open(f'modelos_finais/metricas_{modelo_number}.json', 'w') as f:\n",
    "        json.dump(metricas_modelo, f, indent=4)\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070cbe57",
   "metadata": {},
   "source": [
    "## Modelo 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bf2057",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_number = '3_1'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.5\n",
    "target = 'vl_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "list_features_modelo_3 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo3()\n",
    "\n",
    "df_base_geral,df_base_especializado = SepararBaseEspecializadoGeral_Modelo3(df_base,coluna_vl_prioridade_vizinha,threshold_modelo_especializado)\n",
    "df_treino_especializado,df_teste_especializado,df_treino_geral,df_teste_geral = SplitTreinoTeste_Modelo3(df_base_geral,df_base_especializado,pct_train_test_split,coluna_percentil_temporal='percentil_temporal')\n",
    "\n",
    "df_X_treino_especializado,df_y_treino_especializado = PrepararBaseTreino(df_treino_especializado,list_features_modelo_3,target)\n",
    "df_X_treino_geral,df_y_treino_geral = PrepararBaseTreino(df_teste_especializado,list_features_modelo_3,target)\n",
    "\n",
    "# Treinando os modelos especializados e geral\n",
    "modelo_3_1_especializado = TreinarAlgoritmo_Modelo3(df_X_treino_especializado,df_y_treino_especializado,Algoritmo)\n",
    "modelo_3_1_geral = TreinarAlgoritmo_Modelo3(df_X_treino_geral,df_y_treino_geral,Algoritmo)\n",
    "\n",
    "# Validando\n",
    "df_validacao_especializado = RealizarPredicaoTeste_Modelo3(df_teste_especializado,list_features_modelo_3,target,modelo_3_1_especializado,modelo_number,'especializado')\n",
    "df_validacao_geral = RealizarPredicaoTeste_Modelo3(df_teste_geral,list_features_modelo_3,target,modelo_3_1_geral,modelo_number,'geral')\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_3_1,df_validacao_all = CalcularMetricasTeste_Modelo3(df_validacao_geral,df_validacao_especializado,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo3(df_validacao_all,modelo_3_1_geral,modelo_3_1_especializado,metricas_modelo_3_1,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477288b0",
   "metadata": {},
   "source": [
    "## Modelo 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec2ccfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02d65eba4694b15b1ed873f7f82fe54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '3_2'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.75\n",
    "target = 'vl_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "list_features_modelo_3 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo3()\n",
    "\n",
    "df_base_geral,df_base_especializado = SepararBaseEspecializadoGeral_Modelo3(df_base,coluna_vl_prioridade_vizinha,threshold_modelo_especializado)\n",
    "df_treino_especializado,df_teste_especializado,df_treino_geral,df_teste_geral = SplitTreinoTeste_Modelo3(df_base_geral,df_base_especializado,pct_train_test_split,coluna_percentil_temporal='percentil_temporal')\n",
    "\n",
    "df_X_treino_especializado,df_y_treino_especializado = PrepararBaseTreino(df_treino_especializado,list_features_modelo_3,target)\n",
    "df_X_treino_geral,df_y_treino_geral = PrepararBaseTreino(df_teste_especializado,list_features_modelo_3,target)\n",
    "\n",
    "# Treinando os modelos especializados e geral\n",
    "modelo_3_2_especializado = TreinarAlgoritmo_Modelo3(df_X_treino_especializado,df_y_treino_especializado,Algoritmo)\n",
    "modelo_3_2_geral = TreinarAlgoritmo_Modelo3(df_X_treino_geral,df_y_treino_geral,Algoritmo)\n",
    "\n",
    "# Validando\n",
    "df_validacao_especializado = RealizarPredicaoTeste_Modelo3(df_teste_especializado,list_features_modelo_3,target,modelo_3_2_especializado,modelo_number,'especializado')\n",
    "df_validacao_geral = RealizarPredicaoTeste_Modelo3(df_teste_geral,list_features_modelo_3,target,modelo_3_2_geral,modelo_number,'geral')\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_3_2,df_validacao_all = CalcularMetricasTeste_Modelo3(df_validacao_geral,df_validacao_especializado,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo3(df_validacao_all,modelo_3_2_geral,modelo_3_2_especializado,metricas_modelo_3_2,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d3c2c1",
   "metadata": {},
   "source": [
    "## Modelo 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "513bcd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9696111e7b14470a802f791eaea248f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '3_3'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.9\n",
    "target = 'vl_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "list_features_modelo_3 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo3()\n",
    "\n",
    "df_base_geral,df_base_especializado = SepararBaseEspecializadoGeral_Modelo3(df_base,coluna_vl_prioridade_vizinha,threshold_modelo_especializado)\n",
    "df_treino_especializado,df_teste_especializado,df_treino_geral,df_teste_geral = SplitTreinoTeste_Modelo3(df_base_geral,df_base_especializado,pct_train_test_split,coluna_percentil_temporal='percentil_temporal')\n",
    "\n",
    "df_X_treino_especializado,df_y_treino_especializado = PrepararBaseTreino(df_treino_especializado,list_features_modelo_3,target)\n",
    "df_X_treino_geral,df_y_treino_geral = PrepararBaseTreino(df_teste_especializado,list_features_modelo_3,target)\n",
    "\n",
    "# Treinando os modelos especializados e geral\n",
    "modelo_3_3_especializado = TreinarAlgoritmo_Modelo3(df_X_treino_especializado,df_y_treino_especializado,Algoritmo)\n",
    "modelo_3_3_geral = TreinarAlgoritmo_Modelo3(df_X_treino_geral,df_y_treino_geral,Algoritmo)\n",
    "\n",
    "# Validando\n",
    "df_validacao_especializado = RealizarPredicaoTeste_Modelo3(df_teste_especializado,list_features_modelo_3,target,modelo_3_3_especializado,modelo_number,'especializado')\n",
    "df_validacao_geral = RealizarPredicaoTeste_Modelo3(df_teste_geral,list_features_modelo_3,target,modelo_3_3_geral,modelo_number,'geral')\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_3_3,df_validacao_all = CalcularMetricasTeste_Modelo3(df_validacao_geral,df_validacao_especializado,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo3(df_validacao_all,modelo_3_3_geral,modelo_3_3_especializado,metricas_modelo_3_3,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc44e15a",
   "metadata": {},
   "source": [
    "## Modelo 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432c1a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9380890ee34c90abcdd9d7e2909db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '3_4'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.4\n",
    "target = 'vl_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "list_features_modelo_3 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo3()\n",
    "\n",
    "df_base_geral,df_base_especializado = SepararBaseEspecializadoGeral_Modelo3(df_base,coluna_vl_prioridade_vizinha,threshold_modelo_especializado)\n",
    "df_treino_especializado,df_teste_especializado,df_treino_geral,df_teste_geral = SplitTreinoTeste_Modelo3(df_base_geral,df_base_especializado,pct_train_test_split,coluna_percentil_temporal='percentil_temporal')\n",
    "\n",
    "df_X_treino_especializado,df_y_treino_especializado = PrepararBaseTreino(df_treino_especializado,list_features_modelo_3,target)\n",
    "df_X_treino_geral,df_y_treino_geral = PrepararBaseTreino(df_teste_especializado,list_features_modelo_3,target)\n",
    "\n",
    "# Treinando os modelos especializados e geral\n",
    "modelo_3_4_especializado = TreinarAlgoritmo_Modelo3(df_X_treino_especializado,df_y_treino_especializado,Algoritmo)\n",
    "modelo_3_4_geral = TreinarAlgoritmo_Modelo3(df_X_treino_geral,df_y_treino_geral,Algoritmo)\n",
    "\n",
    "# Validando\n",
    "df_validacao_especializado = RealizarPredicaoTeste_Modelo3(df_teste_especializado,list_features_modelo_3,target,modelo_3_4_especializado,modelo_number,'especializado')\n",
    "df_validacao_geral = RealizarPredicaoTeste_Modelo3(df_teste_geral,list_features_modelo_3,target,modelo_3_4_geral,modelo_number,'geral')\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_3_4,df_validacao_all = CalcularMetricasTeste_Modelo3(df_validacao_geral,df_validacao_especializado,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo3(df_validacao_all,modelo_3_4_geral,modelo_3_4_especializado,metricas_modelo_3_4,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c6f9af",
   "metadata": {},
   "source": [
    "## Modelo 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd47dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8113f0bb6f4169834c7170e92bb40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '3_5'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.3\n",
    "target = 'vl_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "list_features_modelo_3 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo3()\n",
    "\n",
    "df_base_geral,df_base_especializado = SepararBaseEspecializadoGeral_Modelo3(df_base,coluna_vl_prioridade_vizinha,threshold_modelo_especializado)\n",
    "df_treino_especializado,df_teste_especializado,df_treino_geral,df_teste_geral = SplitTreinoTeste_Modelo3(df_base_geral,df_base_especializado,pct_train_test_split,coluna_percentil_temporal='percentil_temporal')\n",
    "\n",
    "df_X_treino_especializado,df_y_treino_especializado = PrepararBaseTreino(df_treino_especializado,list_features_modelo_3,target)\n",
    "df_X_treino_geral,df_y_treino_geral = PrepararBaseTreino(df_teste_especializado,list_features_modelo_3,target)\n",
    "\n",
    "# Treinando os modelos especializados e geral\n",
    "modelo_3_5_especializado = TreinarAlgoritmo_Modelo3(df_X_treino_especializado,df_y_treino_especializado,Algoritmo)\n",
    "modelo_3_5_geral = TreinarAlgoritmo_Modelo3(df_X_treino_geral,df_y_treino_geral,Algoritmo)\n",
    "\n",
    "# Validando\n",
    "df_validacao_especializado = RealizarPredicaoTeste_Modelo3(df_teste_especializado,list_features_modelo_3,target,modelo_3_5_especializado,modelo_number,'especializado')\n",
    "df_validacao_geral = RealizarPredicaoTeste_Modelo3(df_teste_geral,list_features_modelo_3,target,modelo_3_5_geral,modelo_number,'geral')\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_3_5,df_validacao_all = CalcularMetricasTeste_Modelo3(df_validacao_geral,df_validacao_especializado,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo3(df_validacao_all,modelo_3_5_geral,modelo_3_5_especializado,metricas_modelo_3_5,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a1204",
   "metadata": {},
   "source": [
    "# MODELO 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02490922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os modelos 4 são iguais aos modelos 1_4, porém com modelo de pré-classificação. Esses modelos são compostos por um algoritmo de classificação + alguns algoritmos de regressão, sempre usando XGBoost. A partição já é a padrão, de 70-30 por estação., e sem modelos especializados\n",
      "\n",
      "> Com pré modelo de classificação (direto)\n",
      "> Sem modelo especializado\n",
      "> Apenas algoritmo de XGBoost\n",
      "> Partição padrão\n",
      "> Target padrão\n",
      "> Usando todas as variáveis explicativas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Os modelos 4 são iguais aos modelos 1_4, porém com modelo de pré-classificação. Esses modelos são compostos por um algoritmo de classificação + alguns algoritmos de regressão, sempre usando XGBoost. A partição já é a padrão, de 70-30 por estação., e sem modelos especializados\\n\n",
    "> Com pré modelo de classificação (direto)\n",
    "> Sem modelo especializado\n",
    "> Apenas algoritmo de XGBoost\n",
    "> Partição padrão\n",
    "> Target padrão\n",
    "> Usando todas as variáveis explicativas\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fbc49b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImportBase_Modelo4(final_db=final_db,table_name='abt_base'):\n",
    "    df = final_db.execute(f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM {table_name}\n",
    "    \"\"\").fetch_df()\n",
    "\n",
    "    return df\n",
    "\n",
    "def SplitTreinoTeste_Modelo4(df_base,pct_split,coluna_percentil_temporal='percentil_temporal'):\n",
    "  df_treino = df_base.loc[df_base[coluna_percentil_temporal]<=pct_split]\n",
    "  df_teste = df_base.loc[df_base[coluna_percentil_temporal]>pct_split]\n",
    "  return df_treino,df_teste\n",
    "\n",
    "def CriarColunaClasse_Modelo4(df_base,dict_classes):\n",
    "    df_base['classe_precipitacao'] = df_base['vl_precipitacao'].apply(\n",
    "        lambda x: next((classe for classe, (limite_inf, limite_sup) in dict_classes.items()\n",
    "                        if limite_inf <= x < limite_sup), None)\n",
    "    )\n",
    "\n",
    "    return df_base\n",
    "\n",
    "def PrepararBaseTreino(df_treino,list_features,target):\n",
    "   df_X_treino = df_treino.loc[:,list_features]\n",
    "   df_y_treino = df_treino.loc[:,[target]]\n",
    "   return df_X_treino,df_y_treino\n",
    "\n",
    "def TreinarAlgoritmo_Modelo4(df_X_treino,df_y_treino,Algoritmo):\n",
    "   alg = Algoritmo()\n",
    "   alg.fit(df_X_treino,df_y_treino)\n",
    "   return alg\n",
    "\n",
    "def PreverClasseTeste_Modelo4(df_teste, list_features, modelo_classificacao, nome_coluna_classe_predita='classe_predita'):\n",
    "    df_teste = df_teste.copy()\n",
    "    df_X_teste_classificacao = df_teste[list_features]\n",
    "    df_teste[nome_coluna_classe_predita] = modelo_classificacao.predict(df_X_teste_classificacao)\n",
    "    return df_teste\n",
    "\n",
    "def RealizarPredicaoTeste_Modelo4(df_test,list_features,target,dict_modelos_regressao,modelo_number,coluna_classe_predita='classe_predita'):\n",
    "    \n",
    "    df_test = df_test.copy()\n",
    "    dict_validacao = {}\n",
    "\n",
    "    for classe, modelo in dict_modelos_regressao.items():\n",
    "        df_teste_classe = df_test.loc[df_test[coluna_classe_predita] == classe]\n",
    "\n",
    "        if len(df_teste_classe) == 0:\n",
    "            continue\n",
    "\n",
    "        df_X_test = df_teste_classe[list_features]\n",
    "        df_y_pred = modelo.predict(df_X_test)\n",
    "\n",
    "        df_validacao_classe = df_teste_classe.copy()\n",
    "        df_validacao_classe[f'{target}_modelo_{modelo_number}'] = df_y_pred\n",
    "\n",
    "        dict_validacao[classe] = df_validacao_classe\n",
    "\n",
    "    if len(dict_validacao) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_validacao = pd.concat(dict_validacao.values(), ignore_index=True)\n",
    "    return df_validacao\n",
    "\n",
    "def CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva):\n",
    "   metricas_modelo = {\n",
    "      'MAE':MAE(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "      'RMSE':RMSE(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "      'R2':R2_determinacao(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "      'PSC_A':PSC_A(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}'],psc_a_max_chuva),\n",
    "      'PCC_A':PCC_A(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}'],pcc_a_erro),\n",
    "      'PMC_A':PMC_A(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}'],pmc_a_erro,pmc_a_min_chuva)\n",
    "   }\n",
    "\n",
    "   return metricas_modelo\n",
    "\n",
    "def SalvarValidacaoModeloMetricas_Modelo4(df_validacao,modelo_classificacao,dict_modelo_regressao,metricas_modelo,target,modelo_number,final_db=final_db):\n",
    "\n",
    "    df_validacao_key_target_pred = df_validacao[list_key+[target,f'{target}_modelo_{modelo_number}']]\n",
    "\n",
    "    final_db.execute(\n",
    "    f\"\"\"\n",
    "    CREATE OR REPLACE TABLE tb_validacao_modelo_{modelo_number} AS (\n",
    "    SELECT * FROM df_validacao_key_target_pred)\n",
    "    \"\"\")\n",
    "\n",
    "    with open(f'modelos_finais/modelo_{modelo_number}_classificacao.pkl','wb') as f:\n",
    "        pickle.dump(modelo_classificacao,f)\n",
    "    \n",
    "    for classe,modelo in dict_modelo_regressao.items():\n",
    "       with open(f'modelos_finais/modelo_{modelo_number}_regressao_classe_{classe}.pkl','wb') as f:\n",
    "          pickle.dump(modelo,f)\n",
    "\n",
    "    with open(f'modelos_finais/metricas_{modelo_number}.json', 'w') as f:\n",
    "        json.dump(metricas_modelo, f, indent=4)\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124bda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f33938af",
   "metadata": {},
   "source": [
    "## Modelo 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62829298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7703c3d2914b70b3689eaa3b3b94f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '4_1'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,np.inf)\n",
    "}\n",
    "list_features_modelo_4_1 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo4()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo4(df_base,dict_classes)\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo4(df_base_classes,pct_train_test_split)\n",
    "\n",
    "df_X_treino_classificacao,df_y_treino_classificacao = PrepararBaseTreino(df_treino,list_features_modelo_4_1,target_classificacao)\n",
    "\n",
    "dict_treino_regressao = {classe:df_treino.loc[df_treino[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "dict_teste_regressao = {classe:df_teste.loc[df_teste[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "\n",
    "dict_X_y_treino_regressao = {classe:PrepararBaseTreino(df_treino_regressao,list_features_modelo_4_1,target) for classe,df_treino_regressao in dict_treino_regressao.items()}\n",
    "\n",
    "# Treinando os modelos\n",
    "modelo_4_1_classificacao = TreinarAlgoritmo_Modelo4(df_X_treino_classificacao,df_y_treino_classificacao,AlgoritmoClassificacao)\n",
    "dict_modelo_4_1_regressao = {classe:TreinarAlgoritmo_Modelo4(df_X_treino,df_y_treino,Algoritmo) for classe,(df_X_treino,df_y_treino) in dict_X_y_treino_regressao.items()}\n",
    "\n",
    "# Validando\n",
    "df_teste_com_classe = PreverClasseTeste_Modelo4(df_teste,list_features_modelo_4_1,modelo_4_1_classificacao,nome_coluna_classe_predita='classe_predita')\n",
    "df_validacao = RealizarPredicaoTeste_Modelo4(df_teste_com_classe,list_features_modelo_4_1,target,dict_modelo_4_1_regressao,coluna_classe_predita='classe_predita',modelo_number=modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_4_1 = CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo4(df_validacao,modelo_4_1_classificacao,dict_modelo_4_1_regressao,metricas_modelo_4_1,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe447705",
   "metadata": {},
   "source": [
    "## Modelo 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b399d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc166a852864d00b9cdf50dc0905274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '4_2'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,51), # 51 é o top 1% da base de dados\n",
    "    2:(51,np.inf)\n",
    "}\n",
    "list_features_modelo_4_2 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo4()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo4(df_base,dict_classes)\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo4(df_base_classes,pct_train_test_split)\n",
    "\n",
    "df_X_treino_classificacao,df_y_treino_classificacao = PrepararBaseTreino(df_treino,list_features_modelo_4_2,target_classificacao)\n",
    "\n",
    "dict_treino_regressao = {classe:df_treino.loc[df_treino[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "dict_teste_regressao = {classe:df_teste.loc[df_teste[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "\n",
    "dict_X_y_treino_regressao = {classe:PrepararBaseTreino(df_treino_regressao,list_features_modelo_4_2,target) for classe,df_treino_regressao in dict_treino_regressao.items()}\n",
    "\n",
    "# Treinando os modelos\n",
    "modelo_4_2_classificacao = TreinarAlgoritmo_Modelo4(df_X_treino_classificacao,df_y_treino_classificacao,AlgoritmoClassificacao)\n",
    "dict_modelo_4_2_regressao = {classe:TreinarAlgoritmo_Modelo4(df_X_treino,df_y_treino,Algoritmo) for classe,(df_X_treino,df_y_treino) in dict_X_y_treino_regressao.items()}\n",
    "\n",
    "# Validando\n",
    "df_teste_com_classe = PreverClasseTeste_Modelo4(df_teste,list_features_modelo_4_2,modelo_4_2_classificacao,nome_coluna_classe_predita='classe_predita')\n",
    "df_validacao = RealizarPredicaoTeste_Modelo4(df_teste_com_classe,list_features_modelo_4_2,target,dict_modelo_4_2_regressao,coluna_classe_predita='classe_predita',modelo_number=modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_4_2 = CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo4(df_validacao,modelo_4_2_classificacao,dict_modelo_4_2_regressao,metricas_modelo_4_2,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333662e2",
   "metadata": {},
   "source": [
    "## Modelo 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b7dda3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c650c3a3fb9b43c5b34a0fcff1c1b760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '4_3'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,23), # 23 é o top 5% da base de dados\n",
    "    2:(23,51), # 51 é o top 1% da base de dados\n",
    "    3:(51,np.inf)\n",
    "}\n",
    "list_features_modelo_4_3 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo4()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo4(df_base,dict_classes)\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo4(df_base_classes,pct_train_test_split)\n",
    "\n",
    "df_X_treino_classificacao,df_y_treino_classificacao = PrepararBaseTreino(df_treino,list_features_modelo_4_3,target_classificacao)\n",
    "\n",
    "dict_treino_regressao = {classe:df_treino.loc[df_treino[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "dict_teste_regressao = {classe:df_teste.loc[df_teste[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "\n",
    "dict_X_y_treino_regressao = {classe:PrepararBaseTreino(df_treino_regressao,list_features_modelo_4_3,target) for classe,df_treino_regressao in dict_treino_regressao.items()}\n",
    "\n",
    "# Treinando os modelos\n",
    "modelo_4_3_classificacao = TreinarAlgoritmo_Modelo4(df_X_treino_classificacao,df_y_treino_classificacao,AlgoritmoClassificacao)\n",
    "dict_modelo_4_3_regressao = {classe:TreinarAlgoritmo_Modelo4(df_X_treino,df_y_treino,Algoritmo) for classe,(df_X_treino,df_y_treino) in dict_X_y_treino_regressao.items()}\n",
    "\n",
    "# Validando\n",
    "df_teste_com_classe = PreverClasseTeste_Modelo4(df_teste,list_features_modelo_4_3,modelo_4_3_classificacao,nome_coluna_classe_predita='classe_predita')\n",
    "df_validacao = RealizarPredicaoTeste_Modelo4(df_teste_com_classe,list_features_modelo_4_3,target,dict_modelo_4_3_regressao,coluna_classe_predita='classe_predita',modelo_number=modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_4_3 = CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo4(df_validacao,modelo_4_3_classificacao,dict_modelo_4_3_regressao,metricas_modelo_4_3,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db768e",
   "metadata": {},
   "source": [
    "## Modelo 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52e15aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1702c883fa2484e992b03c3b2956223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '4_4'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,7), # 7 é o top 15% da base de dados\n",
    "    2:(7,51), # 51 é o top 1% da base de dados\n",
    "    3:(51,np.inf)\n",
    "}\n",
    "list_features_modelo_4_4 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo4()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo4(df_base,dict_classes)\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo4(df_base_classes,pct_train_test_split)\n",
    "\n",
    "df_X_treino_classificacao,df_y_treino_classificacao = PrepararBaseTreino(df_treino,list_features_modelo_4_4,target_classificacao)\n",
    "\n",
    "dict_treino_regressao = {classe:df_treino.loc[df_treino[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "dict_teste_regressao = {classe:df_teste.loc[df_teste[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "\n",
    "dict_X_y_treino_regressao = {classe:PrepararBaseTreino(df_treino_regressao,list_features_modelo_4_4,target) for classe,df_treino_regressao in dict_treino_regressao.items()}\n",
    "\n",
    "# Treinando os modelos\n",
    "modelo_4_4_classificacao = TreinarAlgoritmo_Modelo4(df_X_treino_classificacao,df_y_treino_classificacao,AlgoritmoClassificacao)\n",
    "dict_modelo_4_4_regressao = {classe:TreinarAlgoritmo_Modelo4(df_X_treino,df_y_treino,Algoritmo) for classe,(df_X_treino,df_y_treino) in dict_X_y_treino_regressao.items()}\n",
    "\n",
    "# Validando\n",
    "df_teste_com_classe = PreverClasseTeste_Modelo4(df_teste,list_features_modelo_4_4,modelo_4_4_classificacao,nome_coluna_classe_predita='classe_predita')\n",
    "df_validacao = RealizarPredicaoTeste_Modelo4(df_teste_com_classe,list_features_modelo_4_4,target,dict_modelo_4_4_regressao,coluna_classe_predita='classe_predita',modelo_number=modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_4_4 = CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo4(df_validacao,modelo_4_4_classificacao,dict_modelo_4_4_regressao,metricas_modelo_4_4,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3481e09d",
   "metadata": {},
   "source": [
    "## Modelo 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25aedaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd5aab8c27e42bc94c22b48238f7c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '4_5'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,7), # 7 é o top 15% da base de dados\n",
    "    2:(7,np.inf)\n",
    "}\n",
    "list_features_modelo_4_5 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo4()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo4(df_base,dict_classes)\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo4(df_base_classes,pct_train_test_split)\n",
    "\n",
    "df_X_treino_classificacao,df_y_treino_classificacao = PrepararBaseTreino(df_treino,list_features_modelo_4_5,target_classificacao)\n",
    "\n",
    "dict_treino_regressao = {classe:df_treino.loc[df_treino[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "dict_teste_regressao = {classe:df_teste.loc[df_teste[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "\n",
    "dict_X_y_treino_regressao = {classe:PrepararBaseTreino(df_treino_regressao,list_features_modelo_4_5,target) for classe,df_treino_regressao in dict_treino_regressao.items()}\n",
    "\n",
    "# Treinando os modelos\n",
    "modelo_4_5_classificacao = TreinarAlgoritmo_Modelo4(df_X_treino_classificacao,df_y_treino_classificacao,AlgoritmoClassificacao)\n",
    "dict_modelo_4_5_regressao = {classe:TreinarAlgoritmo_Modelo4(df_X_treino,df_y_treino,Algoritmo) for classe,(df_X_treino,df_y_treino) in dict_X_y_treino_regressao.items()}\n",
    "\n",
    "# Validando\n",
    "df_teste_com_classe = PreverClasseTeste_Modelo4(df_teste,list_features_modelo_4_5,modelo_4_5_classificacao,nome_coluna_classe_predita='classe_predita')\n",
    "df_validacao = RealizarPredicaoTeste_Modelo4(df_teste_com_classe,list_features_modelo_4_5,target,dict_modelo_4_5_regressao,coluna_classe_predita='classe_predita',modelo_number=modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_4_5 = CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo4(df_validacao,modelo_4_5_classificacao,dict_modelo_4_5_regressao,metricas_modelo_4_5,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa3f753",
   "metadata": {},
   "source": [
    "# MODELOS 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67fb518a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os modelos 5 são iguais aos modelos 4, porém com modelo de pré-classificação ponderado ao invés de direto. Esses modelos são compostos por um algoritmo de classificação + alguns algoritmos de regressão, sempre usando XGBoost. A partição já é a padrão, de 70-30 por estação., e sem modelos especializados\n",
      "\n",
      "> Com pré modelo de classificação (ponderado, exceto nulo)\n",
      "> Sem modelo especializado\n",
      "> Apenas algoritmo de XGBoost\n",
      "> Partição padrão\n",
      "> Target padrão\n",
      "> Usando todas as variáveis explicativas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Os modelos 5 são iguais aos modelos 4, porém com modelo de pré-classificação ponderado ao invés de direto. Esses modelos são compostos por um algoritmo de classificação + alguns algoritmos de regressão, sempre usando XGBoost. A partição já é a padrão, de 70-30 por estação., e sem modelos especializados\\n\n",
    "> Com pré modelo de classificação (ponderado, exceto nulo)\n",
    "> Sem modelo especializado\n",
    "> Apenas algoritmo de XGBoost\n",
    "> Partição padrão\n",
    "> Target padrão\n",
    "> Usando todas as variáveis explicativas\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79733e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImportBase_Modelo5(final_db=final_db,table_name='abt_base'):\n",
    "    df = final_db.execute(f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM {table_name}\n",
    "    \"\"\").fetch_df()\n",
    "\n",
    "    return df\n",
    "\n",
    "def SplitTreinoTeste_Modelo5(df_base,pct_split,coluna_percentil_temporal='percentil_temporal'):\n",
    "  df_treino = df_base.loc[df_base[coluna_percentil_temporal]<=pct_split]\n",
    "  df_teste = df_base.loc[df_base[coluna_percentil_temporal]>pct_split]\n",
    "  return df_treino,df_teste\n",
    "\n",
    "def CriarColunaClasse_Modelo5(df_base,dict_classes):\n",
    "    df_base['classe_precipitacao'] = df_base['vl_precipitacao'].apply(\n",
    "        lambda x: next((classe for classe, (limite_inf, limite_sup) in dict_classes.items()\n",
    "                        if limite_inf <= x < limite_sup), None)\n",
    "    )\n",
    "\n",
    "    return df_base\n",
    "\n",
    "def PrepararBaseTreino(df_treino,list_features,target):\n",
    "   df_X_treino = df_treino.loc[:,list_features]\n",
    "   df_y_treino = df_treino.loc[:,[target]]\n",
    "   return df_X_treino,df_y_treino\n",
    "\n",
    "def TreinarAlgoritmo_Modelo5(df_X_treino,df_y_treino,Algoritmo):\n",
    "   alg = Algoritmo()\n",
    "   alg.fit(df_X_treino,df_y_treino)\n",
    "   return alg\n",
    "\n",
    "def PreverClasseTeste_Modelo5(df_teste, list_features, modelo_classificacao, nome_coluna_classe_predita='classe_predita'):\n",
    "    df_teste = df_teste.copy()\n",
    "    df_X_teste_classificacao = df_teste[list_features]\n",
    "    \n",
    "    df_teste[nome_coluna_classe_predita] = modelo_classificacao.predict(df_X_teste_classificacao)\n",
    "    \n",
    "    proba = modelo_classificacao.predict_proba(df_X_teste_classificacao)\n",
    "    classes = modelo_classificacao.classes_\n",
    "    \n",
    "    for i, classe in enumerate(classes):\n",
    "        df_teste[f'proba_classe_{classe}'] = proba[:, i]\n",
    "    \n",
    "    return df_teste\n",
    "\n",
    "def RealizarPredicaoTeste_Modelo5(df_test, list_features, target, dict_modelos_regressao, modelo_number, coluna_classe_predita='classe_predita'):\n",
    "    \n",
    "    df_test = df_test.copy()\n",
    "    \n",
    "    df_classe_0 = df_test.loc[df_test[coluna_classe_predita] == 0]\n",
    "    df_outras_classes = df_test.loc[df_test[coluna_classe_predita] != 0]\n",
    "    \n",
    "    list_df_validacao = []\n",
    "    \n",
    "    if len(df_classe_0) > 0 and 0 in dict_modelos_regressao:\n",
    "        df_X_classe_0 = df_classe_0[list_features]\n",
    "        df_y_pred_0 = dict_modelos_regressao[0].predict(df_X_classe_0)\n",
    "        \n",
    "        df_validacao_0 = df_classe_0.copy()\n",
    "        df_validacao_0[f'{target}_modelo_{modelo_number}'] = df_y_pred_0\n",
    "        list_df_validacao.append(df_validacao_0)\n",
    "    \n",
    "    if len(df_outras_classes) > 0:\n",
    "        df_X_outras = df_outras_classes[list_features]\n",
    "        \n",
    "        predicoes_ponderadas = []\n",
    "        \n",
    "        for classe, modelo in dict_modelos_regressao.items():\n",
    "            if classe == 0:\n",
    "                continue\n",
    "                \n",
    "            col_proba = f'proba_classe_{classe}'\n",
    "            if col_proba not in df_outras_classes.columns:\n",
    "                continue\n",
    "            \n",
    "            y_pred_classe = modelo.predict(df_X_outras)\n",
    "            \n",
    "            peso = df_outras_classes[col_proba].values\n",
    "            predicoes_ponderadas.append(y_pred_classe * peso)\n",
    "        \n",
    "        if len(predicoes_ponderadas) > 0:\n",
    "            predicao_final = sum(predicoes_ponderadas)\n",
    "            \n",
    "            df_validacao_outras = df_outras_classes.copy()\n",
    "            df_validacao_outras[f'{target}_modelo_{modelo_number}'] = predicao_final\n",
    "            list_df_validacao.append(df_validacao_outras)\n",
    "    \n",
    "    if len(list_df_validacao) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df_validacao = pd.concat(list_df_validacao, ignore_index=True)\n",
    "    return df_validacao\n",
    "\n",
    "def CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva):\n",
    "   metricas_modelo = {\n",
    "      'MAE':MAE(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "      'RMSE':RMSE(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "      'R2':R2_determinacao(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "      'PSC_A':PSC_A(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}'],psc_a_max_chuva),\n",
    "      'PCC_A':PCC_A(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}'],pcc_a_erro),\n",
    "      'PMC_A':PMC_A(df_validacao[target],df_validacao[f'{target}_modelo_{modelo_number}'],pmc_a_erro,pmc_a_min_chuva)\n",
    "   }\n",
    "\n",
    "   return metricas_modelo\n",
    "\n",
    "def SalvarValidacaoModeloMetricas_Modelo5(df_validacao,modelo_classificacao,dict_modelo_regressao,metricas_modelo,target,modelo_number,final_db=final_db):\n",
    "\n",
    "    df_validacao_key_target_pred = df_validacao[list_key+[target,f'{target}_modelo_{modelo_number}']]\n",
    "\n",
    "    final_db.execute(\n",
    "    f\"\"\"\n",
    "    CREATE OR REPLACE TABLE tb_validacao_modelo_{modelo_number} AS (\n",
    "    SELECT * FROM df_validacao_key_target_pred)\n",
    "    \"\"\")\n",
    "\n",
    "    with open(f'modelos_finais/modelo_{modelo_number}_classificacao.pkl','wb') as f:\n",
    "        pickle.dump(modelo_classificacao,f)\n",
    "    \n",
    "    for classe,modelo in dict_modelo_regressao.items():\n",
    "       with open(f'modelos_finais/modelo_{modelo_number}_regressao_classe_{classe}.pkl','wb') as f:\n",
    "          pickle.dump(modelo,f)\n",
    "\n",
    "    with open(f'modelos_finais/metricas_{modelo_number}.json', 'w') as f:\n",
    "        json.dump(metricas_modelo, f, indent=4)\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43b4402",
   "metadata": {},
   "source": [
    "## Modelo 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b46625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e10d30e751445fa5a47d6f56b8b08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '5_1'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,np.inf)\n",
    "}\n",
    "list_features_modelo_5_1 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo5()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo5(df_base,dict_classes)\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo5(df_base_classes,pct_train_test_split)\n",
    "\n",
    "df_X_treino_classificacao,df_y_treino_classificacao = PrepararBaseTreino(df_treino,list_features_modelo_5_1,target_classificacao)\n",
    "\n",
    "dict_treino_regressao = {classe:df_treino.loc[df_treino[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "dict_teste_regressao = {classe:df_teste.loc[df_teste[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "\n",
    "dict_X_y_treino_regressao = {classe:PrepararBaseTreino(df_treino_regressao,list_features_modelo_5_1,target) for classe,df_treino_regressao in dict_treino_regressao.items()}\n",
    "\n",
    "# Treinando os modelos\n",
    "modelo_5_1_classificacao = TreinarAlgoritmo_Modelo5(df_X_treino_classificacao,df_y_treino_classificacao,AlgoritmoClassificacao)\n",
    "dict_modelo_5_1_regressao = {classe:TreinarAlgoritmo_Modelo5(df_X_treino,df_y_treino,Algoritmo) for classe,(df_X_treino,df_y_treino) in dict_X_y_treino_regressao.items()}\n",
    "\n",
    "# Validando\n",
    "df_teste_com_classe = PreverClasseTeste_Modelo5(df_teste,list_features_modelo_5_1,modelo_5_1_classificacao,nome_coluna_classe_predita='classe_predita')\n",
    "df_validacao = RealizarPredicaoTeste_Modelo5(df_teste_com_classe,list_features_modelo_5_1,target,dict_modelo_5_1_regressao,coluna_classe_predita='classe_predita',modelo_number=modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_5_1 = CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo5(df_validacao,modelo_5_1_classificacao,dict_modelo_5_1_regressao,metricas_modelo_5_1,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a4a1df",
   "metadata": {},
   "source": [
    "## Modelo 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e21910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c07066507f54efd967549d5a883770f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '5_2'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,51), # 51 é o top 1% da base de dados\n",
    "    2:(51,np.inf)\n",
    "}\n",
    "list_features_modelo_5_2 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo5()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo5(df_base,dict_classes)\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo5(df_base_classes,pct_train_test_split)\n",
    "\n",
    "df_X_treino_classificacao,df_y_treino_classificacao = PrepararBaseTreino(df_treino,list_features_modelo_5_2,target_classificacao)\n",
    "\n",
    "dict_treino_regressao = {classe:df_treino.loc[df_treino[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "dict_teste_regressao = {classe:df_teste.loc[df_teste[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "\n",
    "dict_X_y_treino_regressao = {classe:PrepararBaseTreino(df_treino_regressao,list_features_modelo_5_2,target) for classe,df_treino_regressao in dict_treino_regressao.items()}\n",
    "\n",
    "# Treinando os modelos\n",
    "modelo_5_2_classificacao = TreinarAlgoritmo_Modelo5(df_X_treino_classificacao,df_y_treino_classificacao,AlgoritmoClassificacao)\n",
    "dict_modelo_5_2_regressao = {classe:TreinarAlgoritmo_Modelo5(df_X_treino,df_y_treino,Algoritmo) for classe,(df_X_treino,df_y_treino) in dict_X_y_treino_regressao.items()}\n",
    "\n",
    "# Validando\n",
    "df_teste_com_classe = PreverClasseTeste_Modelo5(df_teste,list_features_modelo_5_2,modelo_5_2_classificacao,nome_coluna_classe_predita='classe_predita')\n",
    "df_validacao = RealizarPredicaoTeste_Modelo5(df_teste_com_classe,list_features_modelo_5_2,target,dict_modelo_5_2_regressao,coluna_classe_predita='classe_predita',modelo_number=modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_5_2 = CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo5(df_validacao,modelo_5_2_classificacao,dict_modelo_5_2_regressao,metricas_modelo_5_2,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a015279",
   "metadata": {},
   "source": [
    "## Modelo 5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "829514de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1679599e6944a2c959cd7a74ab8fdc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '5_3'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,23), # 23 é o top 5% da base de dados\n",
    "    2:(23,51), # 51 é o top 1% da base de dados\n",
    "    3:(51,np.inf)\n",
    "}\n",
    "list_features_modelo_5_3 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo5()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo5(df_base,dict_classes)\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo5(df_base_classes,pct_train_test_split)\n",
    "\n",
    "df_X_treino_classificacao,df_y_treino_classificacao = PrepararBaseTreino(df_treino,list_features_modelo_5_3,target_classificacao)\n",
    "\n",
    "dict_treino_regressao = {classe:df_treino.loc[df_treino[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "dict_teste_regressao = {classe:df_teste.loc[df_teste[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "\n",
    "dict_X_y_treino_regressao = {classe:PrepararBaseTreino(df_treino_regressao,list_features_modelo_5_3,target) for classe,df_treino_regressao in dict_treino_regressao.items()}\n",
    "\n",
    "# Treinando os modelos\n",
    "modelo_5_3_classificacao = TreinarAlgoritmo_Modelo5(df_X_treino_classificacao,df_y_treino_classificacao,AlgoritmoClassificacao)\n",
    "dict_modelo_5_3_regressao = {classe:TreinarAlgoritmo_Modelo5(df_X_treino,df_y_treino,Algoritmo) for classe,(df_X_treino,df_y_treino) in dict_X_y_treino_regressao.items()}\n",
    "\n",
    "# Validando\n",
    "df_teste_com_classe = PreverClasseTeste_Modelo5(df_teste,list_features_modelo_5_3,modelo_5_3_classificacao,nome_coluna_classe_predita='classe_predita')\n",
    "df_validacao = RealizarPredicaoTeste_Modelo5(df_teste_com_classe,list_features_modelo_5_3,target,dict_modelo_5_3_regressao,coluna_classe_predita='classe_predita',modelo_number=modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_5_3 = CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo5(df_validacao,modelo_5_3_classificacao,dict_modelo_5_3_regressao,metricas_modelo_5_3,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c33bd1",
   "metadata": {},
   "source": [
    "## Modelo 5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c90fab5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593b7c2b82f742a4b0d4e2b6f045df2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '5_4'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,7), # 7 é o top 15% da base de dados\n",
    "    2:(7,51), # 51 é o top 1% da base de dados\n",
    "    3:(51,np.inf)\n",
    "}\n",
    "list_features_modelo_5_4 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo5()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo5(df_base,dict_classes)\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo5(df_base_classes,pct_train_test_split)\n",
    "\n",
    "df_X_treino_classificacao,df_y_treino_classificacao = PrepararBaseTreino(df_treino,list_features_modelo_5_4,target_classificacao)\n",
    "\n",
    "dict_treino_regressao = {classe:df_treino.loc[df_treino[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "dict_teste_regressao = {classe:df_teste.loc[df_teste[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "\n",
    "dict_X_y_treino_regressao = {classe:PrepararBaseTreino(df_treino_regressao,list_features_modelo_5_4,target) for classe,df_treino_regressao in dict_treino_regressao.items()}\n",
    "\n",
    "# Treinando os modelos\n",
    "modelo_5_4_classificacao = TreinarAlgoritmo_Modelo5(df_X_treino_classificacao,df_y_treino_classificacao,AlgoritmoClassificacao)\n",
    "dict_modelo_5_4_regressao = {classe:TreinarAlgoritmo_Modelo5(df_X_treino,df_y_treino,Algoritmo) for classe,(df_X_treino,df_y_treino) in dict_X_y_treino_regressao.items()}\n",
    "\n",
    "# Validando\n",
    "df_teste_com_classe = PreverClasseTeste_Modelo5(df_teste,list_features_modelo_5_4,modelo_5_4_classificacao,nome_coluna_classe_predita='classe_predita')\n",
    "df_validacao = RealizarPredicaoTeste_Modelo5(df_teste_com_classe,list_features_modelo_5_4,target,dict_modelo_5_4_regressao,coluna_classe_predita='classe_predita',modelo_number=modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_5_4 = CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo5(df_validacao,modelo_5_4_classificacao,dict_modelo_5_4_regressao,metricas_modelo_5_4,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a8ea1",
   "metadata": {},
   "source": [
    "## Modelo 5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f24051dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68aa8a2181ee4b41b6934c161eb844ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '5_5'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,7), # 7 é o top 15% da base de dados\n",
    "    2:(7,np.inf)\n",
    "}\n",
    "list_features_modelo_5_5 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# Preparando base\n",
    "df_base = ImportBase_Modelo5()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo5(df_base,dict_classes)\n",
    "df_treino,df_teste = SplitTreinoTeste_Modelo5(df_base_classes,pct_train_test_split)\n",
    "\n",
    "df_X_treino_classificacao,df_y_treino_classificacao = PrepararBaseTreino(df_treino,list_features_modelo_5_5,target_classificacao)\n",
    "\n",
    "dict_treino_regressao = {classe:df_treino.loc[df_treino[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "dict_teste_regressao = {classe:df_teste.loc[df_teste[target_classificacao]==classe] for classe in dict_classes.keys()}\n",
    "\n",
    "dict_X_y_treino_regressao = {classe:PrepararBaseTreino(df_treino_regressao,list_features_modelo_5_5,target) for classe,df_treino_regressao in dict_treino_regressao.items()}\n",
    "\n",
    "# Treinando os modelos\n",
    "modelo_5_5_classificacao = TreinarAlgoritmo_Modelo5(df_X_treino_classificacao,df_y_treino_classificacao,AlgoritmoClassificacao)\n",
    "dict_modelo_5_5_regressao = {classe:TreinarAlgoritmo_Modelo5(df_X_treino,df_y_treino,Algoritmo) for classe,(df_X_treino,df_y_treino) in dict_X_y_treino_regressao.items()}\n",
    "\n",
    "# Validando\n",
    "df_teste_com_classe = PreverClasseTeste_Modelo5(df_teste,list_features_modelo_5_5,modelo_5_5_classificacao,nome_coluna_classe_predita='classe_predita')\n",
    "df_validacao = RealizarPredicaoTeste_Modelo5(df_teste_com_classe,list_features_modelo_5_5,target,dict_modelo_5_5_regressao,coluna_classe_predita='classe_predita',modelo_number=modelo_number)\n",
    "\n",
    "# Calculando Métricas\n",
    "metricas_modelo_5_5 = CalcularMetricasTeste(df_validacao,target,modelo_number,psc_a_max_chuva,pcc_a_erro,pmc_a_erro,pmc_a_min_chuva)\n",
    "\n",
    "# Salvando modelo, base de validação e métricas\n",
    "SalvarValidacaoModeloMetricas_Modelo5(df_validacao,modelo_5_5_classificacao,dict_modelo_5_5_regressao,metricas_modelo_5_5,target,modelo_number,final_db=final_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccb794f",
   "metadata": {},
   "source": [
    "# MODELOS 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8aa4214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os modelos 6 combinam:\n",
      "- a lógica de modelo especializado + geral dos MODELOS 3; e\n",
      "- o pré-modelo de classificação dos MODELOS 4.\n",
      "\n",
      "> Com pré modelo de classificação\n",
      "> Com modelo especializado\n",
      "> Apenas algoritmo de XGBoost\n",
      "> Partição padrão\n",
      "> Target padrão\n",
      "> Usando todas as variáveis explicativas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Os modelos 6 combinam:\n",
    "- a lógica de modelo especializado + geral dos MODELOS 3; e\n",
    "- o pré-modelo de classificação dos MODELOS 4.\n",
    "\n",
    "> Com pré modelo de classificação\n",
    "> Com modelo especializado\n",
    "> Apenas algoritmo de XGBoost\n",
    "> Partição padrão\n",
    "> Target padrão\n",
    "> Usando todas as variáveis explicativas\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "242f0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImportBase_Modelo6(final_db=final_db, table_name='abt_base'):\n",
    "    df = final_db.execute(f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM {table_name}\n",
    "    \"\"\").fetch_df()\n",
    "    return df\n",
    "\n",
    "def CriarColunaClasse_Modelo6(df_base, dict_classes):\n",
    "    \"\"\"\n",
    "    Igual ao CriarColunaClasse dos modelos 4/5.\n",
    "    \"\"\"\n",
    "    df_base = df_base.copy()\n",
    "    df_base['classe_precipitacao'] = df_base['vl_precipitacao'].apply(\n",
    "        lambda x: next(\n",
    "            (classe for classe, (limite_inf, limite_sup) in dict_classes.items()\n",
    "             if limite_inf <= x < limite_sup),\n",
    "            None\n",
    "        )\n",
    "    )\n",
    "    return df_base\n",
    "\n",
    "def SepararBaseEspecializadoGeral_Modelo6(df_base, coluna_vl_prioridade_vizinha, threshold_modelo_especializado):\n",
    "    \"\"\"\n",
    "    Igual à lógica do Modelo3: separa base geral e especializada.\n",
    "    \"\"\"\n",
    "    df_base_especializado = df_base.loc[df_base[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado]\n",
    "    df_base_geral = df_base.copy()\n",
    "    return df_base_geral, df_base_especializado\n",
    "\n",
    "def SplitTreinoTeste_Modelo6(df_base_geral, df_base_especializado, pct_split, coluna_percentil_temporal='percentil_temporal'):\n",
    "    \"\"\"\n",
    "    Split temporal para geral e especializado (como no Modelo 3).\n",
    "    \"\"\"\n",
    "    df_treino_especializado = df_base_especializado.loc[df_base_especializado[coluna_percentil_temporal] <= pct_split]\n",
    "    df_teste_especializado  = df_base_especializado.loc[df_base_especializado[coluna_percentil_temporal] >  pct_split]\n",
    "\n",
    "    df_treino_geral = df_base_geral.loc[df_base_geral[coluna_percentil_temporal] <= pct_split]\n",
    "    df_teste_geral  = df_base_geral.loc[df_base_geral[coluna_percentil_temporal] >  pct_split]\n",
    "\n",
    "    return df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral\n",
    "\n",
    "def PrepararBaseTreino(df_treino, list_features, target):\n",
    "    df_X_treino = df_treino.loc[:, list_features]\n",
    "    df_y_treino = df_treino.loc[:, [target]]\n",
    "    return df_X_treino, df_y_treino\n",
    "\n",
    "def TreinarAlgoritmo_Modelo6(df_X_treino, df_y_treino, Algoritmo):\n",
    "    alg = Algoritmo()\n",
    "    alg.fit(df_X_treino, df_y_treino)\n",
    "    return alg\n",
    "\n",
    "def TreinarClassificacao_Modelo6(df_X_treino_classificacao, df_y_treino_classificacao, AlgoritmoClassificacao):\n",
    "    modelo_classificacao = AlgoritmoClassificacao()\n",
    "    modelo_classificacao.fit(df_X_treino_classificacao, df_y_treino_classificacao)\n",
    "    return modelo_classificacao\n",
    "\n",
    "def PreverClasseTeste_Modelo6(df_teste, list_features, modelo_classificacao, nome_coluna_classe_predita='classe_predita'):\n",
    "    \"\"\"\n",
    "    Igual ao PreverClasseTeste_Modelo4, mas reaproveitado aqui.\n",
    "    \"\"\"\n",
    "    df_teste = df_teste.copy()\n",
    "    df_X_teste_classificacao = df_teste[list_features]\n",
    "    df_teste[nome_coluna_classe_predita] = modelo_classificacao.predict(df_X_teste_classificacao)\n",
    "    return df_teste\n",
    "\n",
    "def RealizarPredicaoTeste_Modelo6(df_test,\n",
    "                                  list_features,\n",
    "                                  target,\n",
    "                                  dict_modelos_regressao_geral,\n",
    "                                  dict_modelos_regressao_especializado,\n",
    "                                  modelo_number,\n",
    "                                  coluna_classe_predita='classe_predita',\n",
    "                                  coluna_flag_especializado='flag_especializado'):\n",
    "    \"\"\"\n",
    "    Para cada registro:\n",
    "      - se flag_especializado == 1 e existir modelo especializado para a classe -> usa especializado\n",
    "      - senão -> usa o modelo geral da classe.\n",
    "    A estrutura de dicts é: {classe: modelo}.\n",
    "    \"\"\"\n",
    "    df_test = df_test.copy()\n",
    "    dict_validacao = {}\n",
    "\n",
    "    for classe in dict_modelos_regressao_geral.keys():\n",
    "        df_teste_classe = df_test.loc[df_test[coluna_classe_predita] == classe]\n",
    "\n",
    "        if len(df_teste_classe) == 0:\n",
    "            continue\n",
    "\n",
    "        df_teste_classe_esp = df_teste_classe.loc[df_teste_classe[coluna_flag_especializado] == 1]\n",
    "        df_teste_classe_ger = df_teste_classe.loc[df_teste_classe[coluna_flag_especializado] != 1]\n",
    "\n",
    "        list_df_val_classe = []\n",
    "\n",
    "        if classe in dict_modelos_regressao_especializado and len(df_teste_classe_esp) > 0:\n",
    "            df_X_esp = df_teste_classe_esp[list_features]\n",
    "            modelo_esp = dict_modelos_regressao_especializado[classe]\n",
    "            y_pred_esp = modelo_esp.predict(df_X_esp)\n",
    "\n",
    "            df_val_esp = df_teste_classe_esp.copy()\n",
    "            df_val_esp[f'{target}_modelo_{modelo_number}'] = y_pred_esp\n",
    "            list_df_val_classe.append(df_val_esp)\n",
    "\n",
    "        if len(df_teste_classe_ger) > 0:\n",
    "            df_X_ger = df_teste_classe_ger[list_features]\n",
    "            modelo_geral = dict_modelos_regressao_geral[classe]\n",
    "            y_pred_ger = modelo_geral.predict(df_X_ger)\n",
    "\n",
    "            df_val_ger = df_teste_classe_ger.copy()\n",
    "            df_val_ger[f'{target}_modelo_{modelo_number}'] = y_pred_ger\n",
    "            list_df_val_classe.append(df_val_ger)\n",
    "\n",
    "        if len(list_df_val_classe) > 0:\n",
    "            df_validacao_classe = pd.concat(list_df_val_classe, ignore_index=True)\n",
    "            dict_validacao[classe] = df_validacao_classe\n",
    "\n",
    "    if len(dict_validacao) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_validacao = pd.concat(dict_validacao.values(), ignore_index=True)\n",
    "    return df_validacao\n",
    "\n",
    "def CalcularMetricasTeste_Modelo6(df_validacao, target, modelo_number,\n",
    "                                  psc_a_max_chuva, pcc_a_erro, pmc_a_erro, pmc_a_min_chuva):\n",
    "    metricas_modelo = {\n",
    "        'MAE':   MAE(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "        'RMSE':  RMSE(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "        'R2':    R2_determinacao(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "        'PSC_A': PSC_A(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}'], psc_a_max_chuva),\n",
    "        'PCC_A': PCC_A(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}'], pcc_a_erro),\n",
    "        'PMC_A': PMC_A(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}'], pmc_a_erro, pmc_a_min_chuva)\n",
    "    }\n",
    "    return metricas_modelo\n",
    "\n",
    "def SalvarValidacaoModeloMetricas_Modelo6(df_validacao,\n",
    "                                          modelo_classificacao,\n",
    "                                          dict_modelos_regressao_geral,\n",
    "                                          dict_modelos_regressao_especializado,\n",
    "                                          metricas_modelo,\n",
    "                                          target,\n",
    "                                          modelo_number,\n",
    "                                          final_db=final_db):\n",
    "    df_validacao_key_target_pred = df_validacao[list_key + [target, f'{target}_modelo_{modelo_number}']]\n",
    "\n",
    "    final_db.execute(\n",
    "        f\"\"\"\n",
    "        CREATE OR REPLACE TABLE tb_validacao_modelo_{modelo_number} AS (\n",
    "            SELECT * FROM df_validacao_key_target_pred\n",
    "        )\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    with open(f'modelos_finais/modelo_{modelo_number}_classificacao.pkl', 'wb') as f:\n",
    "        pickle.dump(modelo_classificacao, f)\n",
    "\n",
    "    for classe, modelo in dict_modelos_regressao_geral.items():\n",
    "        with open(f'modelos_finais/modelo_{modelo_number}_regressao_geral_classe_{classe}.pkl', 'wb') as f:\n",
    "            pickle.dump(modelo, f)\n",
    "\n",
    "    for classe, modelo in dict_modelos_regressao_especializado.items():\n",
    "        with open(f'modelos_finais/modelo_{modelo_number}_regressao_especializado_classe_{classe}.pkl', 'wb') as f:\n",
    "            pickle.dump(modelo, f)\n",
    "\n",
    "    with open(f'modelos_finais/metricas_{modelo_number}.json', 'w') as f:\n",
    "        json.dump(metricas_modelo, f, indent=4)\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f2db9b",
   "metadata": {},
   "source": [
    "## Modelo 6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30aaf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b9b04bcbaf440b80030c297bf7bf0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '6_1'\n",
    "\n",
    "# Parâmetros de treinamento (mesmos de 3_1 + 4_1)\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.5               # igual 3_1\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "\n",
    "# Classes iguais ao 4_1\n",
    "dict_classes = {\n",
    "    0: (0, 1),\n",
    "    1: (1, np.inf)\n",
    "}\n",
    "\n",
    "list_features_modelo_6_1 = (\n",
    "    list_features_geoespaciais\n",
    "    + list_features_estacoes\n",
    "    + list_features_vizinhas\n",
    "    + list_features_produtos\n",
    ")\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# =====================================================================\n",
    "# Preparando base\n",
    "# =====================================================================\n",
    "df_base = ImportBase_Modelo6()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo6(df_base, dict_classes)\n",
    "\n",
    "# df_base não é mais usado depois daqui\n",
    "del df_base\n",
    "\n",
    "df_base_classes['flag_especializado'] = (\n",
    "    df_base_classes[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado\n",
    ").astype(int)\n",
    "\n",
    "df_base_geral, df_base_especializado = SepararBaseEspecializadoGeral_Modelo6(\n",
    "    df_base_classes,\n",
    "    coluna_vl_prioridade_vizinha,\n",
    "    threshold_modelo_especializado\n",
    ")\n",
    "\n",
    "df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral = SplitTreinoTeste_Modelo6(\n",
    "    df_base_geral,\n",
    "    df_base_especializado,\n",
    "    pct_train_test_split,\n",
    "    coluna_percentil_temporal='percentil_temporal'\n",
    ")\n",
    "\n",
    "# df_base_geral e df_base_especializado não são mais usados\n",
    "del df_base_geral, df_base_especializado\n",
    "\n",
    "# =====================================================================\n",
    "# Treino do modelo de classificação (usando df_treino_geral com todas as classes)\n",
    "# =====================================================================\n",
    "df_X_treino_classificacao, df_y_treino_classificacao = PrepararBaseTreino(\n",
    "    df_treino_geral,\n",
    "    list_features_modelo_6_1,\n",
    "    target_classificacao\n",
    ")\n",
    "\n",
    "modelo_6_1_classificacao = TreinarClassificacao_Modelo6(\n",
    "    df_X_treino_classificacao,\n",
    "    df_y_treino_classificacao,\n",
    "    AlgoritmoClassificacao\n",
    ")\n",
    "\n",
    "# Features de treino de classificação não são mais utilizados\n",
    "del df_X_treino_classificacao, df_y_treino_classificacao\n",
    "\n",
    "# =====================================================================\n",
    "# Treino dos modelos de regressão por classe - geral e especializado\n",
    "# =====================================================================\n",
    "dict_treino_regressao_geral = {\n",
    "    classe: df_treino_geral.loc[df_treino_geral[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_treino_regressao_especializado = {\n",
    "    classe: df_treino_especializado.loc[df_treino_especializado[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_geral = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_6_1, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_geral.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_especializado = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_6_1, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_especializado.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "# df_treino_geral / df_treino_especializado e dict_treino_* não são mais usados\n",
    "del df_treino_geral, df_treino_especializado\n",
    "del dict_treino_regressao_geral, dict_treino_regressao_especializado\n",
    "\n",
    "dict_modelo_6_1_regressao_geral = {\n",
    "    classe: TreinarAlgoritmo_Modelo6(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_geral.items()\n",
    "}\n",
    "\n",
    "dict_modelo_6_1_regressao_especializado = {\n",
    "    classe: TreinarAlgoritmo_Modelo6(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_especializado.items()\n",
    "}\n",
    "\n",
    "# X e y de treino de regressão não são mais usados\n",
    "del dict_X_y_treino_regressao_geral, dict_X_y_treino_regressao_especializado\n",
    "\n",
    "# =====================================================================\n",
    "# Preparação do conjunto de teste\n",
    "# =====================================================================\n",
    "df_teste_all = pd.concat(\n",
    "    [df_teste_geral, df_teste_especializado],\n",
    "    ignore_index=True\n",
    ").drop_duplicates(\n",
    "    subset=['id_estacao', 'dt_medicao']\n",
    ")\n",
    "\n",
    "# df_teste_geral / df_teste_especializado não são mais usados\n",
    "del df_teste_geral, df_teste_especializado\n",
    "\n",
    "if 'flag_especializado' not in df_teste_all.columns:\n",
    "    df_teste_all = df_teste_all.merge(\n",
    "        df_base_classes[['id_estacao', 'dt_medicao', 'flag_especializado']],\n",
    "        on=['id_estacao', 'dt_medicao'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# df_base_classes só serve para o merge acima. Depois disso não é mais usado.\n",
    "del df_base_classes\n",
    "\n",
    "df_teste_com_classe_pred = PreverClasseTeste_Modelo6(\n",
    "    df_teste_all,\n",
    "    list_features_modelo_6_1,\n",
    "    modelo_6_1_classificacao,\n",
    "    nome_coluna_classe_predita='classe_predita'\n",
    ")\n",
    "\n",
    "# df_teste_all não é mais necessário\n",
    "del df_teste_all\n",
    "\n",
    "df_validacao_6_1 = RealizarPredicaoTeste_Modelo6(\n",
    "    df_teste_com_classe_pred,\n",
    "    list_features_modelo_6_1,\n",
    "    target,\n",
    "    dict_modelo_6_1_regressao_geral,\n",
    "    dict_modelo_6_1_regressao_especializado,\n",
    "    modelo_number=modelo_number,\n",
    "    coluna_classe_predita='classe_predita',\n",
    "    coluna_flag_especializado='flag_especializado'\n",
    ")\n",
    "\n",
    "# df_teste_com_classe_pred não é mais necessário\n",
    "del df_teste_com_classe_pred\n",
    "\n",
    "metricas_modelo_6_1 = CalcularMetricasTeste_Modelo6(\n",
    "    df_validacao_6_1,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    psc_a_max_chuva,\n",
    "    pcc_a_erro,\n",
    "    pmc_a_erro,\n",
    "    pmc_a_min_chuva\n",
    ")\n",
    "\n",
    "SalvarValidacaoModeloMetricas_Modelo6(\n",
    "    df_validacao_6_1,\n",
    "    modelo_6_1_classificacao,\n",
    "    dict_modelo_6_1_regressao_geral,\n",
    "    dict_modelo_6_1_regressao_especializado,\n",
    "    metricas_modelo_6_1,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    final_db=final_db\n",
    ")\n",
    "\n",
    "# Se o script termina aqui, o GC vai limpar de qualquer forma.\n",
    "# Mas se for um notebook longo, você ainda pode:\n",
    "# del df_validacao_6_1, metricas_modelo_6_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b677a0cd",
   "metadata": {},
   "source": [
    "## Modelo 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "162bfba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c131065c36143d4a308f372d4830760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '6_2'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.5\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,51), # 51 é o top 1% da base de dados\n",
    "    2:(51,np.inf)\n",
    "}\n",
    "\n",
    "list_features_modelo_6_2 = (\n",
    "    list_features_geoespaciais\n",
    "    + list_features_estacoes\n",
    "    + list_features_vizinhas\n",
    "    + list_features_produtos\n",
    ")\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# =====================================================================\n",
    "# Preparando base\n",
    "# =====================================================================\n",
    "df_base = ImportBase_Modelo6()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo6(df_base, dict_classes)\n",
    "\n",
    "del df_base\n",
    "\n",
    "df_base_classes['flag_especializado'] = (\n",
    "    df_base_classes[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado\n",
    ").astype(int)\n",
    "\n",
    "df_base_geral, df_base_especializado = SepararBaseEspecializadoGeral_Modelo6(\n",
    "    df_base_classes,\n",
    "    coluna_vl_prioridade_vizinha,\n",
    "    threshold_modelo_especializado\n",
    ")\n",
    "\n",
    "df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral = SplitTreinoTeste_Modelo6(\n",
    "    df_base_geral,\n",
    "    df_base_especializado,\n",
    "    pct_train_test_split,\n",
    "    coluna_percentil_temporal='percentil_temporal'\n",
    ")\n",
    "\n",
    "del df_base_geral, df_base_especializado\n",
    "\n",
    "# =====================================================================\n",
    "# Treino do modelo de classificação (usando df_treino_geral com todas as classes)\n",
    "# =====================================================================\n",
    "df_X_treino_classificacao, df_y_treino_classificacao = PrepararBaseTreino(\n",
    "    df_treino_geral,\n",
    "    list_features_modelo_6_2,\n",
    "    target_classificacao\n",
    ")\n",
    "\n",
    "modelo_6_2_classificacao = TreinarClassificacao_Modelo6(\n",
    "    df_X_treino_classificacao,\n",
    "    df_y_treino_classificacao,\n",
    "    AlgoritmoClassificacao\n",
    ")\n",
    "\n",
    "del df_X_treino_classificacao, df_y_treino_classificacao\n",
    "\n",
    "# =====================================================================\n",
    "# Treino dos modelos de regressão por classe - geral e especializado\n",
    "# =====================================================================\n",
    "dict_treino_regressao_geral = {\n",
    "    classe: df_treino_geral.loc[df_treino_geral[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_treino_regressao_especializado = {\n",
    "    classe: df_treino_especializado.loc[df_treino_especializado[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_geral = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_6_2, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_geral.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_especializado = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_6_2, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_especializado.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "del df_treino_geral, df_treino_especializado\n",
    "del dict_treino_regressao_geral, dict_treino_regressao_especializado\n",
    "\n",
    "dict_modelo_6_2_regressao_geral = {\n",
    "    classe: TreinarAlgoritmo_Modelo6(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_geral.items()\n",
    "}\n",
    "\n",
    "dict_modelo_6_2_regressao_especializado = {\n",
    "    classe: TreinarAlgoritmo_Modelo6(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_especializado.items()\n",
    "}\n",
    "\n",
    "del dict_X_y_treino_regressao_geral, dict_X_y_treino_regressao_especializado\n",
    "\n",
    "# =====================================================================\n",
    "# Preparação do conjunto de teste\n",
    "# =====================================================================\n",
    "df_teste_all = pd.concat(\n",
    "    [df_teste_geral, df_teste_especializado],\n",
    "    ignore_index=True\n",
    ").drop_duplicates(\n",
    "    subset=['id_estacao', 'dt_medicao']\n",
    ")\n",
    "\n",
    "del df_teste_geral, df_teste_especializado\n",
    "\n",
    "if 'flag_especializado' not in df_teste_all.columns:\n",
    "    df_teste_all = df_teste_all.merge(\n",
    "        df_base_classes[['id_estacao', 'dt_medicao', 'flag_especializado']],\n",
    "        on=['id_estacao', 'dt_medicao'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "del df_base_classes\n",
    "\n",
    "df_teste_com_classe_pred = PreverClasseTeste_Modelo6(\n",
    "    df_teste_all,\n",
    "    list_features_modelo_6_2,\n",
    "    modelo_6_2_classificacao,\n",
    "    nome_coluna_classe_predita='classe_predita'\n",
    ")\n",
    "\n",
    "del df_teste_all\n",
    "\n",
    "df_validacao_6_2 = RealizarPredicaoTeste_Modelo6(\n",
    "    df_teste_com_classe_pred,\n",
    "    list_features_modelo_6_2,\n",
    "    target,\n",
    "    dict_modelo_6_2_regressao_geral,\n",
    "    dict_modelo_6_2_regressao_especializado,\n",
    "    modelo_number=modelo_number,\n",
    "    coluna_classe_predita='classe_predita',\n",
    "    coluna_flag_especializado='flag_especializado'\n",
    ")\n",
    "\n",
    "del df_teste_com_classe_pred\n",
    "\n",
    "metricas_modelo_6_2 = CalcularMetricasTeste_Modelo6(\n",
    "    df_validacao_6_2,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    psc_a_max_chuva,\n",
    "    pcc_a_erro,\n",
    "    pmc_a_erro,\n",
    "    pmc_a_min_chuva\n",
    ")\n",
    "\n",
    "SalvarValidacaoModeloMetricas_Modelo6(\n",
    "    df_validacao_6_2,\n",
    "    modelo_6_2_classificacao,\n",
    "    dict_modelo_6_2_regressao_geral,\n",
    "    dict_modelo_6_2_regressao_especializado,\n",
    "    metricas_modelo_6_2,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    final_db=final_db\n",
    ")\n",
    "\n",
    "# Se o script termina aqui, o GC vai limpar de qualquer forma.\n",
    "# Mas se for um notebook longo, você ainda pode:\n",
    "# del df_validacao_6_2, metricas_modelo_6_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352fd3a0",
   "metadata": {},
   "source": [
    "## Modelo 6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0eff92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8880d65a49749b19e8c80d3425952b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '6_3'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.5\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,23), # 23 é o top 5% da base de dados\n",
    "    2:(23,51), # 51 é o top 1% da base de dados\n",
    "    3:(51,np.inf)\n",
    "}\n",
    "\n",
    "list_features_modelo_6_3 = (\n",
    "    list_features_geoespaciais\n",
    "    + list_features_estacoes\n",
    "    + list_features_vizinhas\n",
    "    + list_features_produtos\n",
    ")\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# =====================================================================\n",
    "# Preparando base\n",
    "# =====================================================================\n",
    "df_base = ImportBase_Modelo6()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo6(df_base, dict_classes)\n",
    "\n",
    "del df_base\n",
    "\n",
    "df_base_classes['flag_especializado'] = (\n",
    "    df_base_classes[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado\n",
    ").astype(int)\n",
    "\n",
    "df_base_geral, df_base_especializado = SepararBaseEspecializadoGeral_Modelo6(\n",
    "    df_base_classes,\n",
    "    coluna_vl_prioridade_vizinha,\n",
    "    threshold_modelo_especializado\n",
    ")\n",
    "\n",
    "df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral = SplitTreinoTeste_Modelo6(\n",
    "    df_base_geral,\n",
    "    df_base_especializado,\n",
    "    pct_train_test_split,\n",
    "    coluna_percentil_temporal='percentil_temporal'\n",
    ")\n",
    "\n",
    "del df_base_geral, df_base_especializado\n",
    "\n",
    "# =====================================================================\n",
    "# Treino do modelo de classificação (usando df_treino_geral com todas as classes)\n",
    "# =====================================================================\n",
    "df_X_treino_classificacao, df_y_treino_classificacao = PrepararBaseTreino(\n",
    "    df_treino_geral,\n",
    "    list_features_modelo_6_3,\n",
    "    target_classificacao\n",
    ")\n",
    "\n",
    "modelo_6_3_classificacao = TreinarClassificacao_Modelo6(\n",
    "    df_X_treino_classificacao,\n",
    "    df_y_treino_classificacao,\n",
    "    AlgoritmoClassificacao\n",
    ")\n",
    "\n",
    "del df_X_treino_classificacao, df_y_treino_classificacao\n",
    "\n",
    "# =====================================================================\n",
    "# Treino dos modelos de regressão por classe - geral e especializado\n",
    "# =====================================================================\n",
    "dict_treino_regressao_geral = {\n",
    "    classe: df_treino_geral.loc[df_treino_geral[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_treino_regressao_especializado = {\n",
    "    classe: df_treino_especializado.loc[df_treino_especializado[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_geral = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_6_3, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_geral.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_especializado = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_6_3, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_especializado.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "del df_treino_geral, df_treino_especializado\n",
    "del dict_treino_regressao_geral, dict_treino_regressao_especializado\n",
    "\n",
    "dict_modelo_6_3_regressao_geral = {\n",
    "    classe: TreinarAlgoritmo_Modelo6(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_geral.items()\n",
    "}\n",
    "\n",
    "dict_modelo_6_3_regressao_especializado = {\n",
    "    classe: TreinarAlgoritmo_Modelo6(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_especializado.items()\n",
    "}\n",
    "\n",
    "del dict_X_y_treino_regressao_geral, dict_X_y_treino_regressao_especializado\n",
    "\n",
    "# =====================================================================\n",
    "# Preparação do conjunto de teste\n",
    "# =====================================================================\n",
    "df_teste_all = pd.concat(\n",
    "    [df_teste_geral, df_teste_especializado],\n",
    "    ignore_index=True\n",
    ").drop_duplicates(\n",
    "    subset=['id_estacao', 'dt_medicao']\n",
    ")\n",
    "\n",
    "del df_teste_geral, df_teste_especializado\n",
    "\n",
    "if 'flag_especializado' not in df_teste_all.columns:\n",
    "    df_teste_all = df_teste_all.merge(\n",
    "        df_base_classes[['id_estacao', 'dt_medicao', 'flag_especializado']],\n",
    "        on=['id_estacao', 'dt_medicao'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "del df_base_classes\n",
    "\n",
    "df_teste_com_classe_pred = PreverClasseTeste_Modelo6(\n",
    "    df_teste_all,\n",
    "    list_features_modelo_6_3,\n",
    "    modelo_6_3_classificacao,\n",
    "    nome_coluna_classe_predita='classe_predita'\n",
    ")\n",
    "\n",
    "del df_teste_all\n",
    "\n",
    "df_validacao_6_3 = RealizarPredicaoTeste_Modelo6(\n",
    "    df_teste_com_classe_pred,\n",
    "    list_features_modelo_6_3,\n",
    "    target,\n",
    "    dict_modelo_6_3_regressao_geral,\n",
    "    dict_modelo_6_3_regressao_especializado,\n",
    "    modelo_number=modelo_number,\n",
    "    coluna_classe_predita='classe_predita',\n",
    "    coluna_flag_especializado='flag_especializado'\n",
    ")\n",
    "\n",
    "del df_teste_com_classe_pred\n",
    "\n",
    "metricas_modelo_6_3 = CalcularMetricasTeste_Modelo6(\n",
    "    df_validacao_6_3,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    psc_a_max_chuva,\n",
    "    pcc_a_erro,\n",
    "    pmc_a_erro,\n",
    "    pmc_a_min_chuva\n",
    ")\n",
    "\n",
    "SalvarValidacaoModeloMetricas_Modelo6(\n",
    "    df_validacao_6_3,\n",
    "    modelo_6_3_classificacao,\n",
    "    dict_modelo_6_3_regressao_geral,\n",
    "    dict_modelo_6_3_regressao_especializado,\n",
    "    metricas_modelo_6_3,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    final_db=final_db\n",
    ")\n",
    "\n",
    "# Se o script termina aqui, o GC vai limpar de qualquer forma.\n",
    "# Mas se for um notebook longo, você ainda pode:\n",
    "# del df_validacao_6_3, metricas_modelo_6_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d040176",
   "metadata": {},
   "source": [
    "## Modelo 6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35063ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e65e1ea01294c8cbb9b2223901a4c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '6_4'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.5\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,7), # 7 é o top 15% da base de dados\n",
    "    2:(7,51), # 51 é o top 1% da base de dados\n",
    "    3:(51,np.inf)\n",
    "}\n",
    "\n",
    "list_features_modelo_6_4 = (\n",
    "    list_features_geoespaciais\n",
    "    + list_features_estacoes\n",
    "    + list_features_vizinhas\n",
    "    + list_features_produtos\n",
    ")\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# =====================================================================\n",
    "# Preparando base\n",
    "# =====================================================================\n",
    "df_base = ImportBase_Modelo6()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo6(df_base, dict_classes)\n",
    "\n",
    "del df_base\n",
    "\n",
    "df_base_classes['flag_especializado'] = (\n",
    "    df_base_classes[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado\n",
    ").astype(int)\n",
    "\n",
    "df_base_geral, df_base_especializado = SepararBaseEspecializadoGeral_Modelo6(\n",
    "    df_base_classes,\n",
    "    coluna_vl_prioridade_vizinha,\n",
    "    threshold_modelo_especializado\n",
    ")\n",
    "\n",
    "df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral = SplitTreinoTeste_Modelo6(\n",
    "    df_base_geral,\n",
    "    df_base_especializado,\n",
    "    pct_train_test_split,\n",
    "    coluna_percentil_temporal='percentil_temporal'\n",
    ")\n",
    "\n",
    "del df_base_geral, df_base_especializado\n",
    "\n",
    "# =====================================================================\n",
    "# Treino do modelo de classificação (usando df_treino_geral com todas as classes)\n",
    "# =====================================================================\n",
    "df_X_treino_classificacao, df_y_treino_classificacao = PrepararBaseTreino(\n",
    "    df_treino_geral,\n",
    "    list_features_modelo_6_4,\n",
    "    target_classificacao\n",
    ")\n",
    "\n",
    "modelo_6_4_classificacao = TreinarClassificacao_Modelo6(\n",
    "    df_X_treino_classificacao,\n",
    "    df_y_treino_classificacao,\n",
    "    AlgoritmoClassificacao\n",
    ")\n",
    "\n",
    "del df_X_treino_classificacao, df_y_treino_classificacao\n",
    "\n",
    "# =====================================================================\n",
    "# Treino dos modelos de regressão por classe - geral e especializado\n",
    "# =====================================================================\n",
    "dict_treino_regressao_geral = {\n",
    "    classe: df_treino_geral.loc[df_treino_geral[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_treino_regressao_especializado = {\n",
    "    classe: df_treino_especializado.loc[df_treino_especializado[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_geral = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_6_4, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_geral.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_especializado = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_6_4, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_especializado.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "del df_treino_geral, df_treino_especializado\n",
    "del dict_treino_regressao_geral, dict_treino_regressao_especializado\n",
    "\n",
    "dict_modelo_6_4_regressao_geral = {\n",
    "    classe: TreinarAlgoritmo_Modelo6(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_geral.items()\n",
    "}\n",
    "\n",
    "dict_modelo_6_4_regressao_especializado = {\n",
    "    classe: TreinarAlgoritmo_Modelo6(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_especializado.items()\n",
    "}\n",
    "\n",
    "del dict_X_y_treino_regressao_geral, dict_X_y_treino_regressao_especializado\n",
    "\n",
    "# =====================================================================\n",
    "# Preparação do conjunto de teste\n",
    "# =====================================================================\n",
    "df_teste_all = pd.concat(\n",
    "    [df_teste_geral, df_teste_especializado],\n",
    "    ignore_index=True\n",
    ").drop_duplicates(\n",
    "    subset=['id_estacao', 'dt_medicao']\n",
    ")\n",
    "\n",
    "del df_teste_geral, df_teste_especializado\n",
    "\n",
    "if 'flag_especializado' not in df_teste_all.columns:\n",
    "    df_teste_all = df_teste_all.merge(\n",
    "        df_base_classes[['id_estacao', 'dt_medicao', 'flag_especializado']],\n",
    "        on=['id_estacao', 'dt_medicao'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "del df_base_classes\n",
    "\n",
    "df_teste_com_classe_pred = PreverClasseTeste_Modelo6(\n",
    "    df_teste_all,\n",
    "    list_features_modelo_6_4,\n",
    "    modelo_6_4_classificacao,\n",
    "    nome_coluna_classe_predita='classe_predita'\n",
    ")\n",
    "\n",
    "del df_teste_all\n",
    "\n",
    "df_validacao_6_4 = RealizarPredicaoTeste_Modelo6(\n",
    "    df_teste_com_classe_pred,\n",
    "    list_features_modelo_6_4,\n",
    "    target,\n",
    "    dict_modelo_6_4_regressao_geral,\n",
    "    dict_modelo_6_4_regressao_especializado,\n",
    "    modelo_number=modelo_number,\n",
    "    coluna_classe_predita='classe_predita',\n",
    "    coluna_flag_especializado='flag_especializado'\n",
    ")\n",
    "\n",
    "del df_teste_com_classe_pred\n",
    "\n",
    "metricas_modelo_6_4 = CalcularMetricasTeste_Modelo6(\n",
    "    df_validacao_6_4,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    psc_a_max_chuva,\n",
    "    pcc_a_erro,\n",
    "    pmc_a_erro,\n",
    "    pmc_a_min_chuva\n",
    ")\n",
    "\n",
    "SalvarValidacaoModeloMetricas_Modelo6(\n",
    "    df_validacao_6_4,\n",
    "    modelo_6_4_classificacao,\n",
    "    dict_modelo_6_4_regressao_geral,\n",
    "    dict_modelo_6_4_regressao_especializado,\n",
    "    metricas_modelo_6_4,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    final_db=final_db\n",
    ")\n",
    "\n",
    "# Se o script termina aqui, o GC vai limpar de qualquer forma.\n",
    "# Mas se for um notebook longo, você ainda pode:\n",
    "# del df_validacao_6_4, metricas_modelo_6_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39848ca4",
   "metadata": {},
   "source": [
    "## Modelo 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cef08c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0058d55a18ba41ffad80c01dc0f81406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_number = '6_5'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.5\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,7), # 7 é o top 15% da base de dados\n",
    "    2:(7,np.inf)\n",
    "}\n",
    "\n",
    "list_features_modelo_6_5 = (\n",
    "    list_features_geoespaciais\n",
    "    + list_features_estacoes\n",
    "    + list_features_vizinhas\n",
    "    + list_features_produtos\n",
    ")\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "# =====================================================================\n",
    "# Preparando base\n",
    "# =====================================================================\n",
    "df_base = ImportBase_Modelo6()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo6(df_base, dict_classes)\n",
    "\n",
    "del df_base\n",
    "\n",
    "df_base_classes['flag_especializado'] = (\n",
    "    df_base_classes[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado\n",
    ").astype(int)\n",
    "\n",
    "df_base_geral, df_base_especializado = SepararBaseEspecializadoGeral_Modelo6(\n",
    "    df_base_classes,\n",
    "    coluna_vl_prioridade_vizinha,\n",
    "    threshold_modelo_especializado\n",
    ")\n",
    "\n",
    "df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral = SplitTreinoTeste_Modelo6(\n",
    "    df_base_geral,\n",
    "    df_base_especializado,\n",
    "    pct_train_test_split,\n",
    "    coluna_percentil_temporal='percentil_temporal'\n",
    ")\n",
    "\n",
    "del df_base_geral, df_base_especializado\n",
    "\n",
    "# =====================================================================\n",
    "# Treino do modelo de classificação (usando df_treino_geral com todas as classes)\n",
    "# =====================================================================\n",
    "df_X_treino_classificacao, df_y_treino_classificacao = PrepararBaseTreino(\n",
    "    df_treino_geral,\n",
    "    list_features_modelo_6_5,\n",
    "    target_classificacao\n",
    ")\n",
    "\n",
    "modelo_6_5_classificacao = TreinarClassificacao_Modelo6(\n",
    "    df_X_treino_classificacao,\n",
    "    df_y_treino_classificacao,\n",
    "    AlgoritmoClassificacao\n",
    ")\n",
    "\n",
    "del df_X_treino_classificacao, df_y_treino_classificacao\n",
    "\n",
    "# =====================================================================\n",
    "# Treino dos modelos de regressão por classe - geral e especializado\n",
    "# =====================================================================\n",
    "dict_treino_regressao_geral = {\n",
    "    classe: df_treino_geral.loc[df_treino_geral[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_treino_regressao_especializado = {\n",
    "    classe: df_treino_especializado.loc[df_treino_especializado[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_geral = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_6_5, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_geral.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_especializado = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_6_5, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_especializado.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "del df_treino_geral, df_treino_especializado\n",
    "del dict_treino_regressao_geral, dict_treino_regressao_especializado\n",
    "\n",
    "dict_modelo_6_5_regressao_geral = {\n",
    "    classe: TreinarAlgoritmo_Modelo6(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_geral.items()\n",
    "}\n",
    "\n",
    "dict_modelo_6_5_regressao_especializado = {\n",
    "    classe: TreinarAlgoritmo_Modelo6(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_especializado.items()\n",
    "}\n",
    "\n",
    "del dict_X_y_treino_regressao_geral, dict_X_y_treino_regressao_especializado\n",
    "\n",
    "# =====================================================================\n",
    "# Preparação do conjunto de teste\n",
    "# =====================================================================\n",
    "df_teste_all = pd.concat(\n",
    "    [df_teste_geral, df_teste_especializado],\n",
    "    ignore_index=True\n",
    ").drop_duplicates(\n",
    "    subset=['id_estacao', 'dt_medicao']\n",
    ")\n",
    "\n",
    "del df_teste_geral, df_teste_especializado\n",
    "\n",
    "if 'flag_especializado' not in df_teste_all.columns:\n",
    "    df_teste_all = df_teste_all.merge(\n",
    "        df_base_classes[['id_estacao', 'dt_medicao', 'flag_especializado']],\n",
    "        on=['id_estacao', 'dt_medicao'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "del df_base_classes\n",
    "\n",
    "df_teste_com_classe_pred = PreverClasseTeste_Modelo6(\n",
    "    df_teste_all,\n",
    "    list_features_modelo_6_5,\n",
    "    modelo_6_5_classificacao,\n",
    "    nome_coluna_classe_predita='classe_predita'\n",
    ")\n",
    "\n",
    "del df_teste_all\n",
    "\n",
    "df_validacao_6_5 = RealizarPredicaoTeste_Modelo6(\n",
    "    df_teste_com_classe_pred,\n",
    "    list_features_modelo_6_5,\n",
    "    target,\n",
    "    dict_modelo_6_5_regressao_geral,\n",
    "    dict_modelo_6_5_regressao_especializado,\n",
    "    modelo_number=modelo_number,\n",
    "    coluna_classe_predita='classe_predita',\n",
    "    coluna_flag_especializado='flag_especializado'\n",
    ")\n",
    "\n",
    "del df_teste_com_classe_pred\n",
    "\n",
    "metricas_modelo_6_5 = CalcularMetricasTeste_Modelo6(\n",
    "    df_validacao_6_5,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    psc_a_max_chuva,\n",
    "    pcc_a_erro,\n",
    "    pmc_a_erro,\n",
    "    pmc_a_min_chuva\n",
    ")\n",
    "\n",
    "SalvarValidacaoModeloMetricas_Modelo6(\n",
    "    df_validacao_6_5,\n",
    "    modelo_6_5_classificacao,\n",
    "    dict_modelo_6_5_regressao_geral,\n",
    "    dict_modelo_6_5_regressao_especializado,\n",
    "    metricas_modelo_6_5,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    final_db=final_db\n",
    ")\n",
    "\n",
    "# Se o script termina aqui, o GC vai limpar de qualquer forma.\n",
    "# Mas se for um notebook longo, você ainda pode:\n",
    "# del df_validacao_6_5, metricas_modelo_6_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21e2f77",
   "metadata": {},
   "source": [
    "# MODELOS 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e96a64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os modelos 7 combinam:\n",
      "- a lógica de modelo especializado + geral dos MODELOS 3; e\n",
      "- o pré-modelo de classificação PONDERADO dos MODELOS 5.\n",
      "\n",
      "> Com pré modelo de classificação (ponderado, exceto nulo)\n",
      "> Com modelo especializado\n",
      "> Apenas algoritmo de XGBoost\n",
      "> Partição padrão\n",
      "> Target padrão\n",
      "> Usando todas as variáveis explicativas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Os modelos 7 combinam:\n",
    "- a lógica de modelo especializado + geral dos MODELOS 3; e\n",
    "- o pré-modelo de classificação PONDERADO dos MODELOS 5.\n",
    "\n",
    "> Com pré modelo de classificação (ponderado, exceto nulo)\n",
    "> Com modelo especializado\n",
    "> Apenas algoritmo de XGBoost\n",
    "> Partição padrão\n",
    "> Target padrão\n",
    "> Usando todas as variáveis explicativas\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2988deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImportBase_Modelo7(final_db=final_db, table_name='abt_base'):\n",
    "    df = final_db.execute(f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM {table_name}\n",
    "    \"\"\").fetch_df()\n",
    "    return df\n",
    "\n",
    "def CriarColunaClasse_Modelo7(df_base, dict_classes):\n",
    "    \"\"\"\n",
    "    Cria coluna de classe de precipitação.\n",
    "    \"\"\"\n",
    "    df_base = df_base.copy()\n",
    "    df_base['classe_precipitacao'] = df_base['vl_precipitacao'].apply(\n",
    "        lambda x: next(\n",
    "            (classe for classe, (limite_inf, limite_sup) in dict_classes.items()\n",
    "             if limite_inf <= x < limite_sup),\n",
    "            None\n",
    "        )\n",
    "    )\n",
    "    return df_base\n",
    "\n",
    "def SepararBaseEspecializadoGeral_Modelo7(df_base, coluna_vl_prioridade_vizinha, threshold_modelo_especializado):\n",
    "    \"\"\"\n",
    "    Separa base geral e especializada baseado no threshold de prioridade.\n",
    "    \"\"\"\n",
    "    df_base_especializado = df_base.loc[df_base[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado]\n",
    "    df_base_geral = df_base.copy()\n",
    "    return df_base_geral, df_base_especializado\n",
    "\n",
    "def SplitTreinoTeste_Modelo7(df_base_geral, df_base_especializado, pct_split, coluna_percentil_temporal='percentil_temporal'):\n",
    "    \"\"\"\n",
    "    Split temporal para geral e especializado.\n",
    "    \"\"\"\n",
    "    df_treino_especializado = df_base_especializado.loc[df_base_especializado[coluna_percentil_temporal] <= pct_split]\n",
    "    df_teste_especializado  = df_base_especializado.loc[df_base_especializado[coluna_percentil_temporal] >  pct_split]\n",
    "\n",
    "    df_treino_geral = df_base_geral.loc[df_base_geral[coluna_percentil_temporal] <= pct_split]\n",
    "    df_teste_geral  = df_base_geral.loc[df_base_geral[coluna_percentil_temporal] >  pct_split]\n",
    "\n",
    "    return df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral\n",
    "\n",
    "def PrepararBaseTreino(df_treino, list_features, target):\n",
    "    df_X_treino = df_treino.loc[:, list_features]\n",
    "    df_y_treino = df_treino.loc[:, [target]]\n",
    "    return df_X_treino, df_y_treino\n",
    "\n",
    "def TreinarAlgoritmo_Modelo7(df_X_treino, df_y_treino, Algoritmo):\n",
    "    alg = Algoritmo()\n",
    "    alg.fit(df_X_treino, df_y_treino)\n",
    "    return alg\n",
    "\n",
    "def TreinarClassificacao_Modelo7(df_X_treino_classificacao, df_y_treino_classificacao, AlgoritmoClassificacao):\n",
    "    modelo_classificacao = AlgoritmoClassificacao()\n",
    "    modelo_classificacao.fit(df_X_treino_classificacao, df_y_treino_classificacao)\n",
    "    return modelo_classificacao\n",
    "\n",
    "def PreverClasseTeste_Modelo7(df_teste, list_features, modelo_classificacao, nome_coluna_classe_predita='classe_predita'):\n",
    "    \"\"\"\n",
    "    Prediz a classe e também as probabilidades de cada classe (para ponderação).\n",
    "    \"\"\"\n",
    "    df_teste = df_teste.copy()\n",
    "    df_X_teste_classificacao = df_teste[list_features]\n",
    "    \n",
    "    df_teste[nome_coluna_classe_predita] = modelo_classificacao.predict(df_X_teste_classificacao)\n",
    "    \n",
    "    # Probabilidades para ponderação\n",
    "    proba = modelo_classificacao.predict_proba(df_X_teste_classificacao)\n",
    "    classes = modelo_classificacao.classes_\n",
    "    \n",
    "    for i, classe in enumerate(classes):\n",
    "        df_teste[f'proba_classe_{classe}'] = proba[:, i]\n",
    "    \n",
    "    return df_teste\n",
    "\n",
    "def RealizarPredicaoTeste_Modelo7(df_test,\n",
    "                                  list_features,\n",
    "                                  target,\n",
    "                                  dict_modelos_regressao_geral,\n",
    "                                  dict_modelos_regressao_especializado,\n",
    "                                  modelo_number,\n",
    "                                  coluna_classe_predita='classe_predita',\n",
    "                                  coluna_flag_especializado='flag_especializado'):\n",
    "    \"\"\"\n",
    "    Predição ponderada (exceto classe 0) combinando especializado + geral.\n",
    "    \n",
    "    Lógica:\n",
    "    - Classe 0: predição direta (sem ponderação)\n",
    "    - Outras classes: ponderação por probabilidade\n",
    "    - Para cada registro, usa modelo especializado se flag_especializado==1, senão usa geral\n",
    "    \"\"\"\n",
    "    df_test = df_test.copy()\n",
    "    \n",
    "    # Separar classe 0 e outras classes\n",
    "    df_classe_0 = df_test.loc[df_test[coluna_classe_predita] == 0]\n",
    "    df_outras_classes = df_test.loc[df_test[coluna_classe_predita] != 0]\n",
    "    \n",
    "    list_df_validacao = []\n",
    "    \n",
    "    # ===== CLASSE 0: Predição direta (sem ponderação) =====\n",
    "    if len(df_classe_0) > 0 and 0 in dict_modelos_regressao_geral:\n",
    "        # Separar especializado e geral dentro da classe 0\n",
    "        df_classe_0_esp = df_classe_0.loc[df_classe_0[coluna_flag_especializado] == 1]\n",
    "        df_classe_0_ger = df_classe_0.loc[df_classe_0[coluna_flag_especializado] != 1]\n",
    "        \n",
    "        # Especializado\n",
    "        if 0 in dict_modelos_regressao_especializado and len(df_classe_0_esp) > 0:\n",
    "            df_X_esp = df_classe_0_esp[list_features]\n",
    "            y_pred_esp = dict_modelos_regressao_especializado[0].predict(df_X_esp)\n",
    "            \n",
    "            df_val_esp = df_classe_0_esp.copy()\n",
    "            df_val_esp[f'{target}_modelo_{modelo_number}'] = y_pred_esp\n",
    "            list_df_validacao.append(df_val_esp)\n",
    "        \n",
    "        # Geral\n",
    "        if len(df_classe_0_ger) > 0:\n",
    "            df_X_ger = df_classe_0_ger[list_features]\n",
    "            y_pred_ger = dict_modelos_regressao_geral[0].predict(df_X_ger)\n",
    "            \n",
    "            df_val_ger = df_classe_0_ger.copy()\n",
    "            df_val_ger[f'{target}_modelo_{modelo_number}'] = y_pred_ger\n",
    "            list_df_validacao.append(df_val_ger)\n",
    "    \n",
    "    # ===== OUTRAS CLASSES: Predição ponderada =====\n",
    "    if len(df_outras_classes) > 0:\n",
    "        # Separar especializado e geral\n",
    "        df_outras_esp = df_outras_classes.loc[df_outras_classes[coluna_flag_especializado] == 1]\n",
    "        df_outras_ger = df_outras_classes.loc[df_outras_classes[coluna_flag_especializado] != 1]\n",
    "        \n",
    "        # Processar especializado\n",
    "        if len(df_outras_esp) > 0:\n",
    "            df_X_esp = df_outras_esp[list_features]\n",
    "            predicoes_ponderadas_esp = []\n",
    "            \n",
    "            for classe, modelo in dict_modelos_regressao_especializado.items():\n",
    "                if classe == 0:\n",
    "                    continue\n",
    "                \n",
    "                col_proba = f'proba_classe_{classe}'\n",
    "                if col_proba not in df_outras_esp.columns:\n",
    "                    continue\n",
    "                \n",
    "                y_pred_classe = modelo.predict(df_X_esp)\n",
    "                peso = df_outras_esp[col_proba].values\n",
    "                predicoes_ponderadas_esp.append(y_pred_classe * peso)\n",
    "            \n",
    "            if len(predicoes_ponderadas_esp) > 0:\n",
    "                predicao_final_esp = sum(predicoes_ponderadas_esp)\n",
    "                \n",
    "                df_val_esp = df_outras_esp.copy()\n",
    "                df_val_esp[f'{target}_modelo_{modelo_number}'] = predicao_final_esp\n",
    "                list_df_validacao.append(df_val_esp)\n",
    "        \n",
    "        # Processar geral\n",
    "        if len(df_outras_ger) > 0:\n",
    "            df_X_ger = df_outras_ger[list_features]\n",
    "            predicoes_ponderadas_ger = []\n",
    "            \n",
    "            for classe, modelo in dict_modelos_regressao_geral.items():\n",
    "                if classe == 0:\n",
    "                    continue\n",
    "                \n",
    "                col_proba = f'proba_classe_{classe}'\n",
    "                if col_proba not in df_outras_ger.columns:\n",
    "                    continue\n",
    "                \n",
    "                y_pred_classe = modelo.predict(df_X_ger)\n",
    "                peso = df_outras_ger[col_proba].values\n",
    "                predicoes_ponderadas_ger.append(y_pred_classe * peso)\n",
    "            \n",
    "            if len(predicoes_ponderadas_ger) > 0:\n",
    "                predicao_final_ger = sum(predicoes_ponderadas_ger)\n",
    "                \n",
    "                df_val_ger = df_outras_ger.copy()\n",
    "                df_val_ger[f'{target}_modelo_{modelo_number}'] = predicao_final_ger\n",
    "                list_df_validacao.append(df_val_ger)\n",
    "    \n",
    "    if len(list_df_validacao) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df_validacao = pd.concat(list_df_validacao, ignore_index=True)\n",
    "    return df_validacao\n",
    "\n",
    "def CalcularMetricasTeste_Modelo7(df_validacao, target, modelo_number,\n",
    "                                  psc_a_max_chuva, pcc_a_erro, pmc_a_erro, pmc_a_min_chuva):\n",
    "    metricas_modelo = {\n",
    "        'MAE':   MAE(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "        'RMSE':  RMSE(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "        'R2':    R2_determinacao(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "        'PSC_A': PSC_A(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}'], psc_a_max_chuva),\n",
    "        'PCC_A': PCC_A(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}'], pcc_a_erro),\n",
    "        'PMC_A': PMC_A(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}'], pmc_a_erro, pmc_a_min_chuva)\n",
    "    }\n",
    "    return metricas_modelo\n",
    "\n",
    "def SalvarValidacaoModeloMetricas_Modelo7(df_validacao,\n",
    "                                          modelo_classificacao,\n",
    "                                          dict_modelos_regressao_geral,\n",
    "                                          dict_modelos_regressao_especializado,\n",
    "                                          metricas_modelo,\n",
    "                                          target,\n",
    "                                          modelo_number,\n",
    "                                          final_db=final_db):\n",
    "    df_validacao_key_target_pred = df_validacao[list_key + [target, f'{target}_modelo_{modelo_number}']]\n",
    "\n",
    "    final_db.execute(\n",
    "        f\"\"\"\n",
    "        CREATE OR REPLACE TABLE tb_validacao_modelo_{modelo_number} AS (\n",
    "            SELECT * FROM df_validacao_key_target_pred\n",
    "        )\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Salvar modelo de classificação\n",
    "    with open(f'modelos_finais/modelo_{modelo_number}_classificacao.pkl', 'wb') as f:\n",
    "        pickle.dump(modelo_classificacao, f)\n",
    "\n",
    "    # Salvar modelos gerais por classe\n",
    "    for classe, modelo in dict_modelos_regressao_geral.items():\n",
    "        with open(f'modelos_finais/modelo_{modelo_number}_regressao_geral_classe_{classe}.pkl', 'wb') as f:\n",
    "            pickle.dump(modelo, f)\n",
    "\n",
    "    # Salvar modelos especializados por classe\n",
    "    for classe, modelo in dict_modelos_regressao_especializado.items():\n",
    "        with open(f'modelos_finais/modelo_{modelo_number}_regressao_especializado_classe_{classe}.pkl', 'wb') as f:\n",
    "            pickle.dump(modelo, f)\n",
    "\n",
    "    # Salvar métricas\n",
    "    with open(f'modelos_finais/metricas_{modelo_number}.json', 'w') as f:\n",
    "        json.dump(metricas_modelo, f, indent=4)\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc2fdec",
   "metadata": {},
   "source": [
    "## Modelo 7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0070795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ff750f7b3b40eda31fe81317198340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.5\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "\n",
    "dict_classes = {\n",
    "    0: (0, 1),\n",
    "    1: (1, np.inf)\n",
    "}\n",
    "\n",
    "list_features_modelo_7_1 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "modelo_number = '7_1'\n",
    "\n",
    "# ===== Carregando base =====\n",
    "df_base = ImportBase_Modelo7()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo7(df_base, dict_classes)\n",
    "\n",
    "df_base_classes['flag_especializado'] = (df_base_classes[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado).astype(int)\n",
    "\n",
    "df_base_geral, df_base_especializado = SepararBaseEspecializadoGeral_Modelo7(\n",
    "    df_base_classes,\n",
    "    coluna_vl_prioridade_vizinha,\n",
    "    threshold_modelo_especializado\n",
    ")\n",
    "\n",
    "df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral = SplitTreinoTeste_Modelo7(\n",
    "    df_base_geral,\n",
    "    df_base_especializado,\n",
    "    pct_train_test_split,\n",
    "    coluna_percentil_temporal='percentil_temporal'\n",
    ")\n",
    "\n",
    "# Já podemos descartar as bases completas\n",
    "del df_base, df_base_classes, df_base_geral, df_base_especializado\n",
    "gc.collect()\n",
    "\n",
    "# ===== Treino do modelo de classificação (usando df_treino_geral com todas as classes) =====\n",
    "df_X_treino_classificacao, df_y_treino_classificacao = PrepararBaseTreino(\n",
    "    df_treino_geral,\n",
    "    list_features_modelo_7_1,\n",
    "    target_classificacao\n",
    ")\n",
    "\n",
    "modelo_7_1_classificacao = TreinarClassificacao_Modelo7(\n",
    "    df_X_treino_classificacao,\n",
    "    df_y_treino_classificacao,\n",
    "    AlgoritmoClassificacao\n",
    ")\n",
    "\n",
    "# Libera X e y de classificação (não serão mais usados)\n",
    "del df_X_treino_classificacao, df_y_treino_classificacao\n",
    "gc.collect()\n",
    "\n",
    "# ===== Treino dos modelos de regressão por classe - geral e especializado =====\n",
    "dict_treino_regressao_geral = {\n",
    "    classe: df_treino_geral.loc[df_treino_geral[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_treino_regressao_especializado = {\n",
    "    classe: df_treino_especializado.loc[df_treino_especializado[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_geral = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_7_1, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_geral.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_especializado = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_7_1, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_especializado.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_modelo_7_1_regressao_geral = {\n",
    "    classe: TreinarAlgoritmo_Modelo7(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_geral.items()\n",
    "}\n",
    "\n",
    "dict_modelo_7_1_regressao_especializado = {\n",
    "    classe: TreinarAlgoritmo_Modelo7(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_especializado.items()\n",
    "}\n",
    "\n",
    "# Podemos liberar tudo que era de treino\n",
    "del (\n",
    "    df_treino_geral,\n",
    "    df_treino_especializado,\n",
    "    dict_treino_regressao_geral,\n",
    "    dict_treino_regressao_especializado,\n",
    "    dict_X_y_treino_regressao_geral,\n",
    "    dict_X_y_treino_regressao_especializado\n",
    ")\n",
    "gc.collect()\n",
    "\n",
    "# ===== Validação =====\n",
    "df_teste_all = pd.concat([df_teste_geral, df_teste_especializado], ignore_index=True).drop_duplicates(\n",
    "    subset=['id_estacao', 'dt_medicao']\n",
    ")\n",
    "\n",
    "# df_teste_geral / df_teste_especializado não são mais necessários depois de df_teste_all\n",
    "del df_teste_geral, df_teste_especializado\n",
    "gc.collect()\n",
    "\n",
    "if 'flag_especializado' not in df_teste_all.columns:\n",
    "    df_teste_all = df_teste_all.merge(\n",
    "        df_base_classes[['id_estacao', 'dt_medicao', 'flag_especializado']],\n",
    "        on=['id_estacao', 'dt_medicao'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# OBS: se tiver removido df_base_classes lá em cima, remova também este merge\n",
    "# ou adapte para carregar flag_especializado de outra fonte. Caso mantenha,\n",
    "# não dê del em df_base_classes antes deste ponto.\n",
    "\n",
    "df_teste_com_classe_pred = PreverClasseTeste_Modelo7(\n",
    "    df_teste_all,\n",
    "    list_features_modelo_7_1,\n",
    "    modelo_7_1_classificacao,\n",
    "    nome_coluna_classe_predita='classe_predita'\n",
    ")\n",
    "\n",
    "# df_teste_all não será mais usado\n",
    "del df_teste_all\n",
    "gc.collect()\n",
    "\n",
    "df_validacao_7_1 = RealizarPredicaoTeste_Modelo7(\n",
    "    df_teste_com_classe_pred,\n",
    "    list_features_modelo_7_1,\n",
    "    target,\n",
    "    dict_modelo_7_1_regressao_geral,\n",
    "    dict_modelo_7_1_regressao_especializado,\n",
    "    modelo_number=modelo_number,\n",
    "    coluna_classe_predita='classe_predita',\n",
    "    coluna_flag_especializado='flag_especializado'\n",
    ")\n",
    "\n",
    "# df_teste_com_classe_pred não é mais necessário\n",
    "del df_teste_com_classe_pred\n",
    "gc.collect()\n",
    "\n",
    "# ===== Métricas =====\n",
    "metricas_modelo_7_1 = CalcularMetricasTeste_Modelo7(\n",
    "    df_validacao_7_1,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    psc_a_max_chuva,\n",
    "    pcc_a_erro,\n",
    "    pmc_a_erro,\n",
    "    pmc_a_min_chuva\n",
    ")\n",
    "\n",
    "# ===== Salvando =====\n",
    "SalvarValidacaoModeloMetricas_Modelo7(\n",
    "    df_validacao_7_1,\n",
    "    modelo_7_1_classificacao,\n",
    "    dict_modelo_7_1_regressao_geral,\n",
    "    dict_modelo_7_1_regressao_especializado,\n",
    "    metricas_modelo_7_1,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    final_db=final_db\n",
    ")\n",
    "\n",
    "# Após salvar, podemos liberar praticamente tudo\n",
    "del (\n",
    "    df_validacao_7_1,\n",
    "    modelo_7_1_classificacao,\n",
    "    dict_modelo_7_1_regressao_geral,\n",
    "    dict_modelo_7_1_regressao_especializado,\n",
    "    metricas_modelo_7_1\n",
    ")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7037c9",
   "metadata": {},
   "source": [
    "## Modelo 7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18295018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9bfe74538c043f696b8568586a8b625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.5\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,51), # 51 é o top 1% da base de dados\n",
    "    2:(51,np.inf)\n",
    "}\n",
    "\n",
    "list_features_modelo_7_2 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "modelo_number = '7_2'\n",
    "\n",
    "# ===== Carregando base =====\n",
    "df_base = ImportBase_Modelo7()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo7(df_base, dict_classes)\n",
    "\n",
    "df_base_classes['flag_especializado'] = (df_base_classes[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado).astype(int)\n",
    "\n",
    "df_base_geral, df_base_especializado = SepararBaseEspecializadoGeral_Modelo7(\n",
    "    df_base_classes,\n",
    "    coluna_vl_prioridade_vizinha,\n",
    "    threshold_modelo_especializado\n",
    ")\n",
    "\n",
    "df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral = SplitTreinoTeste_Modelo7(\n",
    "    df_base_geral,\n",
    "    df_base_especializado,\n",
    "    pct_train_test_split,\n",
    "    coluna_percentil_temporal='percentil_temporal'\n",
    ")\n",
    "\n",
    "# Já podemos descartar as bases completas\n",
    "del df_base, df_base_classes, df_base_geral, df_base_especializado\n",
    "gc.collect()\n",
    "\n",
    "# ===== Treino do modelo de classificação (usando df_treino_geral com todas as classes) =====\n",
    "df_X_treino_classificacao, df_y_treino_classificacao = PrepararBaseTreino(\n",
    "    df_treino_geral,\n",
    "    list_features_modelo_7_2,\n",
    "    target_classificacao\n",
    ")\n",
    "\n",
    "modelo_7_2_classificacao = TreinarClassificacao_Modelo7(\n",
    "    df_X_treino_classificacao,\n",
    "    df_y_treino_classificacao,\n",
    "    AlgoritmoClassificacao\n",
    ")\n",
    "\n",
    "# Libera X e y de classificação (não serão mais usados)\n",
    "del df_X_treino_classificacao, df_y_treino_classificacao\n",
    "gc.collect()\n",
    "\n",
    "# ===== Treino dos modelos de regressão por classe - geral e especializado =====\n",
    "dict_treino_regressao_geral = {\n",
    "    classe: df_treino_geral.loc[df_treino_geral[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_treino_regressao_especializado = {\n",
    "    classe: df_treino_especializado.loc[df_treino_especializado[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_geral = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_7_2, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_geral.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_especializado = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_7_2, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_especializado.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_modelo_7_2_regressao_geral = {\n",
    "    classe: TreinarAlgoritmo_Modelo7(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_geral.items()\n",
    "}\n",
    "\n",
    "dict_modelo_7_2_regressao_especializado = {\n",
    "    classe: TreinarAlgoritmo_Modelo7(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_especializado.items()\n",
    "}\n",
    "\n",
    "# Podemos liberar tudo que era de treino\n",
    "del (\n",
    "    df_treino_geral,\n",
    "    df_treino_especializado,\n",
    "    dict_treino_regressao_geral,\n",
    "    dict_treino_regressao_especializado,\n",
    "    dict_X_y_treino_regressao_geral,\n",
    "    dict_X_y_treino_regressao_especializado\n",
    ")\n",
    "gc.collect()\n",
    "\n",
    "# ===== Validação =====\n",
    "df_teste_all = pd.concat([df_teste_geral, df_teste_especializado], ignore_index=True).drop_duplicates(\n",
    "    subset=['id_estacao', 'dt_medicao']\n",
    ")\n",
    "\n",
    "# df_teste_geral / df_teste_especializado não são mais necessários depois de df_teste_all\n",
    "del df_teste_geral, df_teste_especializado\n",
    "gc.collect()\n",
    "\n",
    "if 'flag_especializado' not in df_teste_all.columns:\n",
    "    df_teste_all = df_teste_all.merge(\n",
    "        df_base_classes[['id_estacao', 'dt_medicao', 'flag_especializado']],\n",
    "        on=['id_estacao', 'dt_medicao'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# OBS: se tiver removido df_base_classes lá em cima, remova também este merge\n",
    "# ou adapte para carregar flag_especializado de outra fonte. Caso mantenha,\n",
    "# não dê del em df_base_classes antes deste ponto.\n",
    "\n",
    "df_teste_com_classe_pred = PreverClasseTeste_Modelo7(\n",
    "    df_teste_all,\n",
    "    list_features_modelo_7_2,\n",
    "    modelo_7_2_classificacao,\n",
    "    nome_coluna_classe_predita='classe_predita'\n",
    ")\n",
    "\n",
    "# df_teste_all não será mais usado\n",
    "del df_teste_all\n",
    "gc.collect()\n",
    "\n",
    "df_validacao_7_2 = RealizarPredicaoTeste_Modelo7(\n",
    "    df_teste_com_classe_pred,\n",
    "    list_features_modelo_7_2,\n",
    "    target,\n",
    "    dict_modelo_7_2_regressao_geral,\n",
    "    dict_modelo_7_2_regressao_especializado,\n",
    "    modelo_number=modelo_number,\n",
    "    coluna_classe_predita='classe_predita',\n",
    "    coluna_flag_especializado='flag_especializado'\n",
    ")\n",
    "\n",
    "# df_teste_com_classe_pred não é mais necessário\n",
    "del df_teste_com_classe_pred\n",
    "gc.collect()\n",
    "\n",
    "# ===== Métricas =====\n",
    "metricas_modelo_7_2 = CalcularMetricasTeste_Modelo7(\n",
    "    df_validacao_7_2,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    psc_a_max_chuva,\n",
    "    pcc_a_erro,\n",
    "    pmc_a_erro,\n",
    "    pmc_a_min_chuva\n",
    ")\n",
    "\n",
    "# ===== Salvando =====\n",
    "SalvarValidacaoModeloMetricas_Modelo7(\n",
    "    df_validacao_7_2,\n",
    "    modelo_7_2_classificacao,\n",
    "    dict_modelo_7_2_regressao_geral,\n",
    "    dict_modelo_7_2_regressao_especializado,\n",
    "    metricas_modelo_7_2,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    final_db=final_db\n",
    ")\n",
    "\n",
    "# Após salvar, podemos liberar praticamente tudo\n",
    "del (\n",
    "    df_validacao_7_2,\n",
    "    modelo_7_2_classificacao,\n",
    "    dict_modelo_7_2_regressao_geral,\n",
    "    dict_modelo_7_2_regressao_especializado,\n",
    "    metricas_modelo_7_2\n",
    ")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0e506d",
   "metadata": {},
   "source": [
    "## Modelo 7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaf0de03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996ed3c3b12249438f91f40d323cedc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.5\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,23), # 23 é o top 5% da base de dados\n",
    "    2:(23,51), # 51 é o top 1% da base de dados\n",
    "    3:(51,np.inf)\n",
    "}\n",
    "\n",
    "list_features_modelo_7_3 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "modelo_number = '7_3'\n",
    "\n",
    "# ===== Carregando base =====\n",
    "df_base = ImportBase_Modelo7()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo7(df_base, dict_classes)\n",
    "\n",
    "df_base_classes['flag_especializado'] = (df_base_classes[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado).astype(int)\n",
    "\n",
    "df_base_geral, df_base_especializado = SepararBaseEspecializadoGeral_Modelo7(\n",
    "    df_base_classes,\n",
    "    coluna_vl_prioridade_vizinha,\n",
    "    threshold_modelo_especializado\n",
    ")\n",
    "\n",
    "df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral = SplitTreinoTeste_Modelo7(\n",
    "    df_base_geral,\n",
    "    df_base_especializado,\n",
    "    pct_train_test_split,\n",
    "    coluna_percentil_temporal='percentil_temporal'\n",
    ")\n",
    "\n",
    "# Já podemos descartar as bases completas\n",
    "del df_base, df_base_classes, df_base_geral, df_base_especializado\n",
    "gc.collect()\n",
    "\n",
    "# ===== Treino do modelo de classificação (usando df_treino_geral com todas as classes) =====\n",
    "df_X_treino_classificacao, df_y_treino_classificacao = PrepararBaseTreino(\n",
    "    df_treino_geral,\n",
    "    list_features_modelo_7_3,\n",
    "    target_classificacao\n",
    ")\n",
    "\n",
    "modelo_7_3_classificacao = TreinarClassificacao_Modelo7(\n",
    "    df_X_treino_classificacao,\n",
    "    df_y_treino_classificacao,\n",
    "    AlgoritmoClassificacao\n",
    ")\n",
    "\n",
    "# Libera X e y de classificação (não serão mais usados)\n",
    "del df_X_treino_classificacao, df_y_treino_classificacao\n",
    "gc.collect()\n",
    "\n",
    "# ===== Treino dos modelos de regressão por classe - geral e especializado =====\n",
    "dict_treino_regressao_geral = {\n",
    "    classe: df_treino_geral.loc[df_treino_geral[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_treino_regressao_especializado = {\n",
    "    classe: df_treino_especializado.loc[df_treino_especializado[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_geral = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_7_3, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_geral.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_especializado = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_7_3, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_especializado.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_modelo_7_3_regressao_geral = {\n",
    "    classe: TreinarAlgoritmo_Modelo7(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_geral.items()\n",
    "}\n",
    "\n",
    "dict_modelo_7_3_regressao_especializado = {\n",
    "    classe: TreinarAlgoritmo_Modelo7(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_especializado.items()\n",
    "}\n",
    "\n",
    "# Podemos liberar tudo que era de treino\n",
    "del (\n",
    "    df_treino_geral,\n",
    "    df_treino_especializado,\n",
    "    dict_treino_regressao_geral,\n",
    "    dict_treino_regressao_especializado,\n",
    "    dict_X_y_treino_regressao_geral,\n",
    "    dict_X_y_treino_regressao_especializado\n",
    ")\n",
    "gc.collect()\n",
    "\n",
    "# ===== Validação =====\n",
    "df_teste_all = pd.concat([df_teste_geral, df_teste_especializado], ignore_index=True).drop_duplicates(\n",
    "    subset=['id_estacao', 'dt_medicao']\n",
    ")\n",
    "\n",
    "# df_teste_geral / df_teste_especializado não são mais necessários depois de df_teste_all\n",
    "del df_teste_geral, df_teste_especializado\n",
    "gc.collect()\n",
    "\n",
    "if 'flag_especializado' not in df_teste_all.columns:\n",
    "    df_teste_all = df_teste_all.merge(\n",
    "        df_base_classes[['id_estacao', 'dt_medicao', 'flag_especializado']],\n",
    "        on=['id_estacao', 'dt_medicao'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# OBS: se tiver removido df_base_classes lá em cima, remova também este merge\n",
    "# ou adapte para carregar flag_especializado de outra fonte. Caso mantenha,\n",
    "# não dê del em df_base_classes antes deste ponto.\n",
    "\n",
    "df_teste_com_classe_pred = PreverClasseTeste_Modelo7(\n",
    "    df_teste_all,\n",
    "    list_features_modelo_7_3,\n",
    "    modelo_7_3_classificacao,\n",
    "    nome_coluna_classe_predita='classe_predita'\n",
    ")\n",
    "\n",
    "# df_teste_all não será mais usado\n",
    "del df_teste_all\n",
    "gc.collect()\n",
    "\n",
    "df_validacao_7_3 = RealizarPredicaoTeste_Modelo7(\n",
    "    df_teste_com_classe_pred,\n",
    "    list_features_modelo_7_3,\n",
    "    target,\n",
    "    dict_modelo_7_3_regressao_geral,\n",
    "    dict_modelo_7_3_regressao_especializado,\n",
    "    modelo_number=modelo_number,\n",
    "    coluna_classe_predita='classe_predita',\n",
    "    coluna_flag_especializado='flag_especializado'\n",
    ")\n",
    "\n",
    "# df_teste_com_classe_pred não é mais necessário\n",
    "del df_teste_com_classe_pred\n",
    "gc.collect()\n",
    "\n",
    "# ===== Métricas =====\n",
    "metricas_modelo_7_3 = CalcularMetricasTeste_Modelo7(\n",
    "    df_validacao_7_3,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    psc_a_max_chuva,\n",
    "    pcc_a_erro,\n",
    "    pmc_a_erro,\n",
    "    pmc_a_min_chuva\n",
    ")\n",
    "\n",
    "# ===== Salvando =====\n",
    "SalvarValidacaoModeloMetricas_Modelo7(\n",
    "    df_validacao_7_3,\n",
    "    modelo_7_3_classificacao,\n",
    "    dict_modelo_7_3_regressao_geral,\n",
    "    dict_modelo_7_3_regressao_especializado,\n",
    "    metricas_modelo_7_3,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    final_db=final_db\n",
    ")\n",
    "\n",
    "# Após salvar, podemos liberar praticamente tudo\n",
    "del (\n",
    "    df_validacao_7_3,\n",
    "    modelo_7_3_classificacao,\n",
    "    dict_modelo_7_3_regressao_geral,\n",
    "    dict_modelo_7_3_regressao_especializado,\n",
    "    metricas_modelo_7_3\n",
    ")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbcd910",
   "metadata": {},
   "source": [
    "## Modelo 7.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77d1e2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5481c1b01242ae9cddbd503cbcba20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.5\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,7), # 7 é o top 15% da base de dados\n",
    "    2:(7,51), # 51 é o top 1% da base de dados\n",
    "    3:(51,np.inf)\n",
    "}\n",
    "\n",
    "list_features_modelo_7_4 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "modelo_number = '7_4'\n",
    "\n",
    "# ===== Carregando base =====\n",
    "df_base = ImportBase_Modelo7()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo7(df_base, dict_classes)\n",
    "\n",
    "df_base_classes['flag_especializado'] = (df_base_classes[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado).astype(int)\n",
    "\n",
    "df_base_geral, df_base_especializado = SepararBaseEspecializadoGeral_Modelo7(\n",
    "    df_base_classes,\n",
    "    coluna_vl_prioridade_vizinha,\n",
    "    threshold_modelo_especializado\n",
    ")\n",
    "\n",
    "df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral = SplitTreinoTeste_Modelo7(\n",
    "    df_base_geral,\n",
    "    df_base_especializado,\n",
    "    pct_train_test_split,\n",
    "    coluna_percentil_temporal='percentil_temporal'\n",
    ")\n",
    "\n",
    "# Já podemos descartar as bases completas\n",
    "del df_base, df_base_classes, df_base_geral, df_base_especializado\n",
    "gc.collect()\n",
    "\n",
    "# ===== Treino do modelo de classificação (usando df_treino_geral com todas as classes) =====\n",
    "df_X_treino_classificacao, df_y_treino_classificacao = PrepararBaseTreino(\n",
    "    df_treino_geral,\n",
    "    list_features_modelo_7_4,\n",
    "    target_classificacao\n",
    ")\n",
    "\n",
    "modelo_7_4_classificacao = TreinarClassificacao_Modelo7(\n",
    "    df_X_treino_classificacao,\n",
    "    df_y_treino_classificacao,\n",
    "    AlgoritmoClassificacao\n",
    ")\n",
    "\n",
    "# Libera X e y de classificação (não serão mais usados)\n",
    "del df_X_treino_classificacao, df_y_treino_classificacao\n",
    "gc.collect()\n",
    "\n",
    "# ===== Treino dos modelos de regressão por classe - geral e especializado =====\n",
    "dict_treino_regressao_geral = {\n",
    "    classe: df_treino_geral.loc[df_treino_geral[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_treino_regressao_especializado = {\n",
    "    classe: df_treino_especializado.loc[df_treino_especializado[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_geral = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_7_4, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_geral.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_especializado = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_7_4, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_especializado.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_modelo_7_4_regressao_geral = {\n",
    "    classe: TreinarAlgoritmo_Modelo7(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_geral.items()\n",
    "}\n",
    "\n",
    "dict_modelo_7_4_regressao_especializado = {\n",
    "    classe: TreinarAlgoritmo_Modelo7(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_especializado.items()\n",
    "}\n",
    "\n",
    "# Podemos liberar tudo que era de treino\n",
    "del (\n",
    "    df_treino_geral,\n",
    "    df_treino_especializado,\n",
    "    dict_treino_regressao_geral,\n",
    "    dict_treino_regressao_especializado,\n",
    "    dict_X_y_treino_regressao_geral,\n",
    "    dict_X_y_treino_regressao_especializado\n",
    ")\n",
    "gc.collect()\n",
    "\n",
    "# ===== Validação =====\n",
    "df_teste_all = pd.concat([df_teste_geral, df_teste_especializado], ignore_index=True).drop_duplicates(\n",
    "    subset=['id_estacao', 'dt_medicao']\n",
    ")\n",
    "\n",
    "# df_teste_geral / df_teste_especializado não são mais necessários depois de df_teste_all\n",
    "del df_teste_geral, df_teste_especializado\n",
    "gc.collect()\n",
    "\n",
    "if 'flag_especializado' not in df_teste_all.columns:\n",
    "    df_teste_all = df_teste_all.merge(\n",
    "        df_base_classes[['id_estacao', 'dt_medicao', 'flag_especializado']],\n",
    "        on=['id_estacao', 'dt_medicao'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# OBS: se tiver removido df_base_classes lá em cima, remova também este merge\n",
    "# ou adapte para carregar flag_especializado de outra fonte. Caso mantenha,\n",
    "# não dê del em df_base_classes antes deste ponto.\n",
    "\n",
    "df_teste_com_classe_pred = PreverClasseTeste_Modelo7(\n",
    "    df_teste_all,\n",
    "    list_features_modelo_7_4,\n",
    "    modelo_7_4_classificacao,\n",
    "    nome_coluna_classe_predita='classe_predita'\n",
    ")\n",
    "\n",
    "# df_teste_all não será mais usado\n",
    "del df_teste_all\n",
    "gc.collect()\n",
    "\n",
    "df_validacao_7_4 = RealizarPredicaoTeste_Modelo7(\n",
    "    df_teste_com_classe_pred,\n",
    "    list_features_modelo_7_4,\n",
    "    target,\n",
    "    dict_modelo_7_4_regressao_geral,\n",
    "    dict_modelo_7_4_regressao_especializado,\n",
    "    modelo_number=modelo_number,\n",
    "    coluna_classe_predita='classe_predita',\n",
    "    coluna_flag_especializado='flag_especializado'\n",
    ")\n",
    "\n",
    "# df_teste_com_classe_pred não é mais necessário\n",
    "del df_teste_com_classe_pred\n",
    "gc.collect()\n",
    "\n",
    "# ===== Métricas =====\n",
    "metricas_modelo_7_4 = CalcularMetricasTeste_Modelo7(\n",
    "    df_validacao_7_4,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    psc_a_max_chuva,\n",
    "    pcc_a_erro,\n",
    "    pmc_a_erro,\n",
    "    pmc_a_min_chuva\n",
    ")\n",
    "\n",
    "# ===== Salvando =====\n",
    "SalvarValidacaoModeloMetricas_Modelo7(\n",
    "    df_validacao_7_4,\n",
    "    modelo_7_4_classificacao,\n",
    "    dict_modelo_7_4_regressao_geral,\n",
    "    dict_modelo_7_4_regressao_especializado,\n",
    "    metricas_modelo_7_4,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    final_db=final_db\n",
    ")\n",
    "\n",
    "# Após salvar, podemos liberar praticamente tudo\n",
    "del (\n",
    "    df_validacao_7_4,\n",
    "    modelo_7_4_classificacao,\n",
    "    dict_modelo_7_4_regressao_geral,\n",
    "    dict_modelo_7_4_regressao_especializado,\n",
    "    metricas_modelo_7_4\n",
    ")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0b96ee",
   "metadata": {},
   "source": [
    "## Modelo 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aaf94f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91accfdf19e43cb9a1b63e53b78885c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parâmetros de treinamento\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.5\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,7), # 7 é o top 15% da base de dados\n",
    "    2:(7,np.inf)\n",
    "}\n",
    "\n",
    "list_features_modelo_7_5 = list_features_geoespaciais + list_features_estacoes + list_features_vizinhas + list_features_produtos\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "\n",
    "# Parâmetros de métricas\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "modelo_number = '7_5'\n",
    "\n",
    "# ===== Carregando base =====\n",
    "df_base = ImportBase_Modelo7()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo7(df_base, dict_classes)\n",
    "\n",
    "df_base_classes['flag_especializado'] = (df_base_classes[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado).astype(int)\n",
    "\n",
    "df_base_geral, df_base_especializado = SepararBaseEspecializadoGeral_Modelo7(\n",
    "    df_base_classes,\n",
    "    coluna_vl_prioridade_vizinha,\n",
    "    threshold_modelo_especializado\n",
    ")\n",
    "\n",
    "df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral = SplitTreinoTeste_Modelo7(\n",
    "    df_base_geral,\n",
    "    df_base_especializado,\n",
    "    pct_train_test_split,\n",
    "    coluna_percentil_temporal='percentil_temporal'\n",
    ")\n",
    "\n",
    "# Já podemos descartar as bases completas\n",
    "del df_base, df_base_classes, df_base_geral, df_base_especializado\n",
    "gc.collect()\n",
    "\n",
    "# ===== Treino do modelo de classificação (usando df_treino_geral com todas as classes) =====\n",
    "df_X_treino_classificacao, df_y_treino_classificacao = PrepararBaseTreino(\n",
    "    df_treino_geral,\n",
    "    list_features_modelo_7_5,\n",
    "    target_classificacao\n",
    ")\n",
    "\n",
    "modelo_7_5_classificacao = TreinarClassificacao_Modelo7(\n",
    "    df_X_treino_classificacao,\n",
    "    df_y_treino_classificacao,\n",
    "    AlgoritmoClassificacao\n",
    ")\n",
    "\n",
    "# Libera X e y de classificação (não serão mais usados)\n",
    "del df_X_treino_classificacao, df_y_treino_classificacao\n",
    "gc.collect()\n",
    "\n",
    "# ===== Treino dos modelos de regressão por classe - geral e especializado =====\n",
    "dict_treino_regressao_geral = {\n",
    "    classe: df_treino_geral.loc[df_treino_geral[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_treino_regressao_especializado = {\n",
    "    classe: df_treino_especializado.loc[df_treino_especializado[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_geral = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_7_5, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_geral.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_especializado = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_7_5, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_especializado.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_modelo_7_5_regressao_geral = {\n",
    "    classe: TreinarAlgoritmo_Modelo7(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_geral.items()\n",
    "}\n",
    "\n",
    "dict_modelo_7_5_regressao_especializado = {\n",
    "    classe: TreinarAlgoritmo_Modelo7(df_X_treino, df_y_treino, Algoritmo)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_especializado.items()\n",
    "}\n",
    "\n",
    "# Podemos liberar tudo que era de treino\n",
    "del (\n",
    "    df_treino_geral,\n",
    "    df_treino_especializado,\n",
    "    dict_treino_regressao_geral,\n",
    "    dict_treino_regressao_especializado,\n",
    "    dict_X_y_treino_regressao_geral,\n",
    "    dict_X_y_treino_regressao_especializado\n",
    ")\n",
    "gc.collect()\n",
    "\n",
    "# ===== Validação =====\n",
    "df_teste_all = pd.concat([df_teste_geral, df_teste_especializado], ignore_index=True).drop_duplicates(\n",
    "    subset=['id_estacao', 'dt_medicao']\n",
    ")\n",
    "\n",
    "# df_teste_geral / df_teste_especializado não são mais necessários depois de df_teste_all\n",
    "del df_teste_geral, df_teste_especializado\n",
    "gc.collect()\n",
    "\n",
    "if 'flag_especializado' not in df_teste_all.columns:\n",
    "    df_teste_all = df_teste_all.merge(\n",
    "        df_base_classes[['id_estacao', 'dt_medicao', 'flag_especializado']],\n",
    "        on=['id_estacao', 'dt_medicao'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# OBS: se tiver removido df_base_classes lá em cima, remova também este merge\n",
    "# ou adapte para carregar flag_especializado de outra fonte. Caso mantenha,\n",
    "# não dê del em df_base_classes antes deste ponto.\n",
    "\n",
    "df_teste_com_classe_pred = PreverClasseTeste_Modelo7(\n",
    "    df_teste_all,\n",
    "    list_features_modelo_7_5,\n",
    "    modelo_7_5_classificacao,\n",
    "    nome_coluna_classe_predita='classe_predita'\n",
    ")\n",
    "\n",
    "# df_teste_all não será mais usado\n",
    "del df_teste_all\n",
    "gc.collect()\n",
    "\n",
    "df_validacao_7_5 = RealizarPredicaoTeste_Modelo7(\n",
    "    df_teste_com_classe_pred,\n",
    "    list_features_modelo_7_5,\n",
    "    target,\n",
    "    dict_modelo_7_5_regressao_geral,\n",
    "    dict_modelo_7_5_regressao_especializado,\n",
    "    modelo_number=modelo_number,\n",
    "    coluna_classe_predita='classe_predita',\n",
    "    coluna_flag_especializado='flag_especializado'\n",
    ")\n",
    "\n",
    "# df_teste_com_classe_pred não é mais necessário\n",
    "del df_teste_com_classe_pred\n",
    "gc.collect()\n",
    "\n",
    "# ===== Métricas =====\n",
    "metricas_modelo_7_5 = CalcularMetricasTeste_Modelo7(\n",
    "    df_validacao_7_5,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    psc_a_max_chuva,\n",
    "    pcc_a_erro,\n",
    "    pmc_a_erro,\n",
    "    pmc_a_min_chuva\n",
    ")\n",
    "\n",
    "# ===== Salvando =====\n",
    "SalvarValidacaoModeloMetricas_Modelo7(\n",
    "    df_validacao_7_5,\n",
    "    modelo_7_5_classificacao,\n",
    "    dict_modelo_7_5_regressao_geral,\n",
    "    dict_modelo_7_5_regressao_especializado,\n",
    "    metricas_modelo_7_5,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    final_db=final_db\n",
    ")\n",
    "\n",
    "# Após salvar, podemos liberar praticamente tudo\n",
    "del (\n",
    "    df_validacao_7_5,\n",
    "    modelo_7_5_classificacao,\n",
    "    dict_modelo_7_5_regressao_geral,\n",
    "    dict_modelo_7_5_regressao_especializado,\n",
    "    metricas_modelo_7_5\n",
    ")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca7916",
   "metadata": {},
   "source": [
    "# MODELOS 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43710704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os modelos 8 são variações do modelo 6_4, testando diferentes algoritmos de gradient boosting:\n",
      "- 8_1: XGBoost com early stopping\n",
      "- 8_2: HistGradientBoosting\n",
      "- 8_3: ExtraTrees\n",
      "- 8_4: LightGBM\n",
      "\n",
      "> Com pré modelo de classificação\n",
      "> Com modelo especializado\n",
      "> Diferentes algoritmos de gradient boosting\n",
      "> Partição padrão\n",
      "> Target padrão\n",
      "> Usando todas as variáveis explicativas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Os modelos 8 são variações do modelo 6_4, testando diferentes algoritmos de gradient boosting:\n",
    "- 8_1: XGBoost com early stopping\n",
    "- 8_2: HistGradientBoosting\n",
    "- 8_3: ExtraTrees\n",
    "- 8_4: LightGBM\n",
    "\n",
    "> Com pré modelo de classificação\n",
    "> Com modelo especializado\n",
    "> Diferentes algoritmos de gradient boosting\n",
    "> Partição padrão\n",
    "> Target padrão\n",
    "> Usando todas as variáveis explicativas\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82b1b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImportBase_Modelo8(final_db=final_db, table_name='abt_base'):\n",
    "    df = final_db.execute(f\"\"\"\n",
    "    SELECT\n",
    "    *\n",
    "    FROM {table_name}\n",
    "    \"\"\").fetch_df()\n",
    "    return df\n",
    "\n",
    "def CriarColunaClasse_Modelo8(df_base, dict_classes):\n",
    "    df_base = df_base.copy()\n",
    "    df_base['classe_precipitacao'] = df_base['vl_precipitacao'].apply(\n",
    "        lambda x: next(\n",
    "            (classe for classe, (limite_inf, limite_sup) in dict_classes.items()\n",
    "             if limite_inf <= x < limite_sup),\n",
    "            None\n",
    "        )\n",
    "    )\n",
    "    return df_base\n",
    "\n",
    "def SepararBaseEspecializadoGeral_Modelo8(df_base, coluna_vl_prioridade_vizinha, threshold_modelo_especializado):\n",
    "    df_base_especializado = df_base.loc[df_base[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado]\n",
    "    df_base_geral = df_base.copy()\n",
    "    return df_base_geral, df_base_especializado\n",
    "\n",
    "def SplitTreinoTeste_Modelo8(df_base_geral, df_base_especializado, pct_split, coluna_percentil_temporal='percentil_temporal'):\n",
    "    df_treino_especializado = df_base_especializado.loc[df_base_especializado[coluna_percentil_temporal] <= pct_split]\n",
    "    df_teste_especializado  = df_base_especializado.loc[df_base_especializado[coluna_percentil_temporal] >  pct_split]\n",
    "\n",
    "    df_treino_geral = df_base_geral.loc[df_base_geral[coluna_percentil_temporal] <= pct_split]\n",
    "    df_teste_geral  = df_base_geral.loc[df_base_geral[coluna_percentil_temporal] >  pct_split]\n",
    "\n",
    "    return df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral\n",
    "\n",
    "def PrepararBaseTreino(df_treino, list_features, target):\n",
    "    df_X_treino = df_treino.loc[:, list_features]\n",
    "    df_y_treino = df_treino.loc[:, [target]]\n",
    "    return df_X_treino, df_y_treino\n",
    "\n",
    "def TreinarAlgoritmo_Modelo8(df_X_treino, df_y_treino, Algoritmo, **kwargs):\n",
    "    alg = Algoritmo(**kwargs)\n",
    "    alg.fit(df_X_treino, df_y_treino.values.ravel())\n",
    "    return alg\n",
    "\n",
    "def TreinarClassificacao_Modelo8(df_X_treino_classificacao, df_y_treino_classificacao, AlgoritmoClassificacao, **kwargs):\n",
    "    modelo_classificacao = AlgoritmoClassificacao(**kwargs)\n",
    "    modelo_classificacao.fit(df_X_treino_classificacao, df_y_treino_classificacao.values.ravel())\n",
    "    return modelo_classificacao\n",
    "\n",
    "def PreverClasseTeste_Modelo8(df_teste, list_features, modelo_classificacao, nome_coluna_classe_predita='classe_predita'):\n",
    "    df_teste = df_teste.copy()\n",
    "    df_X_teste_classificacao = df_teste[list_features]\n",
    "    df_teste[nome_coluna_classe_predita] = modelo_classificacao.predict(df_X_teste_classificacao)\n",
    "    return df_teste\n",
    "\n",
    "def RealizarPredicaoTeste_Modelo8(df_test,\n",
    "                                   list_features,\n",
    "                                   target,\n",
    "                                   dict_modelos_regressao_geral,\n",
    "                                   dict_modelos_regressao_especializado,\n",
    "                                   modelo_number,\n",
    "                                   coluna_classe_predita='classe_predita',\n",
    "                                   coluna_flag_especializado='flag_especializado'):\n",
    "    df_test = df_test.copy()\n",
    "    dict_validacao = {}\n",
    "\n",
    "    for classe in dict_modelos_regressao_geral.keys():\n",
    "        df_teste_classe = df_test.loc[df_test[coluna_classe_predita] == classe]\n",
    "\n",
    "        if len(df_teste_classe) == 0:\n",
    "            continue\n",
    "\n",
    "        df_teste_classe_esp = df_teste_classe.loc[df_teste_classe[coluna_flag_especializado] == 1]\n",
    "        df_teste_classe_ger = df_teste_classe.loc[df_teste_classe[coluna_flag_especializado] != 1]\n",
    "\n",
    "        list_df_val_classe = []\n",
    "\n",
    "        if classe in dict_modelos_regressao_especializado and len(df_teste_classe_esp) > 0:\n",
    "            df_X_esp = df_teste_classe_esp[list_features]\n",
    "            modelo_esp = dict_modelos_regressao_especializado[classe]\n",
    "            y_pred_esp = modelo_esp.predict(df_X_esp)\n",
    "\n",
    "            df_val_esp = df_teste_classe_esp.copy()\n",
    "            df_val_esp[f'{target}_modelo_{modelo_number}'] = y_pred_esp\n",
    "            list_df_val_classe.append(df_val_esp)\n",
    "\n",
    "        if len(df_teste_classe_ger) > 0:\n",
    "            df_X_ger = df_teste_classe_ger[list_features]\n",
    "            modelo_geral = dict_modelos_regressao_geral[classe]\n",
    "            y_pred_ger = modelo_geral.predict(df_X_ger)\n",
    "\n",
    "            df_val_ger = df_teste_classe_ger.copy()\n",
    "            df_val_ger[f'{target}_modelo_{modelo_number}'] = y_pred_ger\n",
    "            list_df_val_classe.append(df_val_ger)\n",
    "\n",
    "        if len(list_df_val_classe) > 0:\n",
    "            df_validacao_classe = pd.concat(list_df_val_classe, ignore_index=True)\n",
    "            dict_validacao[classe] = df_validacao_classe\n",
    "\n",
    "    if len(dict_validacao) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_validacao = pd.concat(dict_validacao.values(), ignore_index=True)\n",
    "    return df_validacao\n",
    "\n",
    "def CalcularMetricasTeste_Modelo8(df_validacao, target, modelo_number,\n",
    "                                   psc_a_max_chuva, pcc_a_erro, pmc_a_erro, pmc_a_min_chuva):\n",
    "    metricas_modelo = {\n",
    "        'MAE':   MAE(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "        'RMSE':  RMSE(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "        'R2':    R2_determinacao(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}']),\n",
    "        'PSC_A': PSC_A(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}'], psc_a_max_chuva),\n",
    "        'PCC_A': PCC_A(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}'], pcc_a_erro),\n",
    "        'PMC_A': PMC_A(df_validacao[target], df_validacao[f'{target}_modelo_{modelo_number}'], pmc_a_erro, pmc_a_min_chuva)\n",
    "    }\n",
    "    return metricas_modelo\n",
    "\n",
    "def SalvarValidacaoModeloMetricas_Modelo8(df_validacao,\n",
    "                                           modelo_classificacao,\n",
    "                                           dict_modelos_regressao_geral,\n",
    "                                           dict_modelos_regressao_especializado,\n",
    "                                           metricas_modelo,\n",
    "                                           target,\n",
    "                                           modelo_number,\n",
    "                                           final_db=final_db):\n",
    "    df_validacao_key_target_pred = df_validacao[list_key + [target, f'{target}_modelo_{modelo_number}']]\n",
    "\n",
    "    final_db.execute(\n",
    "        f\"\"\"\n",
    "        CREATE OR REPLACE TABLE tb_validacao_modelo_{modelo_number} AS (\n",
    "        SELECT * FROM df_validacao_key_target_pred\n",
    "        )\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    with open(f'modelos_finais/modelo_{modelo_number}_classificacao.pkl', 'wb') as f:\n",
    "        pickle.dump(modelo_classificacao, f)\n",
    "\n",
    "    for classe, modelo in dict_modelos_regressao_geral.items():\n",
    "        with open(f'modelos_finais/modelo_{modelo_number}_regressao_geral_classe_{classe}.pkl', 'wb') as f:\n",
    "            pickle.dump(modelo, f)\n",
    "\n",
    "    for classe, modelo in dict_modelos_regressao_especializado.items():\n",
    "        with open(f'modelos_finais/modelo_{modelo_number}_regressao_especializado_classe_{classe}.pkl', 'wb') as f:\n",
    "            pickle.dump(modelo, f)\n",
    "\n",
    "    with open(f'modelos_finais/metricas_{modelo_number}.json', 'w') as f:\n",
    "        json.dump(metricas_modelo, f, indent=4)\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1647a764",
   "metadata": {},
   "source": [
    "## Modelo 8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acf9c992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f22d0e818b1471691e280095abb7782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Must have at least 1 validation dataset for early stopping.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 65\u001b[0m\n\u001b[0;32m     57\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m     59\u001b[0m df_X_treino_classificacao, df_y_treino_classificacao \u001b[38;5;241m=\u001b[39m PrepararBaseTreino(\n\u001b[0;32m     60\u001b[0m     df_treino_geral,\n\u001b[0;32m     61\u001b[0m     list_features_modelo_8_1,\n\u001b[0;32m     62\u001b[0m     target_classificacao\n\u001b[0;32m     63\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m modelo_8_1_classificacao \u001b[38;5;241m=\u001b[39m \u001b[43mTreinarClassificacao_Modelo8\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_X_treino_classificacao\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_y_treino_classificacao\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mAlgoritmoClassificacao\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_classificacao\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m df_X_treino_classificacao, df_y_treino_classificacao\n\u001b[0;32m     73\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "Cell \u001b[1;32mIn[6], line 46\u001b[0m, in \u001b[0;36mTreinarClassificacao_Modelo8\u001b[1;34m(df_X_treino_classificacao, df_y_treino_classificacao, AlgoritmoClassificacao, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mTreinarClassificacao_Modelo8\u001b[39m(df_X_treino_classificacao, df_y_treino_classificacao, AlgoritmoClassificacao, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     45\u001b[0m     modelo_classificacao \u001b[38;5;241m=\u001b[39m AlgoritmoClassificacao(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 46\u001b[0m     \u001b[43mmodelo_classificacao\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_X_treino_classificacao\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_y_treino_classificacao\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m modelo_classificacao\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1529\u001b[0m )\n\u001b[1;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:182\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    185\u001b[0m bst \u001b[38;5;241m=\u001b[39m cb_container\u001b[38;5;241m.\u001b[39mafter_training(bst)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\callback.py:261\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[1;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[0;32m    259\u001b[0m     metric_score \u001b[38;5;241m=\u001b[39m _parse_eval_str(score)\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_history(metric_score, epoch)\n\u001b[1;32m--> 261\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\callback.py:261\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m     metric_score \u001b[38;5;241m=\u001b[39m _parse_eval_str(score)\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_history(metric_score, epoch)\n\u001b[1;32m--> 261\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\callback.py:446\u001b[0m, in \u001b[0;36mEarlyStopping.after_iteration\u001b[1;34m(self, model, epoch, evals_log)\u001b[0m\n\u001b[0;32m    444\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust have at least 1 validation dataset for early stopping.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(evals_log\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 446\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# Get data name\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata:\n",
      "\u001b[1;31mValueError\u001b[0m: Must have at least 1 validation dataset for early stopping."
     ]
    }
   ],
   "source": [
    "modelo_number = '8_1'\n",
    "\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.5\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,7),\n",
    "    2:(7,51),\n",
    "    3:(51,np.inf)\n",
    "}\n",
    "\n",
    "list_features_modelo_8_1 = (\n",
    "    list_features_geoespaciais\n",
    "    + list_features_estacoes\n",
    "    + list_features_vizinhas\n",
    "    + list_features_produtos\n",
    ")\n",
    "\n",
    "Algoritmo = XGBRegressor\n",
    "AlgoritmoClassificacao = XGBClassifier\n",
    "kwargs_regressao = {'early_stopping_rounds': 10, 'eval_metric': 'rmse'}\n",
    "kwargs_classificacao = {'early_stopping_rounds': 10}\n",
    "\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "df_base = ImportBase_Modelo8()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo8(df_base, dict_classes)\n",
    "\n",
    "del df_base\n",
    "\n",
    "df_base_classes['flag_especializado'] = (\n",
    "    df_base_classes[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado\n",
    ").astype(int)\n",
    "\n",
    "df_base_geral, df_base_especializado = SepararBaseEspecializadoGeral_Modelo8(\n",
    "    df_base_classes,\n",
    "    coluna_vl_prioridade_vizinha,\n",
    "    threshold_modelo_especializado\n",
    ")\n",
    "\n",
    "df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral = SplitTreinoTeste_Modelo8(\n",
    "    df_base_geral,\n",
    "    df_base_especializado,\n",
    "    pct_train_test_split,\n",
    "    coluna_percentil_temporal='percentil_temporal'\n",
    ")\n",
    "\n",
    "del df_base_geral, df_base_especializado\n",
    "gc.collect()\n",
    "\n",
    "df_X_treino_classificacao, df_y_treino_classificacao = PrepararBaseTreino(\n",
    "    df_treino_geral,\n",
    "    list_features_modelo_8_1,\n",
    "    target_classificacao\n",
    ")\n",
    "\n",
    "modelo_8_1_classificacao = TreinarClassificacao_Modelo8(\n",
    "    df_X_treino_classificacao,\n",
    "    df_y_treino_classificacao,\n",
    "    AlgoritmoClassificacao,\n",
    "    **kwargs_classificacao\n",
    ")\n",
    "\n",
    "del df_X_treino_classificacao, df_y_treino_classificacao\n",
    "gc.collect()\n",
    "\n",
    "dict_treino_regressao_geral = {\n",
    "    classe: df_treino_geral.loc[df_treino_geral[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_treino_regressao_especializado = {\n",
    "    classe: df_treino_especializado.loc[df_treino_especializado[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_geral = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_8_1, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_geral.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_especializado = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_8_1, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_especializado.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "del df_treino_geral, df_treino_especializado\n",
    "del dict_treino_regressao_geral, dict_treino_regressao_especializado\n",
    "gc.collect()\n",
    "\n",
    "dict_modelo_8_1_regressao_geral = {\n",
    "    classe: TreinarAlgoritmo_Modelo8(df_X_treino, df_y_treino, Algoritmo, **kwargs_regressao)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_geral.items()\n",
    "}\n",
    "\n",
    "dict_modelo_8_1_regressao_especializado = {\n",
    "    classe: TreinarAlgoritmo_Modelo8(df_X_treino, df_y_treino, Algoritmo, **kwargs_regressao)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_especializado.items()\n",
    "}\n",
    "\n",
    "del dict_X_y_treino_regressao_geral, dict_X_y_treino_regressao_especializado\n",
    "gc.collect()\n",
    "\n",
    "df_teste_all = pd.concat(\n",
    "    [df_teste_geral, df_teste_especializado],\n",
    "    ignore_index=True\n",
    ").drop_duplicates(\n",
    "    subset=['id_estacao', 'dt_medicao']\n",
    ")\n",
    "\n",
    "del df_teste_geral, df_teste_especializado\n",
    "gc.collect()\n",
    "\n",
    "if 'flag_especializado' not in df_teste_all.columns:\n",
    "    df_teste_all = df_teste_all.merge(\n",
    "        df_base_classes[['id_estacao', 'dt_medicao', 'flag_especializado']],\n",
    "        on=['id_estacao', 'dt_medicao'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "del df_base_classes\n",
    "gc.collect()\n",
    "\n",
    "df_teste_com_classe_pred = PreverClasseTeste_Modelo8(\n",
    "    df_teste_all,\n",
    "    list_features_modelo_8_1,\n",
    "    modelo_8_1_classificacao,\n",
    "    nome_coluna_classe_predita='classe_predita'\n",
    ")\n",
    "\n",
    "del df_teste_all\n",
    "gc.collect()\n",
    "\n",
    "df_validacao_8_1 = RealizarPredicaoTeste_Modelo8(\n",
    "    df_teste_com_classe_pred,\n",
    "    list_features_modelo_8_1,\n",
    "    target,\n",
    "    dict_modelo_8_1_regressao_geral,\n",
    "    dict_modelo_8_1_regressao_especializado,\n",
    "    modelo_number=modelo_number,\n",
    "    coluna_classe_predita='classe_predita',\n",
    "    coluna_flag_especializado='flag_especializado'\n",
    ")\n",
    "\n",
    "del df_teste_com_classe_pred\n",
    "gc.collect()\n",
    "\n",
    "metricas_modelo_8_1 = CalcularMetricasTeste_Modelo8(\n",
    "    df_validacao_8_1,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    psc_a_max_chuva,\n",
    "    pcc_a_erro,\n",
    "    pmc_a_erro,\n",
    "    pmc_a_min_chuva\n",
    ")\n",
    "\n",
    "SalvarValidacaoModeloMetricas_Modelo8(\n",
    "    df_validacao_8_1,\n",
    "    modelo_8_1_classificacao,\n",
    "    dict_modelo_8_1_regressao_geral,\n",
    "    dict_modelo_8_1_regressao_especializado,\n",
    "    metricas_modelo_8_1,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    final_db=final_db\n",
    ")\n",
    "\n",
    "del (\n",
    "    df_validacao_8_1,\n",
    "    modelo_8_1_classificacao,\n",
    "    dict_modelo_8_1_regressao_geral,\n",
    "    dict_modelo_8_1_regressao_especializado,\n",
    "    metricas_modelo_8_1\n",
    ")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b384d500",
   "metadata": {},
   "source": [
    "## Modelo 8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028fc42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770d8346849048d3b993d5f18e5e588a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_number = '8_2'\n",
    "\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.5\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,7),\n",
    "    2:(7,51),\n",
    "    3:(51,np.inf)\n",
    "}\n",
    "\n",
    "list_features_modelo_8_2 = (\n",
    "    list_features_geoespaciais\n",
    "    + list_features_estacoes\n",
    "    + list_features_vizinhas\n",
    "    + list_features_produtos\n",
    ")\n",
    "\n",
    "Algoritmo = HistGradientBoostingRegressor\n",
    "AlgoritmoClassificacao = HistGradientBoostingClassifier\n",
    "kwargs_regressao = {'max_iter': 100, 'early_stopping': True, 'n_iter_no_change': 10}\n",
    "kwargs_classificacao = {'max_iter': 100, 'early_stopping': True, 'n_iter_no_change': 10}\n",
    "\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "df_base = ImportBase_Modelo8()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo8(df_base, dict_classes)\n",
    "\n",
    "del df_base\n",
    "\n",
    "df_base_classes['flag_especializado'] = (\n",
    "    df_base_classes[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado\n",
    ").astype(int)\n",
    "\n",
    "df_base_geral, df_base_especializado = SepararBaseEspecializadoGeral_Modelo8(\n",
    "    df_base_classes,\n",
    "    coluna_vl_prioridade_vizinha,\n",
    "    threshold_modelo_especializado\n",
    ")\n",
    "\n",
    "df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral = SplitTreinoTeste_Modelo8(\n",
    "    df_base_geral,\n",
    "    df_base_especializado,\n",
    "    pct_train_test_split,\n",
    "    coluna_percentil_temporal='percentil_temporal'\n",
    ")\n",
    "\n",
    "del df_base_geral, df_base_especializado\n",
    "gc.collect()\n",
    "\n",
    "df_X_treino_classificacao, df_y_treino_classificacao = PrepararBaseTreino(\n",
    "    df_treino_geral,\n",
    "    list_features_modelo_8_2,\n",
    "    target_classificacao\n",
    ")\n",
    "\n",
    "modelo_8_2_classificacao = TreinarClassificacao_Modelo8(\n",
    "    df_X_treino_classificacao,\n",
    "    df_y_treino_classificacao,\n",
    "    AlgoritmoClassificacao,\n",
    "    **kwargs_classificacao\n",
    ")\n",
    "\n",
    "del df_X_treino_classificacao, df_y_treino_classificacao\n",
    "gc.collect()\n",
    "\n",
    "dict_treino_regressao_geral = {\n",
    "    classe: df_treino_geral.loc[df_treino_geral[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_treino_regressao_especializado = {\n",
    "    classe: df_treino_especializado.loc[df_treino_especializado[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_geral = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_8_2, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_geral.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_especializado = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_8_2, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_especializado.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "del df_treino_geral, df_treino_especializado\n",
    "del dict_treino_regressao_geral, dict_treino_regressao_especializado\n",
    "gc.collect()\n",
    "\n",
    "dict_modelo_8_2_regressao_geral = {\n",
    "    classe: TreinarAlgoritmo_Modelo8(df_X_treino, df_y_treino, Algoritmo, **kwargs_regressao)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_geral.items()\n",
    "}\n",
    "\n",
    "dict_modelo_8_2_regressao_especializado = {\n",
    "    classe: TreinarAlgoritmo_Modelo8(df_X_treino, df_y_treino, Algoritmo, **kwargs_regressao)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_especializado.items()\n",
    "}\n",
    "\n",
    "del dict_X_y_treino_regressao_geral, dict_X_y_treino_regressao_especializado\n",
    "gc.collect()\n",
    "\n",
    "df_teste_all = pd.concat(\n",
    "    [df_teste_geral, df_teste_especializado],\n",
    "    ignore_index=True\n",
    ").drop_duplicates(\n",
    "    subset=['id_estacao', 'dt_medicao']\n",
    ")\n",
    "\n",
    "del df_teste_geral, df_teste_especializado\n",
    "gc.collect()\n",
    "\n",
    "if 'flag_especializado' not in df_teste_all.columns:\n",
    "    df_teste_all = df_teste_all.merge(\n",
    "        df_base_classes[['id_estacao', 'dt_medicao', 'flag_especializado']],\n",
    "        on=['id_estacao', 'dt_medicao'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "del df_base_classes\n",
    "gc.collect()\n",
    "\n",
    "df_teste_com_classe_pred = PreverClasseTeste_Modelo8(\n",
    "    df_teste_all,\n",
    "    list_features_modelo_8_2,\n",
    "    modelo_8_2_classificacao,\n",
    "    nome_coluna_classe_predita='classe_predita'\n",
    ")\n",
    "\n",
    "del df_teste_all\n",
    "gc.collect()\n",
    "\n",
    "df_validacao_8_2 = RealizarPredicaoTeste_Modelo8(\n",
    "    df_teste_com_classe_pred,\n",
    "    list_features_modelo_8_2,\n",
    "    target,\n",
    "    dict_modelo_8_2_regressao_geral,\n",
    "    dict_modelo_8_2_regressao_especializado,\n",
    "    modelo_number=modelo_number,\n",
    "    coluna_classe_predita='classe_predita',\n",
    "    coluna_flag_especializado='flag_especializado'\n",
    ")\n",
    "\n",
    "del df_teste_com_classe_pred\n",
    "gc.collect()\n",
    "\n",
    "metricas_modelo_8_2 = CalcularMetricasTeste_Modelo8(\n",
    "    df_validacao_8_2,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    psc_a_max_chuva,\n",
    "    pcc_a_erro,\n",
    "    pmc_a_erro,\n",
    "    pmc_a_min_chuva\n",
    ")\n",
    "\n",
    "SalvarValidacaoModeloMetricas_Modelo8(\n",
    "    df_validacao_8_2,\n",
    "    modelo_8_2_classificacao,\n",
    "    dict_modelo_8_2_regressao_geral,\n",
    "    dict_modelo_8_2_regressao_especializado,\n",
    "    metricas_modelo_8_2,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    final_db=final_db\n",
    ")\n",
    "\n",
    "del (\n",
    "    df_validacao_8_2,\n",
    "    modelo_8_2_classificacao,\n",
    "    dict_modelo_8_2_regressao_geral,\n",
    "    dict_modelo_8_2_regressao_especializado,\n",
    "    metricas_modelo_8_2\n",
    ")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1352f07",
   "metadata": {},
   "source": [
    "## Modelo 8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06dda9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba85ebdcd7b485a9e072c41b011ef0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.28 GiB for an array with shape (94, 6109875) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 80\u001b[0m\n\u001b[0;32m     73\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m     75\u001b[0m dict_treino_regressao_geral \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     76\u001b[0m     classe: df_treino_geral\u001b[38;5;241m.\u001b[39mloc[df_treino_geral[target_classificacao] \u001b[38;5;241m==\u001b[39m classe]\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m classe \u001b[38;5;129;01min\u001b[39;00m dict_classes\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m     78\u001b[0m }\n\u001b[1;32m---> 80\u001b[0m dict_treino_regressao_especializado \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasse\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_treino_especializado\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_treino_especializado\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_classificacao\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclasse\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclasse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdict_classes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m}\u001b[49m\n\u001b[0;32m     85\u001b[0m dict_X_y_treino_regressao_geral \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     86\u001b[0m     classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_8_3, target)\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m classe, df_treino_classe \u001b[38;5;129;01min\u001b[39;00m dict_treino_regressao_geral\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df_treino_classe) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     89\u001b[0m }\n\u001b[0;32m     91\u001b[0m dict_X_y_treino_regressao_especializado \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     92\u001b[0m     classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_8_3, target)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m classe, df_treino_classe \u001b[38;5;129;01min\u001b[39;00m dict_treino_regressao_especializado\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df_treino_classe) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     95\u001b[0m }\n",
      "Cell \u001b[1;32mIn[6], line 81\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     73\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m     75\u001b[0m dict_treino_regressao_geral \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     76\u001b[0m     classe: df_treino_geral\u001b[38;5;241m.\u001b[39mloc[df_treino_geral[target_classificacao] \u001b[38;5;241m==\u001b[39m classe]\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m classe \u001b[38;5;129;01min\u001b[39;00m dict_classes\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m     78\u001b[0m }\n\u001b[0;32m     80\u001b[0m dict_treino_regressao_especializado \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m---> 81\u001b[0m     classe: \u001b[43mdf_treino_especializado\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_treino_especializado\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_classificacao\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclasse\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m classe \u001b[38;5;129;01min\u001b[39;00m dict_classes\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m     83\u001b[0m }\n\u001b[0;32m     85\u001b[0m dict_X_y_treino_regressao_geral \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     86\u001b[0m     classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_8_3, target)\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m classe, df_treino_classe \u001b[38;5;129;01min\u001b[39;00m dict_treino_regressao_geral\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df_treino_classe) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     89\u001b[0m }\n\u001b[0;32m     91\u001b[0m dict_X_y_treino_regressao_especializado \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     92\u001b[0m     classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_8_3, target)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m classe, df_treino_classe \u001b[38;5;129;01min\u001b[39;00m dict_treino_regressao_especializado\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df_treino_classe) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     95\u001b[0m }\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:1413\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_slice_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getbool_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;66;03m# an iterable multi-selection\u001b[39;00m\n\u001b[0;32m   1416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, MultiIndex)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:1211\u001b[0m, in \u001b[0;36m_LocationIndexer._getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1209\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(labels, key)\n\u001b[0;32m   1210\u001b[0m inds \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   4143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   4144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4145\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   4146\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4151\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   4152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4154\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   4155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[0;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4131\u001b[0m     )\n\u001b[1;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4140\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:687\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:688\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 688\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n\u001b[0;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\array_algos\\take.py:157\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    155\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    162\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.28 GiB for an array with shape (94, 6109875) and data type float64"
     ]
    }
   ],
   "source": [
    "modelo_number = '8_3'\n",
    "\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.5\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,7),\n",
    "    2:(7,51),\n",
    "    3:(51,np.inf)\n",
    "}\n",
    "\n",
    "list_features_modelo_8_3 = (\n",
    "    list_features_geoespaciais\n",
    "    + list_features_estacoes\n",
    "    + list_features_vizinhas\n",
    "    + list_features_produtos\n",
    ")\n",
    "\n",
    "Algoritmo = ExtraTreesRegressor\n",
    "AlgoritmoClassificacao = ExtraTreesClassifier\n",
    "kwargs_regressao = {'n_estimators': 100, 'random_state': 42}\n",
    "kwargs_classificacao = {'n_estimators': 100, 'random_state': 42}\n",
    "\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "df_base = ImportBase_Modelo8()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo8(df_base, dict_classes)\n",
    "\n",
    "del df_base\n",
    "\n",
    "df_base_classes['flag_especializado'] = (\n",
    "    df_base_classes[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado\n",
    ").astype(int)\n",
    "\n",
    "df_base_geral, df_base_especializado = SepararBaseEspecializadoGeral_Modelo8(\n",
    "    df_base_classes,\n",
    "    coluna_vl_prioridade_vizinha,\n",
    "    threshold_modelo_especializado\n",
    ")\n",
    "\n",
    "df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral = SplitTreinoTeste_Modelo8(\n",
    "    df_base_geral,\n",
    "    df_base_especializado,\n",
    "    pct_train_test_split,\n",
    "    coluna_percentil_temporal='percentil_temporal'\n",
    ")\n",
    "\n",
    "del df_base_geral, df_base_especializado\n",
    "gc.collect()\n",
    "\n",
    "df_X_treino_classificacao, df_y_treino_classificacao = PrepararBaseTreino(\n",
    "    df_treino_geral,\n",
    "    list_features_modelo_8_3,\n",
    "    target_classificacao\n",
    ")\n",
    "\n",
    "modelo_8_3_classificacao = TreinarClassificacao_Modelo8(\n",
    "    df_X_treino_classificacao,\n",
    "    df_y_treino_classificacao,\n",
    "    AlgoritmoClassificacao,\n",
    "    **kwargs_classificacao\n",
    ")\n",
    "\n",
    "del df_X_treino_classificacao, df_y_treino_classificacao\n",
    "gc.collect()\n",
    "\n",
    "dict_treino_regressao_geral = {\n",
    "    classe: df_treino_geral.loc[df_treino_geral[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_treino_regressao_especializado = {\n",
    "    classe: df_treino_especializado.loc[df_treino_especializado[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_geral = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_8_3, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_geral.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_especializado = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_8_3, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_especializado.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "del df_treino_geral, df_treino_especializado\n",
    "del dict_treino_regressao_geral, dict_treino_regressao_especializado\n",
    "gc.collect()\n",
    "\n",
    "dict_modelo_8_3_regressao_geral = {\n",
    "    classe: TreinarAlgoritmo_Modelo8(df_X_treino, df_y_treino, Algoritmo, **kwargs_regressao)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_geral.items()\n",
    "}\n",
    "\n",
    "dict_modelo_8_3_regressao_especializado = {\n",
    "    classe: TreinarAlgoritmo_Modelo8(df_X_treino, df_y_treino, Algoritmo, **kwargs_regressao)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_especializado.items()\n",
    "}\n",
    "\n",
    "del dict_X_y_treino_regressao_geral, dict_X_y_treino_regressao_especializado\n",
    "gc.collect()\n",
    "\n",
    "df_teste_all = pd.concat(\n",
    "    [df_teste_geral, df_teste_especializado],\n",
    "    ignore_index=True\n",
    ").drop_duplicates(\n",
    "    subset=['id_estacao', 'dt_medicao']\n",
    ")\n",
    "\n",
    "del df_teste_geral, df_teste_especializado\n",
    "gc.collect()\n",
    "\n",
    "if 'flag_especializado' not in df_teste_all.columns:\n",
    "    df_teste_all = df_teste_all.merge(\n",
    "        df_base_classes[['id_estacao', 'dt_medicao', 'flag_especializado']],\n",
    "        on=['id_estacao', 'dt_medicao'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "del df_base_classes\n",
    "gc.collect()\n",
    "\n",
    "df_teste_com_classe_pred = PreverClasseTeste_Modelo8(\n",
    "    df_teste_all,\n",
    "    list_features_modelo_8_3,\n",
    "    modelo_8_3_classificacao,''\n",
    "    nome_coluna_classe_predita='classe_predita'\n",
    ")\n",
    "\n",
    "del df_teste_all\n",
    "gc.collect()\n",
    "\n",
    "df_validacao_8_3 = RealizarPredicaoTeste_Modelo8(\n",
    "    df_teste_com_classe_pred,\n",
    "    list_features_modelo_8_3,\n",
    "    target,\n",
    "    dict_modelo_8_3_regressao_geral,\n",
    "    dict_modelo_8_3_regressao_especializado,\n",
    "    modelo_number=modelo_number,\n",
    "    coluna_classe_predita='classe_predita',\n",
    "    coluna_flag_especializado='flag_especializado'\n",
    ")\n",
    "\n",
    "del df_teste_com_classe_pred\n",
    "gc.collect()\n",
    "\n",
    "metricas_modelo_8_3 = CalcularMetricasTeste_Modelo8(\n",
    "    df_validacao_8_3,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    psc_a_max_chuva,\n",
    "    pcc_a_erro,\n",
    "    pmc_a_erro,\n",
    "    pmc_a_min_chuva\n",
    ")\n",
    "\n",
    "SalvarValidacaoModeloMetricas_Modelo8(\n",
    "    df_validacao_8_3,\n",
    "    modelo_8_3_classificacao,\n",
    "    dict_modelo_8_3_regressao_geral,\n",
    "    dict_modelo_8_3_regressao_especializado,\n",
    "    metricas_modelo_8_3,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    final_db=final_db\n",
    ")\n",
    "\n",
    "del (\n",
    "    df_validacao_8_3,\n",
    "    modelo_8_3_classificacao,\n",
    "    dict_modelo_8_3_regressao_geral,\n",
    "    dict_modelo_8_3_regressao_especializado,\n",
    "    metricas_modelo_8_3\n",
    ")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96af130f",
   "metadata": {},
   "source": [
    "## Modelo 8.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8abaf923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3604148951b747269c6d5d3a3e6d5570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_number = '8_4'\n",
    "\n",
    "pct_train_test_split = 0.7\n",
    "threshold_modelo_especializado = 0.5\n",
    "target = 'vl_precipitacao'\n",
    "target_classificacao = 'classe_precipitacao'\n",
    "coluna_vl_prioridade_vizinha = 'vl_prioridade_vizinha_1'\n",
    "\n",
    "dict_classes = {\n",
    "    0:(0,1),\n",
    "    1:(1,7),\n",
    "    2:(7,51),\n",
    "    3:(51,np.inf)\n",
    "}\n",
    "\n",
    "list_features_modelo_8_4 = (\n",
    "    list_features_geoespaciais\n",
    "    + list_features_estacoes\n",
    "    + list_features_vizinhas\n",
    "    + list_features_produtos\n",
    ")\n",
    "\n",
    "Algoritmo = LGBMRegressor\n",
    "AlgoritmoClassificacao = LGBMClassifier\n",
    "kwargs_regressao = {'n_estimators': 100, 'random_state': 42, 'verbose': -1}\n",
    "kwargs_classificacao = {'n_estimators': 100, 'random_state': 42, 'verbose': -1}\n",
    "\n",
    "psc_a_max_chuva = 1\n",
    "pcc_a_erro = 1\n",
    "pmc_a_erro = 5\n",
    "pmc_a_min_chuva = 20\n",
    "\n",
    "df_base = ImportBase_Modelo8()\n",
    "\n",
    "df_base_classes = CriarColunaClasse_Modelo8(df_base, dict_classes)\n",
    "\n",
    "del df_base\n",
    "\n",
    "df_base_classes['flag_especializado'] = (\n",
    "    df_base_classes[coluna_vl_prioridade_vizinha] >= threshold_modelo_especializado\n",
    ").astype(int)\n",
    "\n",
    "df_base_geral, df_base_especializado = SepararBaseEspecializadoGeral_Modelo8(\n",
    "    df_base_classes,\n",
    "    coluna_vl_prioridade_vizinha,\n",
    "    threshold_modelo_especializado\n",
    ")\n",
    "\n",
    "df_treino_especializado, df_teste_especializado, df_treino_geral, df_teste_geral = SplitTreinoTeste_Modelo8(\n",
    "    df_base_geral,\n",
    "    df_base_especializado,\n",
    "    pct_train_test_split,\n",
    "    coluna_percentil_temporal='percentil_temporal'\n",
    ")\n",
    "\n",
    "del df_base_geral, df_base_especializado\n",
    "gc.collect()\n",
    "\n",
    "df_X_treino_classificacao, df_y_treino_classificacao = PrepararBaseTreino(\n",
    "    df_treino_geral,\n",
    "    list_features_modelo_8_4,\n",
    "    target_classificacao\n",
    ")\n",
    "\n",
    "modelo_8_4_classificacao = TreinarClassificacao_Modelo8(\n",
    "    df_X_treino_classificacao,\n",
    "    df_y_treino_classificacao,\n",
    "    AlgoritmoClassificacao,\n",
    "    **kwargs_classificacao\n",
    ")\n",
    "\n",
    "del df_X_treino_classificacao, df_y_treino_classificacao\n",
    "gc.collect()\n",
    "\n",
    "dict_treino_regressao_geral = {\n",
    "    classe: df_treino_geral.loc[df_treino_geral[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_treino_regressao_especializado = {\n",
    "    classe: df_treino_especializado.loc[df_treino_especializado[target_classificacao] == classe]\n",
    "    for classe in dict_classes.keys()\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_geral = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_8_4, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_geral.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "dict_X_y_treino_regressao_especializado = {\n",
    "    classe: PrepararBaseTreino(df_treino_classe, list_features_modelo_8_4, target)\n",
    "    for classe, df_treino_classe in dict_treino_regressao_especializado.items()\n",
    "    if len(df_treino_classe) > 0\n",
    "}\n",
    "\n",
    "del df_treino_geral, df_treino_especializado\n",
    "del dict_treino_regressao_geral, dict_treino_regressao_especializado\n",
    "gc.collect()\n",
    "\n",
    "dict_modelo_8_4_regressao_geral = {\n",
    "    classe: TreinarAlgoritmo_Modelo8(df_X_treino, df_y_treino, Algoritmo, **kwargs_regressao)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_geral.items()\n",
    "}\n",
    "\n",
    "dict_modelo_8_4_regressao_especializado = {\n",
    "    classe: TreinarAlgoritmo_Modelo8(df_X_treino, df_y_treino, Algoritmo, **kwargs_regressao)\n",
    "    for classe, (df_X_treino, df_y_treino) in dict_X_y_treino_regressao_especializado.items()\n",
    "}\n",
    "\n",
    "del dict_X_y_treino_regressao_geral, dict_X_y_treino_regressao_especializado\n",
    "gc.collect()\n",
    "\n",
    "df_teste_all = pd.concat(\n",
    "    [df_teste_geral, df_teste_especializado],\n",
    "    ignore_index=True\n",
    ").drop_duplicates(\n",
    "    subset=['id_estacao', 'dt_medicao']\n",
    ")\n",
    "\n",
    "del df_teste_geral, df_teste_especializado\n",
    "gc.collect()\n",
    "\n",
    "if 'flag_especializado' not in df_teste_all.columns:\n",
    "    df_teste_all = df_teste_all.merge(\n",
    "        df_base_classes[['id_estacao', 'dt_medicao', 'flag_especializado']],\n",
    "        on=['id_estacao', 'dt_medicao'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "del df_base_classes\n",
    "gc.collect()\n",
    "\n",
    "df_teste_com_classe_pred = PreverClasseTeste_Modelo8(\n",
    "    df_teste_all,\n",
    "    list_features_modelo_8_4,\n",
    "    modelo_8_4_classificacao,\n",
    "    nome_coluna_classe_predita='classe_predita'\n",
    ")\n",
    "\n",
    "del df_teste_all\n",
    "gc.collect()\n",
    "\n",
    "df_validacao_8_4 = RealizarPredicaoTeste_Modelo8(\n",
    "    df_teste_com_classe_pred,\n",
    "    list_features_modelo_8_4,\n",
    "    target,\n",
    "    dict_modelo_8_4_regressao_geral,\n",
    "    dict_modelo_8_4_regressao_especializado,\n",
    "    modelo_number=modelo_number,\n",
    "    coluna_classe_predita='classe_predita',\n",
    "    coluna_flag_especializado='flag_especializado'\n",
    ")\n",
    "\n",
    "del df_teste_com_classe_pred\n",
    "gc.collect()\n",
    "\n",
    "metricas_modelo_8_4 = CalcularMetricasTeste_Modelo8(\n",
    "    df_validacao_8_4,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    psc_a_max_chuva,\n",
    "    pcc_a_erro,\n",
    "    pmc_a_erro,\n",
    "    pmc_a_min_chuva\n",
    ")\n",
    "\n",
    "SalvarValidacaoModeloMetricas_Modelo8(\n",
    "    df_validacao_8_4,\n",
    "    modelo_8_4_classificacao,\n",
    "    dict_modelo_8_4_regressao_geral,\n",
    "    dict_modelo_8_4_regressao_especializado,\n",
    "    metricas_modelo_8_4,\n",
    "    target,\n",
    "    modelo_number,\n",
    "    final_db=final_db\n",
    ")\n",
    "\n",
    "del (\n",
    "    df_validacao_8_4,\n",
    "    modelo_8_4_classificacao,\n",
    "    dict_modelo_8_4_regressao_geral,\n",
    "    dict_modelo_8_4_regressao_especializado,\n",
    "    metricas_modelo_8_4\n",
    ")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff48bf5f",
   "metadata": {},
   "source": [
    "# Comparações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e686da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_modelo_numbers = [\n",
    "    '1_1','1_2','1_3','1_4',\n",
    "    '2_1','2_2','2_3','2_4',\n",
    "    '3_1','3_2','3_3','3_4','3_5',\n",
    "    '4_1','4_2','4_3','4_4','4_5',\n",
    "    '5_1','5_2','5_3','5_4','5_5',\n",
    "    '6_1','6_2','6_3','6_4','6_5',\n",
    "    '7_1','7_2','7_3','7_4','7_5',\n",
    "    '8_2','8_4']\n",
    "\n",
    "metricas_modelos = {}\n",
    "for modelo_number in list_modelo_numbers:\n",
    "    with open(f'modelos_finais/metricas_{modelo_number}.json','r') as f:\n",
    "        metricas_modelos[modelo_number] = json.load(f)\n",
    "\n",
    "pd.DataFrame(metricas_modelos).T.to_excel('metricas_final.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
